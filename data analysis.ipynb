{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# numpy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import *  \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arrays(vector) and matrix(2d array) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3] 3 int32\n",
      "\n",
      "[[1 2 3]\n",
      " [4 5 6]\n",
      " [7 8 9]] 3 int64\n"
     ]
    }
   ],
   "source": [
    "arr = [1,2,3]\n",
    "matrix = [[1,2,3],[4,5,6],[7,8,9]]\n",
    "print(array(arr,dtype=int32),len(array(arr,dtype=int32)),array(arr,dtype=int32).dtype)\n",
    "print('')\n",
    "print(array(matrix),len(array(matrix)),array(matrix).dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  2,  4,  6,  8, 10])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# range in numpy \n",
    "arange(0,11,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# append\n",
    "arr1 = arange(5)\n",
    "arr2 = arange(5,13)\n",
    "arr3 = np.append(arr1,arr2)\n",
    "arr3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1, 4],\n",
       "       [2, 5],\n",
       "       [3, 6]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concatenate\n",
    "arr1 = arange(5)\n",
    "arr2 = arange(5,13)\n",
    "arr3 = np.concatenate([arr1,arr2])\n",
    "print(arr3)\n",
    "# concatenate along second axes\n",
    "np.c_[np.array([1,2,3]), np.array([4,5,6])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0) 0\n",
      "(0, 1) 1\n",
      "(0, 2) 2\n",
      "(1, 0) 3\n",
      "(1, 1) 4\n",
      "(1, 2) 5\n",
      "(2, 0) 6\n",
      "(2, 1) 7\n",
      "(2, 2) 8\n"
     ]
    }
   ],
   "source": [
    "# enumerate in numpy\n",
    "my_3_3_array = np.arange(9).reshape(3,3)\n",
    "for index, value in np.ndenumerate(my_3_3_array):\n",
    "    print(index, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4,) \n",
      "\n",
      "row vector: [[0 1 2 3]]\n",
      "(1, 4)\n",
      "\n",
      "\n",
      "column vector:\n",
      " [[0]\n",
      " [1]\n",
      " [2]\n",
      " [3]]\n",
      "(4, 1)\n"
     ]
    }
   ],
   "source": [
    "# adding new dimensions \n",
    "x1 = np.arange(4)\n",
    "print(x1.shape,'\\n')\n",
    "print(\"row vector:\", x1[np.newaxis, :] )\n",
    "print(x1[np.newaxis, :].shape)\n",
    "### create a column vector by adding second dimension\n",
    "print(\"\\n\")\n",
    "print(\"column vector:\\n\", x1[:, np.newaxis])\n",
    "print(x1[:, np.newaxis].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# search in numpy array \n",
    "np.searchsorted(arange(0,11,2),5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inversion of 10,11,12 :  [-11 -12 -13]\n"
     ]
    }
   ],
   "source": [
    "#invert numbers in binary    \n",
    "out_num = np.invert([10,11,12]) \n",
    "print (\"inversion of 10,11,12 : \", out_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indices of non zero elements :  [ 8  7 -5  1]\n"
     ]
    }
   ],
   "source": [
    "# find the values which are non zero\n",
    "arr_non_zero = np.array([[0, 8, 0], [7, 0, 0], [-5, 0, 1]])\n",
    "out_tpl = arr_non_zero[np.nonzero(arr_non_zero)]\n",
    "print (\"Indices of non zero elements : \", out_tpl) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output array:  [[2.00000000e+000 1.79769313e+308 2.00000000e+000]\n",
      " [2.00000000e+000 2.00000000e+000 0.00000000e+000]]\n"
     ]
    }
   ],
   "source": [
    "# replace nan with 0 and +ve inf with a large and -ve inf with a small no\n",
    "out_arr = np.nan_to_num(np.array([[2, np.inf, 2], [2, 2, np.nan]])) \n",
    "print (\"output array: \", out_arr) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken by vectorized operation : 5.39 µs ± 154 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n",
      "[1.00000000e+00 2.71828183e+00 7.38905610e+00 2.00855369e+01\n",
      " 5.45981500e+01 1.48413159e+02 4.03428793e+02 1.09663316e+03\n",
      " 2.98095799e+03 8.10308393e+03 2.20264658e+04 5.98741417e+04\n",
      " 1.62754791e+05 4.42413392e+05 1.20260428e+06 3.26901737e+06\n",
      " 8.88611052e+06 2.41549528e+07 6.56599691e+07 1.78482301e+08\n",
      " 4.85165195e+08 1.31881573e+09 3.58491285e+09 9.74480345e+09\n",
      " 2.64891221e+10 7.20048993e+10 1.95729609e+11 5.32048241e+11\n",
      " 1.44625706e+12 3.93133430e+12 1.06864746e+13 2.90488497e+13\n",
      " 7.89629602e+13 2.14643580e+14 5.83461743e+14 1.58601345e+15\n",
      " 4.31123155e+15 1.17191424e+16 3.18559318e+16 8.65934004e+16\n",
      " 2.35385267e+17 6.39843494e+17 1.73927494e+18 4.72783947e+18\n",
      " 1.28516001e+19 3.49342711e+19 9.49611942e+19 2.58131289e+20\n",
      " 7.01673591e+20 1.90734657e+21 5.18470553e+21 1.40934908e+22\n",
      " 3.83100800e+22 1.04137594e+23 2.83075330e+23 7.69478527e+23\n",
      " 2.09165950e+24 5.68572000e+24 1.54553894e+25 4.20121040e+25\n",
      " 1.14200739e+26 3.10429794e+26 8.43835667e+26 2.29378316e+27\n",
      " 6.23514908e+27 1.69488924e+28 4.60718663e+28 1.25236317e+29\n",
      " 3.40427605e+29 9.25378173e+29 2.51543867e+30 6.83767123e+30\n",
      " 1.85867175e+31 5.05239363e+31 1.37338298e+32 3.73324200e+32\n",
      " 1.01480039e+33 2.75851345e+33 7.49841700e+33 2.03828107e+34\n",
      " 5.54062238e+34 1.50609731e+35 4.09399696e+35 1.11286375e+36\n",
      " 3.02507732e+36 8.22301271e+36 2.23524660e+37 6.07603023e+37\n",
      " 1.65163625e+38 4.48961282e+38 1.22040329e+39 3.31740010e+39\n",
      " 9.01762841e+39 2.45124554e+40 6.66317622e+40 1.81123908e+41\n",
      " 4.92345829e+41 1.33833472e+42 3.63797095e+42 9.88903032e+42\n",
      " 2.68811714e+43 7.30705998e+43 1.98626484e+44 5.39922761e+44\n",
      " 1.46766223e+45 3.98951957e+45 1.08446386e+46 2.94787839e+46\n",
      " 8.01316426e+46 2.17820388e+47 5.92097203e+47 1.60948707e+48\n",
      " 4.37503945e+48 1.18925902e+49 3.23274119e+49 8.78750164e+49\n",
      " 2.38869060e+50 6.49313426e+50 1.76501689e+51 4.79781333e+51\n",
      " 1.30418088e+52 3.54513118e+52 9.63666567e+52 2.61951732e+53\n",
      " 7.12058633e+53 1.93557604e+54 5.26144118e+54 1.43020800e+55\n",
      " 3.88770841e+55 1.05678871e+56 2.87264955e+56 7.80867107e+56\n",
      " 2.12261687e+57 5.76987086e+57 1.56841351e+58 4.26338995e+58\n",
      " 1.15890954e+59 3.15024275e+59 8.56324762e+59 2.32773204e+60\n",
      " 6.32743171e+60 1.71997426e+61 4.67537478e+61 1.27089863e+62\n",
      " 3.45466066e+62 9.39074129e+62 2.55266814e+63 6.93887142e+63\n",
      " 1.88618081e+64 5.12717102e+64]\n",
      "Time taken by non-vectorized operation : 25.9 µs ± 658 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "# numpy is faster than math module when working on numbers as its vectorized(works on vectors)\n",
    "import math\n",
    "print(\"Time taken by vectorized operation : \", end = \"\")\n",
    "%timeit exp(arange(150))\n",
    "print(exp(arange(150)))\n",
    "  \n",
    "# non-vectorized operation\n",
    "print(\"Time taken by non-vectorized operation : \", end = \"\")\n",
    "%timeit [math.exp(item) for item in range(150)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0.] \n",
      " \n",
      " [[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]] \n",
      "\n",
      "[1. 1. 1.] \n",
      " \n",
      " [[1. 1. 1.]\n",
      " [1. 1. 1.]\n",
      " [1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# 0's and 1's \n",
    "print(zeros(3),'\\n','\\n',zeros((3,3)),'\\n')\n",
    "print(ones(3),'\\n','\\n',ones((3,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  0.20408163,  0.40816327,  0.6122449 ,  0.81632653,\n",
       "        1.02040816,  1.2244898 ,  1.42857143,  1.63265306,  1.83673469,\n",
       "        2.04081633,  2.24489796,  2.44897959,  2.65306122,  2.85714286,\n",
       "        3.06122449,  3.26530612,  3.46938776,  3.67346939,  3.87755102,\n",
       "        4.08163265,  4.28571429,  4.48979592,  4.69387755,  4.89795918,\n",
       "        5.10204082,  5.30612245,  5.51020408,  5.71428571,  5.91836735,\n",
       "        6.12244898,  6.32653061,  6.53061224,  6.73469388,  6.93877551,\n",
       "        7.14285714,  7.34693878,  7.55102041,  7.75510204,  7.95918367,\n",
       "        8.16326531,  8.36734694,  8.57142857,  8.7755102 ,  8.97959184,\n",
       "        9.18367347,  9.3877551 ,  9.59183673,  9.79591837, 10.        ])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Return evenly spaced numbers over a specified interval.\n",
    "linspace(0,10,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "0 1\n",
      "1 2\n",
      "2 3\n",
      "3 4\n",
      "4 5\n"
     ]
    }
   ],
   "source": [
    "# iterating through arrays\n",
    "for i in array([1,2,3,4,5]):\n",
    "    print(i)\n",
    "for i, val in enumerate(array([1,2,3,4,5])):\n",
    "    print(i, val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "(0, 0) 1\n",
      "(0, 1) 2\n",
      "(0, 2) 3\n",
      "(0, 3) 4\n",
      "(1, 0) 5\n",
      "(1, 1) 6\n",
      "(1, 2) 7\n",
      "(1, 3) 8\n"
     ]
    }
   ],
   "source": [
    "# iterate through matrix \n",
    "arr = np.array([[[1, 2], [3, 4]], [[5, 6], [7, 8]]])\n",
    "for x in np.nditer(arr):\n",
    "    print(x)\n",
    "arr = np.array([[1, 2, 3, 4], [5, 6, 7, 8]])\n",
    "for idx, x in np.ndenumerate(arr):\n",
    "    print(idx, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# identity matrix \n",
    "eye(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random \n",
    "# interbal is always [a,b) includes a and excludes b "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.55877651 0.71245806 0.96763268]\n",
      "[[0.11073795 0.11997001 0.01637865]\n",
      " [0.85546639 0.88789953 0.23127915]\n",
      " [0.68128318 0.37998368 0.81648736]]\n"
     ]
    }
   ],
   "source": [
    "# random b/w 0 to 1  \n",
    "print(random.random(3))\n",
    "print(random.random((3,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.79103485 0.65171793 0.83793901]\n",
      "[[0.35933093 0.76408715 0.62685391]\n",
      " [0.28101489 0.63894831 0.38187164]\n",
      " [0.37810567 0.02418898 0.08727117]]\n"
     ]
    }
   ],
   "source": [
    "# uniform distribution between 0&1\n",
    "print(random.rand(3))\n",
    "print(random.rand(3,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.82322646 0.01272209 0.67721033]\n",
      "[[ 0.57621098 -0.51440296  1.10548711]\n",
      " [ 1.67451427  1.90460228  0.75908355]\n",
      " [ 1.12247638 -0.94633383  1.3058865 ]]\n"
     ]
    }
   ],
   "source": [
    "# normal distribution mean 0 & variance 1 \n",
    "print(random.randn(3))\n",
    "print(random.randn(3,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[70, 29, 79, 37, 56, 49, 84, 83, 51, 53] int64 4 0\n",
      "[[4 5 3 6]\n",
      " [4 5 2 3]\n",
      " [5 5 8 5]]\n",
      "[19.13516311127103, 35.43868688342618, 42.74591555011471, 71.40925133945802, 98.84492530012984, 59.44522288150705, 94.19352270679475, 50.11877317025728, 88.10100521674579, 69.33270164522074] float64\n",
      "[-140.1936874683447, 62.20461997569341, -72.2594087328951, -57.746611176318794, 14.615806020358418, 26.449584741520248, 231.79596464897074, 1.2512465617189419, 29.424720615512005, 84.26016982803422] float64\n",
      "[[ 0.34445637 -0.67476633  1.334322  ]\n",
      " [ 0.75283798  1.52461199  0.65545497]\n",
      " [-1.12127774 -0.05239324  0.82684438]]\n"
     ]
    }
   ],
   "source": [
    "# random int \n",
    "# min and max value of random int index \n",
    "print(list(random.randint(1,100,10)),random.randint(1,100,10).dtype,\n",
    "      random.randint(1,100,10).argmin(),random.randint(1,100,10).argmax())\n",
    "# random int for a 2d matrix \n",
    "print(np.random.randint(0,10,(3,4)))\n",
    "# uniform distribution b/w a to b and gives float values \n",
    "print(list(random.uniform(1,100,10)),random.uniform(1,100,10).dtype)\n",
    "# normal distribution b/w a to b \n",
    "print(list(random.normal(1,100,10)),random.normal(1,100,10).dtype)\n",
    "# normal distribution for a 2d matrix\n",
    "print(np.random.normal(0,1,(3,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 4 0 0 1 2 4 3 4 1 1 3 3 3 4 4 4 0 3 3 3 3 4 0 1 4 3 2 4 3 0 2 3 0 2 1 2\n",
      " 0 2 3 2 1 1 4 3 0 4 0 0 3 4 0 3 4 1 1 0 4 4 3 1 0 3 1 2 4 2 1 0 4 3 2 3 0\n",
      " 3 0 0 2 4 3 0 3 4 1 0 1 0 4 3 0 1 4 2 4 0 1 3 1 1 4 0 2 2 1 1 2 4 0 2 4 0\n",
      " 2 1 0 3 0 4 0 4 2 2 4 2 3 1 4 4 4 4 4 2 2 2 0 4 2 2 3 3 3 3 2 1 2 3 2 2 1\n",
      " 0 0 3 4 1 0 2 3 0 4 3 4 1 3 0 0 2 0 4 0 4 3 4 1 1 4 3 4 1 4 4 2 1 2 4 4 3\n",
      " 1 2 0 2 1 3 4 3 4 3 4 0 4 4 1 0 2 2 1 3 1 0 1 1 0 0 3 1 4 1 4 3 4 1 0 3 0\n",
      " 0 2 4 3 2 0 2 3 4 1 1 3 4 2 2 1 1 2 2 3 4 4 0 0 1 0 3 2 0 3 0 1 2 3 0 0 4\n",
      " 4 2 1 2 0 3 2 0 2 3 4 0 4 3 0 2 2 2 0 2 3 2 3 0 1 3 0 3 1 1 0 1 0 2 4 2 4\n",
      " 3 2 2 0 4 1 1 3 0 0 1 4 0 0 1 2 2 1 1 4 3 3 1 2 0 0 4 3 2 4 3 1 0 2 1 1 4\n",
      " 1 2 3 4 4 0 3 1 1 1 0 4 0 4 2 3 2 4 1 2 1 1 0 0 2 0 1 0 2 3 0 3 2 2 4 4 2\n",
      " 0 3 2 0 1 2 1 4 0 0 0 2 3 2 0 4 1 0 2 4 3 2 0 2 4 3 0 1 1 1 2 2 3 4 3 4 1\n",
      " 4 4 1 0 0 4 1 1 2 4 2 1 4 1 1 4 2 1 4 1 3 2 3 2 4 4 1 3 2 1 1 3 2 2 2 3 3\n",
      " 4 1 1 4 2 0 1 0 0 0 2 1 2 3 3 3 2 4 4 4 1 0 2 3 1 3 4 3 2 4 3 2 1 2 0 3 2\n",
      " 0 4 4 2 0 4 4 4 1 2 3 4 4 4 3 1 2 2 1 2 4 1 0 1 4 2 4 0 3 2 3 2 1 4 0 2 1\n",
      " 3 4 1 1 2 2 2 4 1 3 4 4 2 1 2 2 3 4 4 1 4 1 0 2 4 4 4 3 3 3 0 2 1 3 2 1 0\n",
      " 2 0 3 0 4 4 2 0 2 3 2 1 0 2 0 2 4 2 1 3 4 1 1 2 3 0 0 1 4 1 4 3 4 4 0 1 3\n",
      " 2 3 3 2 1 2 2 3 0 4 4 2 1 2 3 3 0 1 1 0 4 1 2 0 4 3 0 2 1 1 1 0 2 2 3 1 0\n",
      " 1 2 3 0 0 0 3 4 4 1 2 1 0 2 4 4 1 4 3 0 4 1 4 4 2 4 1 1 2 4 4 2 3 3 2 3 1\n",
      " 0 0 1 4 1 4 3 4 2 4 2 0 1 4 4 4 3 4 4 4 4 0 1 0 0 4 1 2 0 1 3 0 4 0 0 3 4\n",
      " 0 4 4 4 0 1 3 0 2 1 2 2 0 4 3 1 2 1 1 3 1 4 3 4 1 0 3 1 0 3 0 1 0 3 0 2 3\n",
      " 1 4 1 3 4 3 3 4 1 4 4 2 4 3 3 0 2 2 4 2 0 4 3 4 2 1 2 1 3 2 0 3 0 4 3 2 4\n",
      " 4 0 3 3 3 0 2 2 4 2 4 2 3 2 1 1 1 0 2 2 2 0 4 1 1 0 0 0 4 3 4 2 0 1 2 4 4\n",
      " 2 3 2 4 3 3 2 1 3 4 4 0 1 4 2 1 0 0 3 2 4 0 2 4 0 2 2 1 3 2 3 3 3 4 2 0 4\n",
      " 1 4 1 0 2 2 3 4 1 3 2 2 3 3 2 4 2 2 3 1 1 4 2 2 2 2 3 0 3 3 0 0 2 4 2 4 3\n",
      " 4 3 3 1 2 2 1 0 0 3 2 2 0 4 2 1 3 4 1 2 4 4 0 3 0 3 4 0 4 4 3 1 2 2 1 3 4\n",
      " 2 0 4 1 2 3 0 4 1 0 1 3 1 1 3 1 4 3 3 0 3 4 1 3 0 4 0 3 0 2 0 1 2 2 3 0 2\n",
      " 3 0 0 1 4 4 4 0 4 0 2 3 0 2 3 4 0 0 4 4 1 2 0 1 2 0 2 0 1 3 1 2 0 3 0 4 0\n",
      " 2]\n"
     ]
    }
   ],
   "source": [
    "# random sampling with probability for each sample \n",
    "# below we have 5 samples of size 1000 with equal probability of occuring  \n",
    "gfg = np.random.choice(5, 1000, p =[0.2, 0.2, 0.2, 0.2, 0.2])\n",
    "print(gfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 2 0 1 2 0 1 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 1, 2, 3, 1, 2, 3, 1, 2, 2])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# permutations \n",
    "box = np.array([1,2,3])\n",
    "shaker = np.random.randint(0, len(box), size=10)\n",
    "print(shaker)\n",
    "box.take(shaker) # perm numpy array based on above permutation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 8, 5, 6, 4])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shuffles the array \n",
    "arr = array([1,6,4,8,5])\n",
    "random.shuffle(arr)\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape(rows,cols) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  1  2  3  4]\n",
      " [ 5  6  7  8  9]\n",
      " [10 11 12 13 14]\n",
      " [15 16 17 18 19]\n",
      " [20 21 22 23 24]] \n",
      "\n",
      " [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24]\n",
      "\n",
      " (5, 5) 25 2\n",
      "\n",
      " [[[ 0  1  2]\n",
      "  [ 3  4  5]]\n",
      "\n",
      " [[ 6  7  8]\n",
      "  [ 9 10 11]]\n",
      "\n",
      " [[12 13 14]\n",
      "  [15 16 17]]\n",
      "\n",
      " [[18 19 20]\n",
      "  [21 22 23]]]\n",
      "\n",
      " (12, 1)\n",
      "\n",
      " (1, 12)\n"
     ]
    }
   ],
   "source": [
    "# 1d to 2d\n",
    "print(arange(25).reshape(5,5), '\\n\\n', arange(25).reshape(5,5).reshape(25))\n",
    "print('\\n',arange(25).reshape(5,5).shape,arange(25).reshape(5,5).size,arange(25).reshape(5,5).ndim)\n",
    "#1d to 3d\n",
    "print('\\n',arange(24).reshape(4,2,3))\n",
    "# (mrows,ncols) -> (m*n rows, 1 col)\n",
    "z = np.array([[1, 2, 3, 4],\n",
    "         [5, 6, 7, 8],\n",
    "         [9, 10, 11, 12]])\n",
    "print('\\n',z.reshape(-1,1).shape)\n",
    "# (mrows,ncols) -> (1 row, m*n col)\n",
    "print('\\n',z.reshape(1,-1).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 2]\n",
      " [3 4 5]\n",
      " [6 7 8]] \n",
      "\n",
      "[0 1 2 3 4 5 6 7 8] \n",
      "\n",
      "[[0 1 2]\n",
      " [3 4 5]\n",
      " [6 7 8]]\n"
     ]
    }
   ],
   "source": [
    "# reshape vs resize\n",
    "# resize reshapes inplace \n",
    "original = np.arange(9)\n",
    "print(original.reshape((3,3)),'\\n')\n",
    "print(original,'\\n')\n",
    "original.resize((3,3))\n",
    "print(original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2,) (1, 2) (2, 1)\n"
     ]
    }
   ],
   "source": [
    "# add a new axes \n",
    "x = np.array([1, 2])\n",
    "y = np.expand_dims(x, axis=0)\n",
    "z = np.expand_dims(x, axis=1)\n",
    "print(x.shape, y.shape, z.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 2]\n",
      " [3 4 5]\n",
      " [6 7 8]] \n",
      "\n",
      " [[  0   1   2]\n",
      " [  3   4   5]\n",
      " [  6 100   8]]\n"
     ]
    }
   ],
   "source": [
    "# deep copy in numpy \n",
    "original = np.arange(9).reshape((3,3))\n",
    "copy = original.copy()\n",
    "copy[2,1] = 100\n",
    "print(original,'\\n\\n',copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   1   2]\n",
      " [  3   4   5]\n",
      " [  6 100   8]] \n",
      "\n",
      " [[  0   1   2]\n",
      " [  3   4   5]\n",
      " [  6 100   8]]\n"
     ]
    }
   ],
   "source": [
    "# shallow copy but creates a new array\n",
    "original = np.arange(9).reshape((3,3))\n",
    "copy = original.view()\n",
    "copy[2,1] = 100\n",
    "print(original,'\\n\\n',copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0 50  1  2  3  4  5  6  7  8]\n",
      "[[ 0  1  2  3]\n",
      " [ 4  5  6  7]\n",
      " [ 8  9 10 11]]\n",
      "[[ 0 60  1  2  3]\n",
      " [ 4 60  5  6  7]\n",
      " [ 8 60  9 10 11]]\n",
      "[[ 0  1  2  3]\n",
      " [ 6  6  6  6]\n",
      " [ 9  9  9  9]\n",
      " [ 4  5  6  7]\n",
      " [ 8  9 10 11]]\n",
      "[[66  0  1  2 66  3]\n",
      " [66  4  5  6 66  7]\n",
      " [66  8  9 10 66 11]]\n"
     ]
    }
   ],
   "source": [
    "# insert in both col and rows \n",
    "num1 = np.arange(9)\n",
    "print(np.insert(num1,1,50))\n",
    "num2 = np.arange(12).reshape((3,4))\n",
    "print(num2)\n",
    "print(np.insert(num2,1,60,axis = 1)) # at columns insert a scalar \n",
    "print(np.insert(num2, [1], [[6],[9]], axis = 0)) # at rows insert array \n",
    "print(np.insert(num2, (0, 3), 66, axis = 1)) # insert at two different places "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  1  2  3]\n",
      " [ 4  5  6  7]\n",
      " [ 8  9 10 11]]\n",
      "[[ 0  2  3]\n",
      " [ 4  6  7]\n",
      " [ 8 10 11]]\n",
      "[[ 0  1  2  3]\n",
      " [ 8  9 10 11]]\n"
     ]
    }
   ],
   "source": [
    "# delete from both cols and rows  \n",
    "print(num2)\n",
    "print(np.delete(num2,1,axis = 1)) # inserting from cols \n",
    "print(np.delete(num2,1,axis = 0)) # inserting from rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indexing & broadcasting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2  6 10]\n"
     ]
    }
   ],
   "source": [
    "arr = arange(0,11,2)\n",
    "arr[:4:2] = 100\n",
    "arr\n",
    "print(arr[1:arr.size:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "[[2 3]\n",
      " [5 6]]\n",
      "[[0 4 6 3]\n",
      " [9 9 3 4]\n",
      " [3 5 8 2]]\n",
      "[[0 6]\n",
      " [9 3]\n",
      " [3 8]]\n"
     ]
    }
   ],
   "source": [
    "# matrix indexing \n",
    "matrix = array(([1,2,3],[4,5,6],[7,8,9]))\n",
    "# 1st row and 2nd column value [row,column]\n",
    "print(matrix[1,2])\n",
    "# upto 2nd row and from 1st column    \n",
    "print(matrix[:2,1:])\n",
    "#matrix slicing\n",
    "arr = np.random.randint(10, size=(3,4))\n",
    "print(arr)\n",
    "print(arr[:3, ::2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.51013818, 0.93093689, 0.5838868 , 0.90087481, 0.4263005 ],\n",
       "       [0.51834089, 0.42942757, 0.33284419, 0.93082394, 0.20655949],\n",
       "       [0.20696655, 0.56781012, 0.72779212, 0.09748836, 0.42039944],\n",
       "       [0.52183836, 0.1401716 , 0.79758425, 0.09110487, 0.80358438],\n",
       "       [0.61662568, 0.88332148, 0.31212885, 0.81814127, 0.457571  ]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# boolean indexing with broadcasting \n",
    "# replace values that are 1.5 more than std  \n",
    "mat = random.rand(5, 5)\n",
    "mat[abs(mat-mat.mean()) > 1.5 * mat.std()] = mat.mean()\n",
    "mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conditional selection\n",
    "# remember we use & for and | for or in numpy as well as pandas \n",
    "# using any and all for conditional selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 9 10] [0 2 4 6] [3 4 5 6] [ 0  1  8  9 10] [0 1 2 3 4 5 6 7]\n",
      "True True\n"
     ]
    }
   ],
   "source": [
    "arr = arange(11)\n",
    "print(arr[arr>5][3:],arr[arr%2 == 0][:4],arr[(arr>2)&(arr<7)],arr[(arr<2)|(arr>7)], arr[~(arr>7)])\n",
    "print(arr[arr>5].any(), arr[arr>5].all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2],\n",
       "       [ 0,  2, -1],\n",
       "       [ 0,  3, -1]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ternary conditions \n",
    "a = np.array([[0, 1, 2],\n",
    "              [0, 2, 4],\n",
    "              [0, 3, 6]])\n",
    "np.where(a < 4, a, -1)  # -1 is broadcast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  2  4  6  8 10 12 14 16 18 20]\n",
      "[  0   1   4   9  16  25  36  49  64  81 100]\n",
      "[False  True  True False] [ True  True  True  True]\n"
     ]
    }
   ],
   "source": [
    "# operations\n",
    "print(arr + arr)\n",
    "print(arr ** 2)\n",
    "# logical and, or \n",
    "arr1 = np.array([1,True,2,False])\n",
    "arr2 = np.array([0,True,3,True])\n",
    "print(np.logical_and(arr1,arr2),np.logical_or(arr1,arr2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([12, 10,  5,  6]), 8.699856320652657)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.abs(array([-12,10,5,-6])), np.std(array([-12,10,5,-6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 7 9] \n",
      "\n",
      "[[1 5 7]\n",
      " [6 2 4]\n",
      " [9 3 8]] \n",
      "\n",
      "[[1 2 4]\n",
      " [6 3 7]\n",
      " [9 5 8]] \n",
      "\n",
      "[[1 5 7]\n",
      " [2 4 6]\n",
      " [3 8 9]] \n",
      "\n",
      "[[1 5 7]\n",
      " [2 4 6]\n",
      " [3 8 9]]\n"
     ]
    }
   ],
   "source": [
    "# sort a vector\n",
    "print(np.sort(np.array([1,7,3,9,2])),'\\n')\n",
    "# sort a matrix(will be sorted both row and column wise combindly) \n",
    "a = np.array([[1,5,7],[6,2,4],[9,3,8]])\n",
    "print(a,'\\n')\n",
    "print(np.sort(a,axis = 0),'\\n') # sort first axis\n",
    "print(np.sort(a,axis = 1),'\\n') # sort second axis\n",
    "print(np.sort(a)) # sort last axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 2]\n",
      " [3 4 5]\n",
      " [6 7 8]]\n",
      "[0 1 2]\n",
      "[[ 0  2  4]\n",
      " [ 3  5  7]\n",
      " [ 6  8 10]]\n"
     ]
    }
   ],
   "source": [
    "# addiion of matrix and vector using broadcasting  \n",
    "mat = arange(9).reshape((3, 3))\n",
    "vec = arange(3)\n",
    "print(mat, vec, mat + vec,sep = '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if two arrays are equal \n",
    "mat1 = np.arange(9).reshape((3,3))\n",
    "mat2 = np.arange(9).reshape((3,3))\n",
    "np.allclose(mat1,mat2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of array:\n",
      " (3, 3)\n",
      "Covariance matrix of x:\n",
      " [[4.33333333 2.83333333 2.        ]\n",
      " [2.83333333 2.33333333 1.5       ]\n",
      " [2.         1.5        1.        ]]\n"
     ]
    }
   ],
   "source": [
    "# covariance :- \n",
    "\"\"\"\n",
    "Covariance provides the a measure of strength of correlation between two variable or more set of \n",
    "variables. The covariance matrix element Cij is the covariance of xi and xj. The element Cii is \n",
    "the variance of xi. \n",
    "If COV(xi, xj) = 0 then variables are uncorrelated\n",
    "If COV(xi, xj) > 0 then variables positively correlated\n",
    "If COV(xi, xj) > < 0 then variables negatively correlated\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "Covariance indicates the direction of the linear relationship between variables while correlation \n",
    "measures both the strength and direction of the linear relationship between two variables. \n",
    "Correlation is a function of the covariance\n",
    "\"\"\"\n",
    "x = np.array([[0, 3, 4], [1, 2, 4], [3, 4, 5]])\n",
    "print(\"Shape of array:\\n\", np.shape(x))\n",
    "print(\"Covariance matrix of x:\\n\", np.cov(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('upendra', 5.6, 65.23, 27) ('harindra', 5.7, 70.08, 34)] ('upendra', 5.6, 65.23, 27) ['upendra' 'harindra'] \n",
      " [('upendra', 27) ('harindra', 34)]\n",
      "[('harindra', 5.7, 70.08, 34) ('upendra', 5.6, 65.23, 27)]\n"
     ]
    }
   ],
   "source": [
    "# structured array(similar to c struct which has fields) \n",
    "person_data_def = [('name','U8'),('height','f8'),('weight','f8'), ('age', 'i8')]\n",
    "a = np.array([('upendra', 5.6, 65.23, 27), ('harindra', 5.7, 70.08, 34)], \n",
    "       dtype=person_data_def)\n",
    "print(a,a[0],a['name'],'\\n',a[['name','age']])\n",
    "# sort the struct using field \n",
    "print(np.sort(a,order = 'name'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  1  2  3  4]\n",
      " [ 5  6  7  8  9]\n",
      " [10 11 12 13 14]\n",
      " [15 16 17 18 19]\n",
      " [20 21 22 23 24]]\n",
      "sum of all elements in matrix 300\n",
      "column sum is [50 55 60 65 70] and row sum is [ 10  35  60  85 110]\n",
      "column cumsum is \n",
      " [[ 0  1  2  3  4]\n",
      " [ 5  7  9 11 13]\n",
      " [15 18 21 24 27]\n",
      " [30 34 38 42 46]\n",
      " [50 55 60 65 70]]  \n",
      " row cumsum is \n",
      " [[  0   1   3   6  10]\n",
      " [  5  11  18  26  35]\n",
      " [ 10  21  33  46  60]\n",
      " [ 15  31  48  66  85]\n",
      " [ 20  41  63  86 110]]\n",
      "variance is 0.7260848708543821 and std is 0.8521061382564863\n",
      "mean is 0.4357188239795602\n",
      "column mean is [10. 11. 12. 13. 14.] and row mean is [ 2.  7. 12. 17. 22.]\n",
      "Using nanmean function: 26.4\n",
      "difference b/w each element in [  1   7  19  37  61  91 127 169 217 271 331] is [ 6 12 18 24 30 36 42 48 54 60] and  difference b/w the prev is [6 6 6 6 6 6 6 6 6]\n"
     ]
    }
   ],
   "source": [
    "# universal functions(ufunc)\n",
    "mat = arange(25).reshape(5,5)\n",
    "print(mat)\n",
    "# column & row sum; same for min & max & prod\n",
    "print(f'sum of all elements in matrix {sum(mat)}')\n",
    "print(f'column sum is {mat.sum(axis = 0)} and row sum is {mat.sum(axis = 1)}')\n",
    "# cumulative sum \n",
    "print(f'column cumsum is \\n {mat.cumsum(axis = 0)}  \\n row cumsum is \\n {mat.cumsum(axis = 1)}')\n",
    "# variance, mean and std of array and matrix    \n",
    "normal_arr = random.randn(3)\n",
    "print(f'variance is {normal_arr.var()} and std is {sqrt(normal_arr.var())}')\n",
    "print(f'mean is {normal_arr.mean()}')\n",
    "print(f'column mean is {mat.mean(0)} and row mean is {mat.mean(1)}')\n",
    "\n",
    "# mean of an array ignoring missing values \n",
    "arr = np.array([[20, 15, 37], [47, 13, np.nan]])   \n",
    "print(\"Using nanmean function:\", np.nanmean(arr)) # other op like nanmax, nanmin can be done \n",
    "\n",
    "# difference b/w each element \n",
    "# we can even find the diff b/w diff by giving n = 2\n",
    "diff_array = np.array([1, 7, 19, 37, 61, 91, 127, 169, 217, 271, 331])\n",
    "print(f'difference b/w each element in {diff_array} is {np.diff(diff_array)} and  difference b/w the prev is {np.diff(diff_array, n = 2)}')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1   7  19  37  61  91 127 169 217 271]\n",
      "oops wrong assertion\n"
     ]
    }
   ],
   "source": [
    "# creating a ufunc \n",
    "def truncated_binomial(x):\n",
    "    return (x+1)**3 - (x)**3\n",
    "test_array = np.arange(10)\n",
    "# pass array to new u func created  \n",
    "print(truncated_binomial(test_array))\n",
    "# assertions on ufunc \n",
    "try:\n",
    "    np.testing.assert_equal(truncated_binomial(4), 65)\n",
    "except AssertionError:\n",
    "    print('oops wrong assertion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1.] [0 0 0 0 1 2]\n"
     ]
    }
   ],
   "source": [
    "# creating a custom broadcasting function \n",
    "v = arange(-3, 3)\n",
    "nv = array([-1, nan, 1])\n",
    "@np.vectorize\n",
    "def isneg(n):\n",
    "    return np.isnan(n) or n < 0\n",
    "nv[isneg(nv)] = 0\n",
    "v[isneg(v)] = 0\n",
    "print(nv,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2,  3,  4],\n",
       "       [ 5,  6,  7,  8,  9],\n",
       "       [10, 11, 12, 13, 14],\n",
       "       [15, 16, 17, 18, 19],\n",
       "       [20, 21, 22, 23, 24]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dumping a numpy matrix to a pickle(binary)\n",
    "import pickle\n",
    "pickle.loads(mat.dumps())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  4 26 66 22 42 62 66 48 93]\n",
      "max 93\n",
      "max index 9\n",
      "Using nanmin function: 13.0\n",
      "1.0 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.51659813,  0.01515307,  0.53616721, -0.26981026,  1.98314362,\n",
       "        0.95496967, -0.72643885,  0.6349141 ,  0.12169733,  0.78847373])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# universal functions contd\n",
    "arr = random.randint(0,100,10)\n",
    "print(arr)\n",
    "print('max',arr.max())# same for min \n",
    "print('max index',arr.argmax())\n",
    "# min of an array ignoring missing values; same for max \n",
    "arr = np.array([[20, 15, 37], [47, 13, np.nan]])   \n",
    "print(\"Using nanmin function:\", np.nanmin(arr))\n",
    "# sin 90\n",
    "print(sin(pi/2),'\\n')\n",
    "# max b/w two array elements\n",
    "# Return a sample from the \"standard normal\" distribution.\n",
    "A = np.random.randn(10)\n",
    "B = np.random.randn(10)\n",
    "np.maximum(A,B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  1  2]\n",
      " [ 3  4  5]\n",
      " [ 6  7  8]\n",
      " [ 9 10 11]] \n",
      "\n",
      "[[ 0  1  2  6  7  8]\n",
      " [ 3  4  5  9 10 11]] \n",
      "\n",
      "[1 2 3 4 5 6] \n",
      "\n",
      "\n",
      "\n",
      "[[1 2 3]\n",
      " [4 5 6]]\n"
     ]
    }
   ],
   "source": [
    "# concatenating 2 matrices using h and v stack \n",
    "arr1 = array(([0,1,2],[3,4,5]))\n",
    "arr2 = array(([6,7,8],[9,10,11]))\n",
    "print(vstack((arr1,arr2)),'\\n')\n",
    "print(hstack((arr1,arr2)),'\\n')\n",
    "# concatenating 2 vectors \n",
    "print(hstack((array([1,2,3]),array([4,5,6]))),'\\n')\n",
    "print('\\n')\n",
    "print(vstack((array([1,2,3]),array([4,5,6]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 2]\n",
      " [3 4 5]\n",
      " [6 7 8]] \n",
      "\n",
      "[array([[0],\n",
      "       [3],\n",
      "       [6]]), array([[1],\n",
      "       [4],\n",
      "       [7]]), array([[2],\n",
      "       [5],\n",
      "       [8]])] \n",
      "\n",
      "[array([[0, 1, 2]]), array([[3, 4, 5]]), array([[6, 7, 8]])] \n",
      "\n",
      "[[[ 0  1  2]\n",
      "  [ 3  4  5]\n",
      "  [ 6  7  8]]\n",
      "\n",
      " [[ 9 10 11]\n",
      "  [12 13 14]\n",
      "  [15 16 17]]\n",
      "\n",
      " [[18 19 20]\n",
      "  [21 22 23]\n",
      "  [24 25 26]]] \n",
      "\n",
      "[array([[[ 0],\n",
      "        [ 3],\n",
      "        [ 6]],\n",
      "\n",
      "       [[ 9],\n",
      "        [12],\n",
      "        [15]],\n",
      "\n",
      "       [[18],\n",
      "        [21],\n",
      "        [24]]]), array([[[ 1],\n",
      "        [ 4],\n",
      "        [ 7]],\n",
      "\n",
      "       [[10],\n",
      "        [13],\n",
      "        [16]],\n",
      "\n",
      "       [[19],\n",
      "        [22],\n",
      "        [25]]]), array([[[ 2],\n",
      "        [ 5],\n",
      "        [ 8]],\n",
      "\n",
      "       [[11],\n",
      "        [14],\n",
      "        [17]],\n",
      "\n",
      "       [[20],\n",
      "        [23],\n",
      "        [26]]])]\n"
     ]
    }
   ],
   "source": [
    "# splitting a matrix using h and v split \n",
    "num = np.arange(9).reshape((3,3))\n",
    "print(num,'\\n')\n",
    "print(hsplit(num,3),'\\n')\n",
    "print(vsplit(num,3),'\\n')\n",
    "num2 = np.arange(27).reshape((3,3,3))\n",
    "print(num2,'\\n')\n",
    "# depth wise split in a 3d array\n",
    "print(dsplit(num2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 6,  7,  8,  9, 10, 11]), array([20., 15., 37., 47., 13., nan]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# flatten a matrix into an array \n",
    "arr2.flatten(), arr.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 2]\n",
      " [3 4 5]\n",
      " [6 7 8]] \n",
      "\n",
      " [[2 1 0]\n",
      " [5 4 3]\n",
      " [8 7 6]] \n",
      "\n",
      " [[6 7 8]\n",
      " [3 4 5]\n",
      " [0 1 2]] \n",
      "\n",
      " [[6 7 8]\n",
      " [0 1 2]\n",
      " [3 4 5]] \n",
      "\n",
      " [[2 0 1]\n",
      " [5 3 4]\n",
      " [8 6 7]] \n",
      "\n",
      " [[3 4 5]\n",
      " [6 7 8]\n",
      " [0 1 2]] \n",
      "\n",
      " [[1 2 0]\n",
      " [4 5 3]\n",
      " [7 8 6]]\n"
     ]
    }
   ],
   "source": [
    "# rearrange \n",
    "# flip the array both col(left right) and row wise(up down) and roll(shift by places, also in reverse(-1))\n",
    "num = np.arange(9).reshape((3,3))\n",
    "print(num,'\\n\\n',np.flip(num,1),'\\n\\n',np.flip(num,0),'\\n\\n',\n",
    "      np.roll(num,1,0),'\\n\\n',np.roll(num,1,1),'\\n\\n',np.roll(num,-1,0),'\\n\\n',np.roll(num,-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output of bincount is for the bin [0, 1, 2, 3, 4, 5, 6, 7, 8] : [0 2 2 0 0 1 1 0 3]\n"
     ]
    }
   ],
   "source": [
    "# numpy bin count \n",
    "inp_arr = np.array([1, 2, 5, 6, 2, 1, 8, 8, 8])\n",
    "x = np.bincount(inp_arr)\n",
    "print(f\"Output of bincount is for the bin {[0,1,2,3,4,5,6,7,8]} :\", x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 6],\n",
       "       [2, 4, 7],\n",
       "       [0, 8, 9]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sort the array \n",
    "sorted(list(array([5,1,2,7,9])))\n",
    "mat_sort = array(([2,6,1],[7,2,4],[8,9,0]))\n",
    "mat_sort.sort(axis = 1)\n",
    "mat_sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save npy and npz files\n",
    "arr = np.arange(5)\n",
    "# npy\n",
    "np.save('data/my_array',arr)\n",
    "print(np.load('data/my_array.npy'))\n",
    "#npz\n",
    "np.savez('data/two_arrays.npz',x=arr,y=arr, z=arr)\n",
    "archive_array = np.load('data/two_arrays.npz')\n",
    "archive_array['z']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2. 6. 1.]\n",
      " [7. 2. 4.]\n",
      " [8. 9. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# read and write numpy arrays to a csv file\n",
    "data = array(([2,6,1],[7,2,4],[8,9,0]))\n",
    "np.savetxt('data/npdata.csv', data, delimiter=',')\n",
    "data_read = np.loadtxt('data/npdata.csv', delimiter=',')\n",
    "# print the array\n",
    "print(data_read)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  1  2  3  4]\n",
      " [ 5  6  7  8  9]\n",
      " [10 11 12 13 14]\n",
      " [15 16 17 18 19]\n",
      " [20 21 22 23 24]]\n",
      "\n",
      "\n",
      "[[ 0  5 10 15 20]\n",
      " [ 1  6 11 16 21]\n",
      " [ 2  7 12 17 22]\n",
      " [ 3  8 13 18 23]\n",
      " [ 4  9 14 19 24]]\n",
      "\n",
      " [[[ 0  1]\n",
      "  [ 2  3]\n",
      "  [ 4  5]\n",
      "  [ 6  7]\n",
      "  [ 8  9]]\n",
      "\n",
      " [[10 11]\n",
      "  [12 13]\n",
      "  [14 15]\n",
      "  [16 17]\n",
      "  [18 19]]\n",
      "\n",
      " [[20 21]\n",
      "  [22 23]\n",
      "  [24 25]\n",
      "  [26 27]\n",
      "  [28 29]]\n",
      "\n",
      " [[30 31]\n",
      "  [32 33]\n",
      "  [34 35]\n",
      "  [36 37]\n",
      "  [38 39]]\n",
      "\n",
      " [[40 41]\n",
      "  [42 43]\n",
      "  [44 45]\n",
      "  [46 47]\n",
      "  [48 49]]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[ 0,  1],\n",
       "        [10, 11],\n",
       "        [20, 21],\n",
       "        [30, 31],\n",
       "        [40, 41]],\n",
       "\n",
       "       [[ 2,  3],\n",
       "        [12, 13],\n",
       "        [22, 23],\n",
       "        [32, 33],\n",
       "        [42, 43]],\n",
       "\n",
       "       [[ 4,  5],\n",
       "        [14, 15],\n",
       "        [24, 25],\n",
       "        [34, 35],\n",
       "        [44, 45]],\n",
       "\n",
       "       [[ 6,  7],\n",
       "        [16, 17],\n",
       "        [26, 27],\n",
       "        [36, 37],\n",
       "        [46, 47]],\n",
       "\n",
       "       [[ 8,  9],\n",
       "        [18, 19],\n",
       "        [28, 29],\n",
       "        [38, 39],\n",
       "        [48, 49]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# matrix transpose \n",
    "print(mat)\n",
    "print('\\n')\n",
    "print(mat.T)\n",
    "\n",
    "# tranpose a 3d matrices \n",
    "arr3d = np.arange(50).reshape((5,5,2))\n",
    "print('\\n',arr3d)\n",
    "arr3d.transpose((1,0,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 5, 2, 2) (2, 3, 5, 2)\n"
     ]
    }
   ],
   "source": [
    "# swap axes  and roll axes back\n",
    "swap = np.arange(60).reshape(2,5,2,3)\n",
    "print(np.swapaxes(swap,3,0).shape , np.rollaxis(swap,3,1).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  1  2  3  4]\n",
      " [ 0  1  2  3  4]\n",
      " [ 5  6  7  8  9]\n",
      " [ 5  6  7  8  9]\n",
      " [10 11 12 13 14]\n",
      " [10 11 12 13 14]\n",
      " [15 16 17 18 19]\n",
      " [15 16 17 18 19]\n",
      " [20 21 22 23 24]\n",
      " [20 21 22 23 24]] \n",
      "\n",
      " [[ 0  0  1  1  2  2  3  3  4  4]\n",
      " [ 5  5  6  6  7  7  8  8  9  9]\n",
      " [10 10 11 11 12 12 13 13 14 14]\n",
      " [15 15 16 16 17 17 18 18 19 19]\n",
      " [20 20 21 21 22 22 23 23 24 24]]\n"
     ]
    }
   ],
   "source": [
    "# repeat row and col wise \n",
    "num = np.arange(25).reshape((5,5))\n",
    "print(np.repeat(num,2,axis = 0), '\\n\\n', np.repeat(num,2,axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  1  2  3  4]\n",
      " [ 5  6  7  8  9]\n",
      " [10 11 12 13 14]\n",
      " [15 16 17 18 19]\n",
      " [20 21 22 23 24]] \n",
      "\n",
      "[[ 0  2  4  6  8]\n",
      " [10 12 14 16 18]\n",
      " [20 22 24 26 28]\n",
      " [30 32 34 36 38]\n",
      " [40 42 44 46 48]]\n"
     ]
    }
   ],
   "source": [
    "# matrix addition\n",
    "print(mat,'\\n')\n",
    "print(mat + mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  30   80  130  180  230]\n",
      " [  80  255  430  605  780]\n",
      " [ 130  430  730 1030 1330]\n",
      " [ 180  605 1030 1455 1880]\n",
      " [ 230  780 1330 1880 2430]] \n",
      "\n",
      "[[  30   80  130  180  230]\n",
      " [  80  255  430  605  780]\n",
      " [ 130  430  730 1030 1330]\n",
      " [ 180  605 1030 1455 1880]\n",
      " [ 230  780 1330 1880 2430]] \n",
      "\n",
      "[[  30   80  130  180  230]\n",
      " [  80  255  430  605  780]\n",
      " [ 130  430  730 1030 1330]\n",
      " [ 180  605 1030 1455 1880]\n",
      " [ 230  780 1330 1880 2430]]\n"
     ]
    }
   ],
   "source": [
    "# matrix dot product(matrix multiplication) \n",
    "print(mat.dot(mat.T),'\\n')\n",
    "print(mat @ mat.T,'\\n')\n",
    "print(np.matmul(mat,mat.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-2.   1. ]\n",
      " [ 1.5 -0.5]]\n"
     ]
    }
   ],
   "source": [
    "# inverse matrix(applied only on square matrices with same no of rows and cols) \n",
    "x = array([[1,2],[3,4]]) \n",
    "print(linalg.inv(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "# sum the diagonal elements from left to right \n",
    "x = array([[1,2],[3,4]]) \n",
    "print(np.trace(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main Diagonal elements : \n",
      " [  1 434  56] \n",
      "\n",
      "Diagonal above main diagonal : \n",
      " [21  3] \n",
      "\n",
      "Diagonal below main diagonal : \n",
      " [63 54]\n"
     ]
    }
   ],
   "source": [
    "# matrix diagonal values\n",
    "a = np.matrix([[1, 21, 30],\n",
    "                 [63 ,434, 3],\n",
    "                 [54, 54, 56]])\n",
    "print(\"Main Diagonal elements : \\n\", np.diag(a), \"\\n\")\n",
    "print(\"Diagonal above main diagonal : \\n\", np.diag(a, 1), \"\\n\")\n",
    "print(\"Diagonal below main diagonal : \\n\", np.diag(a, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3. 1.]\n",
      "[[ 0.70710678 -0.70710678]\n",
      " [ 0.70710678  0.70710678]]\n"
     ]
    }
   ],
   "source": [
    "# eigen vector and value \n",
    "A = np.array([[2,1],\n",
    "              [1,2]])\n",
    "\n",
    "eVals, eVecs = np.linalg.eig(A)\n",
    "print(eVals)\n",
    "print(eVecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([(b'Aakash', 2009, 9. ), (b'Ajay', 2008, 8.7),\n",
       "       (b'Hrithik', 2009, 8.5), (b'Pankaj', 2008, 7.9)],\n",
       "      dtype=[('name', 'S10'), ('grad_year', '<i8'), ('cgpa', '<f8')])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# structured array and sorting \n",
    "dtypes = [('name', 'S10'), ('grad_year', int), ('cgpa', float)] \n",
    "values = [('Hrithik', 2009, 8.5), ('Ajay', 2008, 8.7),  \n",
    "           ('Pankaj', 2008, 7.9), ('Aakash', 2009, 9.0)] \n",
    "struct_arr = array(values,dtypes)\n",
    "struct_arr.sort(order='name')\n",
    "struct_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['Bob', 'Joe', 'Will'], dtype='<U4'), array([2, 3, 2]))"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unique values\n",
    "names = array(['Bob', 'Joe', 'Will', 'Bob', 'Will', 'Joe', 'Joe'])\n",
    "unique(names,return_counts = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric Representation : \n",
      " [1 3 3 2 0 2 0 1]\n",
      "Unique Values : \n",
      " ['a' 'b' 'c' 'd']\n"
     ]
    }
   ],
   "source": [
    "# get the numeric representation of an array by identifying distinct values\n",
    "labels, uniques = pd.factorize(['b', 'd', 'd', 'c', 'a', 'c', 'a', 'b'], sort = True)\n",
    "print(\"Numeric Representation : \\n\", labels)\n",
    "print(\"Unique Values : \\n\", uniques)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2015-02-03', '2015-02-10', '2015-02-17', '2015-02-24'],\n",
       "      dtype='datetime64[D]')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# time series\n",
    "arange('2015-02-03', '2015-03-01', 7, dtype='datetime64[D]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('stations.txt', <http.client.HTTPMessage at 0x7f91f4398128>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generating numpy array from a txt file \n",
    "import urllib.request\n",
    "urllib.request.urlretrieve('https://www1.ncdc.noaa.gov/pub/data/ghcn/daily/readme.txt',\n",
    "                           'readme.txt')\n",
    "urllib.request.urlretrieve('https://www1.ncdc.noaa.gov/pub/data/ghcn/daily/ghcnd-stations.txt',\n",
    "                           'stations.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([('ACW00011604',  17.1167, -61.7833,   10.1, '', 'ST JOHNS COOLIDGE FLD', '', '', ''),\n",
       "       ('ACW00011647',  17.1333, -61.7833,   19.2, '', 'ST JOHNS', '', '', ''),\n",
       "       ('AE000041196',  25.333 ,  55.517 ,   34. , '', 'SHARJAH INTER. AIRP', 'GSN', '', '41196'),\n",
       "       ...,\n",
       "       ('ZI000067977', -21.017 ,  31.583 ,  430. , '', 'BUFFALO RANGE', '', '', '67977'),\n",
       "       ('ZI000067983', -20.2   ,  32.616 , 1132. , '', 'CHIPINGE', 'GSN', '', '67983'),\n",
       "       ('ZI000067991', -22.217 ,  30.    ,  457. , '', 'BEITBRIDGE', '', '', '67991')],\n",
       "      dtype=[('id', '<U11'), ('latitude', '<f8'), ('longitude', '<f8'), ('elevation', '<f8'), ('state', '<U3'), ('name', '<U31'), ('gsn', '<U4'), ('hcn', '<U4'), ('wmo', '<U6')])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can give space b/w cols and even names to the cols along with their types\n",
    "stations = np.genfromtxt('stations.txt', delimiter=[11,9,10,7,3,31,4,4,6],\n",
    "                                         names=['id','latitude','longitude','elevation','state','name',\n",
    "                                                'gsn','hcn','wmo'],\n",
    "                                         dtype=['U11','d','d','d','U3','U31','U4','U4','U6'],\n",
    "                                         autostrip=True)\n",
    "stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([('USC00046719', 34.1483, -118.1447, 263.3, 'CA', 'PASADENA', '', 'HCN', '')],\n",
       "      dtype=[('id', '<U11'), ('latitude', '<f8'), ('longitude', '<f8'), ('elevation', '<f8'), ('state', '<U3'), ('name', '<U31'), ('gsn', '<U4'), ('hcn', '<U4'), ('wmo', '<U6')])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can do selection based on col name given above \n",
    "stations[stations['name'] == 'PASADENA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 5, 2, 4, 1])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# return the indices of sorted values in the unsorted array\n",
    "unsorted_array = array([1,5,3,6,4,2,7]) \n",
    "sorted_array = unsorted_array.argsort()[:5]\n",
    "sorted_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'china': 58, 'india': 40, 'uk': 60, 'usa': 23}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# group by operations using numpy \n",
    "countries = np.array(['india', 'uk', 'india', 'uk', 'china', 'usa', 'china', 'china'])\n",
    "deaths = np.array([10,20, 30, 40, 1, 23, 56, 1])\n",
    "unique_countries = np.unique(countries)\n",
    "dict([(country, deaths[countries==country].sum()) for country in unique_countries])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arr :  [20, 2, 7, 1, 34]\n",
      "50th percentile of arr :  7.0\n",
      "25th percentile of arr :  2.0\n",
      "75th percentile of arr :  20.0\n"
     ]
    }
   ],
   "source": [
    "# percentile\n",
    "# 1D array\n",
    "arr = [20, 2, 7, 1, 34]\n",
    "print(\"arr : \", arr)\n",
    "print(\"50th percentile of arr : \",\n",
    "       np.percentile(arr, 50))\n",
    "print(\"25th percentile of arr : \",\n",
    "       np.percentile(arr, 25))\n",
    "print(\"75th percentile of arr : \",\n",
    "       np.percentile(arr, 75))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         3          2\n",
      "0.08704 x - 0.8135 x + 1.693 x - 0.03968\n"
     ]
    }
   ],
   "source": [
    "# linear regression in numpy \n",
    "x = np.array([0.0, 1.0, 2.0, 3.0,  4.0,  5.0])\n",
    "y = np.array([0.0, 0.8, 0.9, 0.1, -0.8, -1.0])\n",
    "f = np.polyfit(x, y, 3) # polynomial \n",
    "print(np.poly1d(f)) #print the fitted function "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "pd.options.display.float_format = '{:,.2f}'.format # global pandas settings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# series \n",
    "# has data with labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name               upendra\n",
       "company       robert bosch\n",
       "university             dsu\n",
       "location         bangalore\n",
       "age                     26\n",
       "dtype: object"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = array(['upendra','robert bosch','dsu','bangalore',26])\n",
    "# labels or indexes \n",
    "labels = ['name','company','university','location','age']\n",
    "ser1 = pd.Series(arr,labels)\n",
    "ser1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name          upendra\n",
       "location    bangalore\n",
       "age                26\n",
       "dtype: object"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# indexing \n",
    "ser1[['name','location','age']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name          upendra\n",
       "university        dsu\n",
       "age                26\n",
       "dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# slicing\n",
    "ser1['name':'age':2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name          upendra\n",
       "university        dsu\n",
       "age                26\n",
       "dtype: object"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# indexing and slicing using iloc\n",
    "ser1.iloc[0:5:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name    upendra\n",
       "dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# conditional selection \n",
    "ser1[ser1.str.startswith('u')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name         object\n",
      "Team         object\n",
      "Number      float64\n",
      "Position     object\n",
      "Age         float64\n",
      "Height       object\n",
      "Weight      float64\n",
      "College      object\n",
      "Salary      float64\n",
      "dtype: object \n",
      "\n",
      "              Name            Team Position Height            College\n",
      "0    Avery Bradley  Boston Celtics       PG    6-2              Texas\n",
      "1      Jae Crowder  Boston Celtics       SF    6-6          Marquette\n",
      "2     John Holland  Boston Celtics       SG    6-5  Boston University\n",
      "3      R.J. Hunter  Boston Celtics       SG    6-5      Georgia State\n",
      "4    Jonas Jerebko  Boston Celtics       PF   6-10                NaN\n",
      "..             ...             ...      ...    ...                ...\n",
      "453   Shelvin Mack       Utah Jazz       PG    6-3             Butler\n",
      "454      Raul Neto       Utah Jazz       PG    6-1                NaN\n",
      "455   Tibor Pleiss       Utah Jazz        C    7-3                NaN\n",
      "456    Jeff Withey       Utah Jazz        C    7-0             Kansas\n",
      "457            NaN             NaN      NaN    NaN                NaN\n",
      "\n",
      "[458 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# selecting based on data type \n",
    "nba = pd.read_csv(\"data/nba.csv\")\n",
    "print(nba.dtypes,'\\n')\n",
    "print(nba.select_dtypes(include ='object'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a      90.00\n",
      "b     -39.00\n",
      "c   8,888.00\n",
      "dtype: float64 \n",
      "\n",
      "a      50.00\n",
      "b     -14.50\n",
      "c   4,449.00\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# operations, broadcasting\n",
    "my_dictionary = {'a' : 45., 'b' : -19.5, 'c' : 4444}\n",
    "my_series = pd.Series(my_dictionary)\n",
    "print(my_series + my_series,'\\n')\n",
    "print(my_series + 5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     3\n",
       "1    11\n",
       "2    13\n",
       "3    17\n",
       "4    19\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# operation on series\n",
    "pd.Series([1,5,6,8,9]) + pd.Series([2,6,7,9,10]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3\n",
       "1    2\n",
       "2    1\n",
       "3    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sort a series \n",
    "arr = array(['upendra','robert bosch','dsu','bangalore'])\n",
    "# labels or indexes \n",
    "labels = ['name','company','university','location']\n",
    "ser1 = pd.Series(arr,labels)\n",
    "ser1.argsort().reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe \n",
    "# has indexes and columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>squares</th>\n",
       "      <th>cubes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1st</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2nd</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3rd</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4th</th>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5th</th>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6th</th>\n",
       "      <td>6</td>\n",
       "      <td>36</td>\n",
       "      <td>216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7th</th>\n",
       "      <td>7</td>\n",
       "      <td>49</td>\n",
       "      <td>343</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     number  squares  cubes\n",
       "1st       1        1      1\n",
       "2nd       2        4      8\n",
       "3rd       3        9     27\n",
       "4th       4       16     64\n",
       "5th       5       25    125\n",
       "6th       6       36    216\n",
       "7th       7       49    343"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data frame from 2d array \n",
    "array = array([[1, 1, 1], [2, 4, 8], [3, 9, 27], \n",
    "                  [4, 16, 64], [5, 25, 125], [6, 36, 216], \n",
    "                  [7, 49, 343]])  \n",
    "# creating a list of index names\n",
    "# for numerical indexes we can use arange \n",
    "index_values = ['1st', '2nd', '3rd',\n",
    "                '4th', '5th', '6th', '7th'] \n",
    "# creating a list of column names\n",
    "column_values = ['number', 'squares', 'cubes']\n",
    "# creating the dataframe\n",
    "df = pd.DataFrame(data = array, \n",
    "                  index = index_values, \n",
    "                  columns = column_values)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 3 2 21 (7, 3) [Index(['1st', '2nd', '3rd', '4th', '5th', '6th', '7th'], dtype='object'), Index(['number', 'squares', 'cubes'], dtype='object')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "number     int64\n",
       "squares    int64\n",
       "cubes      int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many no of rows and columns \n",
    "print(len(df.index),len(df.columns), df.ndim, df.size, df.shape, df.axes)\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>squares</th>\n",
       "      <th>cubes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>first</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>second</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>third</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fourth</th>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fifth</th>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sixth</th>\n",
       "      <td>6</td>\n",
       "      <td>36</td>\n",
       "      <td>216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seventh</th>\n",
       "      <td>7</td>\n",
       "      <td>49</td>\n",
       "      <td>343</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         number  squares  cubes\n",
       "first         1        1      1\n",
       "second        2        4      8\n",
       "third         3        9     27\n",
       "fourth        4       16     64\n",
       "fifth         5       25    125\n",
       "sixth         6       36    216\n",
       "seventh       7       49    343"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reindex \n",
    "index_values = ['first', 'second', 'third',\n",
    "                'fourth', 'fifth', 'sixth', 'seventh'] \n",
    "df.index = index_values\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating dataframe from series\n",
    "points = {'player1': pd.Series([15, 10, 20, 25], \n",
    "                               index=['game1', 'game2', 'game3', 'game4']),\n",
    "         'player2': pd.Series([10, 15, 23, 27],\n",
    "                             index=['game1', 'game2', 'game3', 'game4'])}\n",
    "data = pd.DataFrame(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "game1    10\n",
       "game2    15\n",
       "game3    23\n",
       "Name: player2, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# indexing without loc and iloc \n",
    "data[0:3][\"player2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>letter</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>city</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LA</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SF</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "letter  A  B  C  D\n",
       "city              \n",
       "LA      0  1  2  3\n",
       "SF      4  5  6  7"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating df with index and col names\n",
    "dframe1 = pd.DataFrame(np.arange(8).reshape((2, 4)),\n",
    "                 index=pd.Index(['LA', 'SF'], name='city'),\n",
    "                 columns=pd.Index(['A', 'B', 'C','D'], name='letter'))\n",
    "#Show\n",
    "dframe1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'number': {'first': 1, 'second': 2, 'third': 3, 'fourth': 4, 'fifth': 5, 'sixth': 6, 'seventh': 7}, 'squares': {'first': 1, 'second': 4, 'third': 9, 'fourth': 16, 'fifth': 25, 'sixth': 36, 'seventh': 49}, 'cubes': {'first': 1, 'second': 8, 'third': 27, 'fourth': 64, 'fifth': 125, 'sixth': 216, 'seventh': 343}} \n",
      "\n",
      "[[  1   1   1]\n",
      " [  2   4   8]\n",
      " [  3   9  27]\n",
      " [  4  16  64]\n",
      " [  5  25 125]\n",
      " [  6  36 216]\n",
      " [  7  49 343]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# to_dict and numpy\n",
    "print(df.to_dict(),'\\n')\n",
    "print(df.to_numpy(),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year  discipline                      nobelist\n",
      "0  1901   Chemistry  Jacobus Henricus van 't Hoff\n",
      "1  1901  Literature               Sully Prudhomme\n",
      "2  1901    Medicine        Emil Adolf von Behring\n",
      "3  1901       Peace                Frédéric Passy\n",
      "4  1901       Peace                  Henry Dunant \n",
      "\n",
      "      discipline                      nobelist\n",
      "year                                          \n",
      "1901   Chemistry  Jacobus Henricus van 't Hoff\n",
      "1901  Literature               Sully Prudhomme\n",
      "1901    Medicine        Emil Adolf von Behring\n",
      "1901       Peace                Frédéric Passy\n",
      "1901       Peace                  Henry Dunant\n"
     ]
    }
   ],
   "source": [
    "# setting index based on csv column \n",
    "nobels = pd.read_csv('data/nobels.csv', names=['year','discipline','nobelist'])\n",
    "nobels_by_year = nobels.set_index('year')\n",
    "print(nobels.head(),'\\n')\n",
    "print(nobels_by_year.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            year                      nobelist\n",
      "discipline                                    \n",
      "Chemistry   1901  Jacobus Henricus van 't Hoff\n",
      "Chemistry   1988                  Robert Huber\n",
      "Chemistry   1932               Irving Langmuir\n",
      "Chemistry   1988            Johann Deisenhofer\n",
      "Chemistry   1988                Hartmut Michel \n",
      "\n",
      "   discipline                      nobelist  year\n",
      "0   Chemistry  Jacobus Henricus van 't Hoff  1901\n",
      "1  Literature               Sully Prudhomme  1901\n",
      "2    Medicine        Emil Adolf von Behring  1901\n",
      "3       Peace                Frédéric Passy  1901\n",
      "4       Peace                  Henry Dunant  1901\n"
     ]
    }
   ],
   "source": [
    "# sort the data frame based on the index\n",
    "print(nobels.set_index('discipline').sort_index().head(),'\\n')\n",
    "# sort the data frame based on the col names\n",
    "print(nobels.sort_index(axis = 1).head()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>i</th>\n",
       "      <td>upendra</td>\n",
       "      <td>26</td>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ii</th>\n",
       "      <td>harindra</td>\n",
       "      <td>33</td>\n",
       "      <td>teaching</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iii</th>\n",
       "      <td>lalitha</td>\n",
       "      <td>30</td>\n",
       "      <td>house wife</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iv</th>\n",
       "      <td>arjun</td>\n",
       "      <td>3</td>\n",
       "      <td>play</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v</th>\n",
       "      <td>pops</td>\n",
       "      <td>62</td>\n",
       "      <td>bank retd</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         name  age         job\n",
       "i     upendra   26          it\n",
       "ii   harindra   33    teaching\n",
       "iii   lalitha   30  house wife\n",
       "iv      arjun    3        play\n",
       "v        pops   62   bank retd"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating dataframe from dict of lists \n",
    "data = {\n",
    "    'name': ['upendra','harindra','lalitha','arjun','pops'],\n",
    "    'age' : [26,33,30,3,62],\n",
    "    'job' : ['it','teaching','house wife','play','bank retd']\n",
    "    }\n",
    "df = pd.DataFrame(data,index=['i','ii','iii','iv','v'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['i', 'ii', 'iii', 'iv', 'v'], dtype='object') \n",
      " [['upendra' 26 'it']\n",
      " ['harindra' 33 'teaching']\n",
      " ['lalitha' 30 'house wife']\n",
      " ['arjun' 3 'play']\n",
      " ['pops' 62 'bank retd']] \n",
      " Index(['name', 'age', 'job'], dtype='object')\n",
      "Index(['i', 'iii', 'v'], dtype='object') Index(['name', 'age'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# index, values and columns  \n",
    "print(df.index, '\\n', df.values, '\\n', df.columns)\n",
    "# iterating through index and columns using range  \n",
    "print(df.index[range(0,5,2)], df.columns[range(2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# broadcasting \n",
    "df['family'] = 'badarvada'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_eaccbb98_50fd_11ec_b602_a860b6024b00row4_col1 {\n",
       "            background-color:  yellow;\n",
       "        }</style><table id=\"T_eaccbb98_50fd_11ec_b602_a860b6024b00\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >name</th>        <th class=\"col_heading level0 col1\" >age</th>        <th class=\"col_heading level0 col2\" >job</th>        <th class=\"col_heading level0 col3\" >family</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_eaccbb98_50fd_11ec_b602_a860b6024b00level0_row0\" class=\"row_heading level0 row0\" >i</th>\n",
       "                        <td id=\"T_eaccbb98_50fd_11ec_b602_a860b6024b00row0_col0\" class=\"data row0 col0\" >upendra</td>\n",
       "                        <td id=\"T_eaccbb98_50fd_11ec_b602_a860b6024b00row0_col1\" class=\"data row0 col1\" >26</td>\n",
       "                        <td id=\"T_eaccbb98_50fd_11ec_b602_a860b6024b00row0_col2\" class=\"data row0 col2\" >it</td>\n",
       "                        <td id=\"T_eaccbb98_50fd_11ec_b602_a860b6024b00row0_col3\" class=\"data row0 col3\" >badarvada</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_eaccbb98_50fd_11ec_b602_a860b6024b00level0_row1\" class=\"row_heading level0 row1\" >ii</th>\n",
       "                        <td id=\"T_eaccbb98_50fd_11ec_b602_a860b6024b00row1_col0\" class=\"data row1 col0\" >harindra</td>\n",
       "                        <td id=\"T_eaccbb98_50fd_11ec_b602_a860b6024b00row1_col1\" class=\"data row1 col1\" >33</td>\n",
       "                        <td id=\"T_eaccbb98_50fd_11ec_b602_a860b6024b00row1_col2\" class=\"data row1 col2\" >teaching</td>\n",
       "                        <td id=\"T_eaccbb98_50fd_11ec_b602_a860b6024b00row1_col3\" class=\"data row1 col3\" >badarvada</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_eaccbb98_50fd_11ec_b602_a860b6024b00level0_row2\" class=\"row_heading level0 row2\" >iii</th>\n",
       "                        <td id=\"T_eaccbb98_50fd_11ec_b602_a860b6024b00row2_col0\" class=\"data row2 col0\" >lalitha</td>\n",
       "                        <td id=\"T_eaccbb98_50fd_11ec_b602_a860b6024b00row2_col1\" class=\"data row2 col1\" >30</td>\n",
       "                        <td id=\"T_eaccbb98_50fd_11ec_b602_a860b6024b00row2_col2\" class=\"data row2 col2\" >house wife</td>\n",
       "                        <td id=\"T_eaccbb98_50fd_11ec_b602_a860b6024b00row2_col3\" class=\"data row2 col3\" >badarvada</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_eaccbb98_50fd_11ec_b602_a860b6024b00level0_row3\" class=\"row_heading level0 row3\" >iv</th>\n",
       "                        <td id=\"T_eaccbb98_50fd_11ec_b602_a860b6024b00row3_col0\" class=\"data row3 col0\" >arjun</td>\n",
       "                        <td id=\"T_eaccbb98_50fd_11ec_b602_a860b6024b00row3_col1\" class=\"data row3 col1\" >3</td>\n",
       "                        <td id=\"T_eaccbb98_50fd_11ec_b602_a860b6024b00row3_col2\" class=\"data row3 col2\" >play</td>\n",
       "                        <td id=\"T_eaccbb98_50fd_11ec_b602_a860b6024b00row3_col3\" class=\"data row3 col3\" >badarvada</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_eaccbb98_50fd_11ec_b602_a860b6024b00level0_row4\" class=\"row_heading level0 row4\" >v</th>\n",
       "                        <td id=\"T_eaccbb98_50fd_11ec_b602_a860b6024b00row4_col0\" class=\"data row4 col0\" >pops</td>\n",
       "                        <td id=\"T_eaccbb98_50fd_11ec_b602_a860b6024b00row4_col1\" class=\"data row4 col1\" >62</td>\n",
       "                        <td id=\"T_eaccbb98_50fd_11ec_b602_a860b6024b00row4_col2\" class=\"data row4 col2\" >bank retd</td>\n",
       "                        <td id=\"T_eaccbb98_50fd_11ec_b602_a860b6024b00row4_col3\" class=\"data row4 col3\" >badarvada</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fc704427c88>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pandas styling \n",
    "df.style.highlight_max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_eb74ba58_50fd_11ec_8731_a860b6024b00row0_col1 {\n",
       "            background-color: orange;\n",
       "        }    #T_eb74ba58_50fd_11ec_8731_a860b6024b00row1_col1 {\n",
       "            background-color: orange;\n",
       "        }    #T_eb74ba58_50fd_11ec_8731_a860b6024b00row2_col1 {\n",
       "            background-color: orange;\n",
       "        }    #T_eb74ba58_50fd_11ec_8731_a860b6024b00row4_col1 {\n",
       "            background-color: orange;\n",
       "        }</style><table id=\"T_eb74ba58_50fd_11ec_8731_a860b6024b00\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >name</th>        <th class=\"col_heading level0 col1\" >age</th>        <th class=\"col_heading level0 col2\" >job</th>        <th class=\"col_heading level0 col3\" >family</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_eb74ba58_50fd_11ec_8731_a860b6024b00level0_row0\" class=\"row_heading level0 row0\" >i</th>\n",
       "                        <td id=\"T_eb74ba58_50fd_11ec_8731_a860b6024b00row0_col0\" class=\"data row0 col0\" >upendra</td>\n",
       "                        <td id=\"T_eb74ba58_50fd_11ec_8731_a860b6024b00row0_col1\" class=\"data row0 col1\" >26</td>\n",
       "                        <td id=\"T_eb74ba58_50fd_11ec_8731_a860b6024b00row0_col2\" class=\"data row0 col2\" >it</td>\n",
       "                        <td id=\"T_eb74ba58_50fd_11ec_8731_a860b6024b00row0_col3\" class=\"data row0 col3\" >badarvada</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_eb74ba58_50fd_11ec_8731_a860b6024b00level0_row1\" class=\"row_heading level0 row1\" >ii</th>\n",
       "                        <td id=\"T_eb74ba58_50fd_11ec_8731_a860b6024b00row1_col0\" class=\"data row1 col0\" >harindra</td>\n",
       "                        <td id=\"T_eb74ba58_50fd_11ec_8731_a860b6024b00row1_col1\" class=\"data row1 col1\" >33</td>\n",
       "                        <td id=\"T_eb74ba58_50fd_11ec_8731_a860b6024b00row1_col2\" class=\"data row1 col2\" >teaching</td>\n",
       "                        <td id=\"T_eb74ba58_50fd_11ec_8731_a860b6024b00row1_col3\" class=\"data row1 col3\" >badarvada</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_eb74ba58_50fd_11ec_8731_a860b6024b00level0_row2\" class=\"row_heading level0 row2\" >iii</th>\n",
       "                        <td id=\"T_eb74ba58_50fd_11ec_8731_a860b6024b00row2_col0\" class=\"data row2 col0\" >lalitha</td>\n",
       "                        <td id=\"T_eb74ba58_50fd_11ec_8731_a860b6024b00row2_col1\" class=\"data row2 col1\" >30</td>\n",
       "                        <td id=\"T_eb74ba58_50fd_11ec_8731_a860b6024b00row2_col2\" class=\"data row2 col2\" >house wife</td>\n",
       "                        <td id=\"T_eb74ba58_50fd_11ec_8731_a860b6024b00row2_col3\" class=\"data row2 col3\" >badarvada</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_eb74ba58_50fd_11ec_8731_a860b6024b00level0_row3\" class=\"row_heading level0 row3\" >iv</th>\n",
       "                        <td id=\"T_eb74ba58_50fd_11ec_8731_a860b6024b00row3_col0\" class=\"data row3 col0\" >arjun</td>\n",
       "                        <td id=\"T_eb74ba58_50fd_11ec_8731_a860b6024b00row3_col1\" class=\"data row3 col1\" >3</td>\n",
       "                        <td id=\"T_eb74ba58_50fd_11ec_8731_a860b6024b00row3_col2\" class=\"data row3 col2\" >play</td>\n",
       "                        <td id=\"T_eb74ba58_50fd_11ec_8731_a860b6024b00row3_col3\" class=\"data row3 col3\" >badarvada</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_eb74ba58_50fd_11ec_8731_a860b6024b00level0_row4\" class=\"row_heading level0 row4\" >v</th>\n",
       "                        <td id=\"T_eb74ba58_50fd_11ec_8731_a860b6024b00row4_col0\" class=\"data row4 col0\" >pops</td>\n",
       "                        <td id=\"T_eb74ba58_50fd_11ec_8731_a860b6024b00row4_col1\" class=\"data row4 col1\" >62</td>\n",
       "                        <td id=\"T_eb74ba58_50fd_11ec_8731_a860b6024b00row4_col2\" class=\"data row4 col2\" >bank retd</td>\n",
       "                        <td id=\"T_eb74ba58_50fd_11ec_8731_a860b6024b00row4_col3\" class=\"data row4 col3\" >badarvada</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fc7056f9860>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pandas custom styling \n",
    "def morethan20(val):\n",
    "    if val > 20:\n",
    "        return 'background-color:orange'\n",
    "    return ''\n",
    "df.style.applymap(morethan20,subset = ['age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upendra \n",
      "          name  age\n",
      "i     upendra   26\n",
      "ii   harindra   33\n",
      "iii   lalitha   30\n",
      "iv      arjun    3\n"
     ]
    }
   ],
   "source": [
    "# indexing(first column then row) \n",
    "print(df['name']['i'],'\\n',df[['name','age']]['i':'iv'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>family</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>i</th>\n",
       "      <td>upendra</td>\n",
       "      <td>26</td>\n",
       "      <td>it</td>\n",
       "      <td>badarvada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ii</th>\n",
       "      <td>harindra</td>\n",
       "      <td>33</td>\n",
       "      <td>teaching</td>\n",
       "      <td>badarvada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iii</th>\n",
       "      <td>lalitha</td>\n",
       "      <td>30</td>\n",
       "      <td>house wife</td>\n",
       "      <td>badarvada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iv</th>\n",
       "      <td>arjun</td>\n",
       "      <td>3</td>\n",
       "      <td>play</td>\n",
       "      <td>badarvada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v</th>\n",
       "      <td>pops</td>\n",
       "      <td>62</td>\n",
       "      <td>bank retd</td>\n",
       "      <td>badarvada</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         name  age         job     family\n",
       "i     upendra   26          it  badarvada\n",
       "ii   harindra   33    teaching  badarvada\n",
       "iii   lalitha   30  house wife  badarvada\n",
       "iv      arjun    3        play  badarvada\n",
       "v        pops   62   bank retd  badarvada"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# copy using indexing and selecting specified columns \n",
    "df_copy = df[['name','age','job','family']]\n",
    "df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name        upendra\n",
      "age              26\n",
      "job              it\n",
      "family    badarvada\n",
      "Name: i, dtype: object \n",
      "\n",
      "         name  age         job\n",
      "i     upendra   26          it\n",
      "ii   harindra   33    teaching\n",
      "iii   lalitha   30  house wife\n",
      "iv      arjun    3        play \n",
      "\n",
      "upendra \n",
      "\n",
      "       name   job\n",
      "i   upendra    it\n",
      "iv    arjun  play \n",
      "\n",
      "         name         job\n",
      "i     upendra          it\n",
      "ii   harindra    teaching\n",
      "iii   lalitha  house wife\n",
      "iv      arjun        play\n",
      "v        pops   bank retd \n",
      "\n",
      "       name  age   job     family\n",
      "i   upendra   26    it  badarvada\n",
      "iv    arjun    3  play  badarvada\n"
     ]
    }
   ],
   "source": [
    "# selection using rows and col names(first row then column)\n",
    "print(df.loc['i'],'\\n')\n",
    "print(df.loc['i':'iv','name':'job'],'\\n')\n",
    "print(df.loc['i','name'],'\\n')\n",
    "print(df.loc[['i','iv'],['name','job']],'\\n')\n",
    "print(df.loc[:,['name','job']],'\\n')\n",
    "print(df.loc[['i','iv']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upendra\n"
     ]
    }
   ],
   "source": [
    "# .at used to return only one value at specific row, col and is more faster than .loc to do this\n",
    "print(df.at['i','name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>job</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>i</th>\n",
       "      <td>upendra</td>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iii</th>\n",
       "      <td>lalitha</td>\n",
       "      <td>house wife</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v</th>\n",
       "      <td>pops</td>\n",
       "      <td>bank retd</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        name         job\n",
       "i    upendra          it\n",
       "iii  lalitha  house wife\n",
       "v       pops   bank retd"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# slicing on both rows and columns \n",
    "df.loc[::2,::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>job</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>i</th>\n",
       "      <td>upendra</td>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iii</th>\n",
       "      <td>lalitha</td>\n",
       "      <td>house wife</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v</th>\n",
       "      <td>pops</td>\n",
       "      <td>bank retd</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        name         job\n",
       "i    upendra          it\n",
       "iii  lalitha  house wife\n",
       "v       pops   bank retd"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# indexing on columns and selection on rows \n",
    "df[['name','job']][::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upendra \n",
      "\n",
      "name       harindra\n",
      "age              33\n",
      "job        teaching\n",
      "family    badarvada\n",
      "Name: ii, dtype: object \n",
      "\n",
      "        name  age       job     family\n",
      "ii  harindra   33  teaching  badarvada \n",
      "\n",
      "     age     family\n",
      "iii   30  badarvada\n",
      "iv     3  badarvada\n",
      "     age         job\n",
      "ii    33    teaching\n",
      "iii   30  house wife\n"
     ]
    }
   ],
   "source": [
    "# indexing using index/col index  \n",
    "print(df.iloc[0,0],'\\n') # you can use iat[0,0] for single row selection\n",
    "print(df.iloc[1],'\\n') # as series \n",
    "print(df.iloc[[1],:],'\\n') # as df\n",
    "print(df.iloc[[2,3],[1,3]])  \n",
    "print(df.iloc[1:3,1:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>family</th>\n",
       "      <th>fav cricketer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>i</th>\n",
       "      <td>upendra</td>\n",
       "      <td>26</td>\n",
       "      <td>it</td>\n",
       "      <td>badarvada</td>\n",
       "      <td>dhoni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ii</th>\n",
       "      <td>harindra</td>\n",
       "      <td>33</td>\n",
       "      <td>teaching</td>\n",
       "      <td>badarvada</td>\n",
       "      <td>dhoni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iii</th>\n",
       "      <td>lalitha</td>\n",
       "      <td>30</td>\n",
       "      <td>house wife</td>\n",
       "      <td>badarvada</td>\n",
       "      <td>virat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iv</th>\n",
       "      <td>arjun</td>\n",
       "      <td>3</td>\n",
       "      <td>play</td>\n",
       "      <td>badarvada</td>\n",
       "      <td>dhoni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v</th>\n",
       "      <td>pops</td>\n",
       "      <td>62</td>\n",
       "      <td>bank retd</td>\n",
       "      <td>badarvada</td>\n",
       "      <td>virat</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         name  age         job     family fav cricketer\n",
       "i     upendra   26          it  badarvada         dhoni\n",
       "ii   harindra   33    teaching  badarvada         dhoni\n",
       "iii   lalitha   30  house wife  badarvada         virat\n",
       "iv      arjun    3        play  badarvada         dhoni\n",
       "v        pops   62   bank retd  badarvada         virat"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adding a column \n",
    "df['fav cricketer'] = ['dhoni','dhoni','virat','dhoni','virat']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>family</th>\n",
       "      <th>fav_ipl_team</th>\n",
       "      <th>fav cricketer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>i</th>\n",
       "      <td>upendra</td>\n",
       "      <td>26</td>\n",
       "      <td>it</td>\n",
       "      <td>badarvada</td>\n",
       "      <td>csk</td>\n",
       "      <td>dhoni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ii</th>\n",
       "      <td>harindra</td>\n",
       "      <td>33</td>\n",
       "      <td>teaching</td>\n",
       "      <td>badarvada</td>\n",
       "      <td>csk</td>\n",
       "      <td>dhoni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iii</th>\n",
       "      <td>lalitha</td>\n",
       "      <td>30</td>\n",
       "      <td>house wife</td>\n",
       "      <td>badarvada</td>\n",
       "      <td>rcb</td>\n",
       "      <td>virat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iv</th>\n",
       "      <td>arjun</td>\n",
       "      <td>3</td>\n",
       "      <td>play</td>\n",
       "      <td>badarvada</td>\n",
       "      <td>csk</td>\n",
       "      <td>dhoni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v</th>\n",
       "      <td>pops</td>\n",
       "      <td>62</td>\n",
       "      <td>bank retd</td>\n",
       "      <td>badarvada</td>\n",
       "      <td>rcb</td>\n",
       "      <td>virat</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         name  age         job     family fav_ipl_team fav cricketer\n",
       "i     upendra   26          it  badarvada          csk         dhoni\n",
       "ii   harindra   33    teaching  badarvada          csk         dhoni\n",
       "iii   lalitha   30  house wife  badarvada          rcb         virat\n",
       "iv      arjun    3        play  badarvada          csk         dhoni\n",
       "v        pops   62   bank retd  badarvada          rcb         virat"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adding a new column at a position\n",
    "fav_ipl_team = ['csk','csk','rcb','csk','rcb']\n",
    "df.insert(4,'fav_ipl_team',fav_ipl_team)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Team</th>\n",
       "      <th>Number</th>\n",
       "      <th>Position</th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>College</th>\n",
       "      <th>Salary</th>\n",
       "      <th>New_team</th>\n",
       "      <th>Revised_Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Avery Bradley</td>\n",
       "      <td>Boston Celtics</td>\n",
       "      <td>0.00</td>\n",
       "      <td>PG</td>\n",
       "      <td>25.00</td>\n",
       "      <td>6-2</td>\n",
       "      <td>180.00</td>\n",
       "      <td>Texas</td>\n",
       "      <td>7,730,337.00</td>\n",
       "      <td>Boston Celtics_GO</td>\n",
       "      <td>8,503,370.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jae Crowder</td>\n",
       "      <td>Boston Celtics</td>\n",
       "      <td>99.00</td>\n",
       "      <td>SF</td>\n",
       "      <td>25.00</td>\n",
       "      <td>6-6</td>\n",
       "      <td>235.00</td>\n",
       "      <td>Marquette</td>\n",
       "      <td>6,796,117.00</td>\n",
       "      <td>Boston Celtics_GO</td>\n",
       "      <td>7,475,728.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>John Holland</td>\n",
       "      <td>Boston Celtics</td>\n",
       "      <td>30.00</td>\n",
       "      <td>SG</td>\n",
       "      <td>27.00</td>\n",
       "      <td>6-5</td>\n",
       "      <td>205.00</td>\n",
       "      <td>Boston University</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Boston Celtics_GO</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>R.J. Hunter</td>\n",
       "      <td>Boston Celtics</td>\n",
       "      <td>28.00</td>\n",
       "      <td>SG</td>\n",
       "      <td>22.00</td>\n",
       "      <td>6-5</td>\n",
       "      <td>185.00</td>\n",
       "      <td>Georgia State</td>\n",
       "      <td>1,148,640.00</td>\n",
       "      <td>Boston Celtics_GO</td>\n",
       "      <td>1,263,504.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jonas Jerebko</td>\n",
       "      <td>Boston Celtics</td>\n",
       "      <td>8.00</td>\n",
       "      <td>PF</td>\n",
       "      <td>29.00</td>\n",
       "      <td>6-10</td>\n",
       "      <td>231.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5,000,000.00</td>\n",
       "      <td>Boston Celtics_GO</td>\n",
       "      <td>5,500,000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>Shelvin Mack</td>\n",
       "      <td>Utah Jazz</td>\n",
       "      <td>8.00</td>\n",
       "      <td>PG</td>\n",
       "      <td>26.00</td>\n",
       "      <td>6-3</td>\n",
       "      <td>203.00</td>\n",
       "      <td>Butler</td>\n",
       "      <td>2,433,333.00</td>\n",
       "      <td>Utah Jazz_GO</td>\n",
       "      <td>2,676,666.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>Raul Neto</td>\n",
       "      <td>Utah Jazz</td>\n",
       "      <td>25.00</td>\n",
       "      <td>PG</td>\n",
       "      <td>24.00</td>\n",
       "      <td>6-1</td>\n",
       "      <td>179.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>900,000.00</td>\n",
       "      <td>Utah Jazz_GO</td>\n",
       "      <td>990,000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>Tibor Pleiss</td>\n",
       "      <td>Utah Jazz</td>\n",
       "      <td>21.00</td>\n",
       "      <td>C</td>\n",
       "      <td>26.00</td>\n",
       "      <td>7-3</td>\n",
       "      <td>256.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2,900,000.00</td>\n",
       "      <td>Utah Jazz_GO</td>\n",
       "      <td>3,190,000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>Jeff Withey</td>\n",
       "      <td>Utah Jazz</td>\n",
       "      <td>24.00</td>\n",
       "      <td>C</td>\n",
       "      <td>26.00</td>\n",
       "      <td>7-0</td>\n",
       "      <td>231.00</td>\n",
       "      <td>Kansas</td>\n",
       "      <td>947,276.00</td>\n",
       "      <td>Utah Jazz_GO</td>\n",
       "      <td>1,042,003.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>458 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Name            Team  Number Position   Age Height  Weight  \\\n",
       "0    Avery Bradley  Boston Celtics    0.00       PG 25.00    6-2  180.00   \n",
       "1      Jae Crowder  Boston Celtics   99.00       SF 25.00    6-6  235.00   \n",
       "2     John Holland  Boston Celtics   30.00       SG 27.00    6-5  205.00   \n",
       "3      R.J. Hunter  Boston Celtics   28.00       SG 22.00    6-5  185.00   \n",
       "4    Jonas Jerebko  Boston Celtics    8.00       PF 29.00   6-10  231.00   \n",
       "..             ...             ...     ...      ...   ...    ...     ...   \n",
       "453   Shelvin Mack       Utah Jazz    8.00       PG 26.00    6-3  203.00   \n",
       "454      Raul Neto       Utah Jazz   25.00       PG 24.00    6-1  179.00   \n",
       "455   Tibor Pleiss       Utah Jazz   21.00        C 26.00    7-3  256.00   \n",
       "456    Jeff Withey       Utah Jazz   24.00        C 26.00    7-0  231.00   \n",
       "457            NaN             NaN     NaN      NaN   NaN    NaN     NaN   \n",
       "\n",
       "               College       Salary           New_team  Revised_Salary  \n",
       "0                Texas 7,730,337.00  Boston Celtics_GO    8,503,370.70  \n",
       "1            Marquette 6,796,117.00  Boston Celtics_GO    7,475,728.70  \n",
       "2    Boston University          NaN  Boston Celtics_GO             NaN  \n",
       "3        Georgia State 1,148,640.00  Boston Celtics_GO    1,263,504.00  \n",
       "4                  NaN 5,000,000.00  Boston Celtics_GO    5,500,000.00  \n",
       "..                 ...          ...                ...             ...  \n",
       "453             Butler 2,433,333.00       Utah Jazz_GO    2,676,666.30  \n",
       "454                NaN   900,000.00       Utah Jazz_GO      990,000.00  \n",
       "455                NaN 2,900,000.00       Utah Jazz_GO    3,190,000.00  \n",
       "456             Kansas   947,276.00       Utah Jazz_GO    1,042,003.60  \n",
       "457                NaN          NaN                NaN             NaN  \n",
       "\n",
       "[458 rows x 11 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adding multiple no of new column at a time \n",
    "df_multiple = pd.read_csv(\"data/nba.csv\")\n",
    "# First column ='New_Team', this column\n",
    "# will append '_GO' at the end of each team name.\n",
    "# Second column ='Revised_Salary' will increase \n",
    "# the salary of all employees by 10 % \n",
    "df_multiple = df_multiple.assign(New_team = lambda x: df_multiple['Team']+'_GO', \n",
    "          Revised_Salary = lambda x: df_multiple['Salary'] \n",
    "                             + df_multiple['Salary'] / 10)\n",
    "df_multiple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>family</th>\n",
       "      <th>fav_ipl_team</th>\n",
       "      <th>fav cricketer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>upendra</td>\n",
       "      <td>26</td>\n",
       "      <td>it</td>\n",
       "      <td>badarvada</td>\n",
       "      <td>csk</td>\n",
       "      <td>dhoni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>harindra</td>\n",
       "      <td>33</td>\n",
       "      <td>teaching</td>\n",
       "      <td>badarvada</td>\n",
       "      <td>csk</td>\n",
       "      <td>dhoni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lalitha</td>\n",
       "      <td>30</td>\n",
       "      <td>house wife</td>\n",
       "      <td>badarvada</td>\n",
       "      <td>rcb</td>\n",
       "      <td>virat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>arjun</td>\n",
       "      <td>3</td>\n",
       "      <td>play</td>\n",
       "      <td>badarvada</td>\n",
       "      <td>csk</td>\n",
       "      <td>dhoni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pops</td>\n",
       "      <td>62</td>\n",
       "      <td>bank retd</td>\n",
       "      <td>badarvada</td>\n",
       "      <td>rcb</td>\n",
       "      <td>virat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>vijju</td>\n",
       "      <td>27</td>\n",
       "      <td>it</td>\n",
       "      <td>boddu</td>\n",
       "      <td>csk</td>\n",
       "      <td>dhoni</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       name  age         job     family fav_ipl_team fav cricketer\n",
       "0   upendra   26          it  badarvada          csk         dhoni\n",
       "1  harindra   33    teaching  badarvada          csk         dhoni\n",
       "2   lalitha   30  house wife  badarvada          rcb         virat\n",
       "3     arjun    3        play  badarvada          csk         dhoni\n",
       "4      pops   62   bank retd  badarvada          rcb         virat\n",
       "5     vijju   27          it      boddu          csk         dhoni"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add a new row \n",
    "new_row = pd.Series(['vijju',27,'it','boddu','csk','dhoni'],index=df.columns)\n",
    "df = df.append(new_row,ignore_index=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A  B\n",
       "0  1  4\n",
       "1  2  5\n",
       "2  3  6"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# update dataframe if index or col matches\n",
    "# Modify in place using non-NA values from another DataFrame aligning on indices.\n",
    "df = pd.DataFrame({'A': [1, 2, 3],\n",
    "                   'B': [400, 500, 600]})\n",
    "new_df = pd.DataFrame({'B': [4, 5, 6],\n",
    "                       'C': [7, 8, 9]})\n",
    "df.update(new_df)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NAME</th>\n",
       "      <th>AGE</th>\n",
       "      <th>JOB</th>\n",
       "      <th>family</th>\n",
       "      <th>fav_ipl_team</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>i</th>\n",
       "      <td>upendra</td>\n",
       "      <td>26</td>\n",
       "      <td>it</td>\n",
       "      <td>badarvada</td>\n",
       "      <td>csk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ii</th>\n",
       "      <td>arjun</td>\n",
       "      <td>3</td>\n",
       "      <td>play</td>\n",
       "      <td>badarvada</td>\n",
       "      <td>csk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       NAME  AGE   JOB     family fav_ipl_team\n",
       "i   upendra   26    it  badarvada          csk\n",
       "ii    arjun    3  play  badarvada          csk"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dropping rows and columns \n",
    "df.drop('fav cricketer',axis=1,inplace = True)\n",
    "df.drop(['ii','iii','v'],axis=0,inplace=True)\n",
    "df.rename(index={'i':'i','iv':'ii'},columns={'name':'NAME','age':'AGE','job':'JOB'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>job</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>arjun</td>\n",
       "      <td>play</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    name   job\n",
       "0  arjun  play"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# conditional selection \n",
    "# both integral and string & \n",
    "# resetting the index \n",
    "df[(df['age'] < 30) & (df['name'].str.startswith('a'))][['name','job']].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>plate</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gomez</td>\n",
       "      <td>1XZ2</td>\n",
       "      <td>3.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lurch</td>\n",
       "      <td>Q38X3</td>\n",
       "      <td>-3.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>03A</td>\n",
       "      <td>14.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Pugsley</td>\n",
       "      <td>ZF003</td>\n",
       "      <td>153.14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      name  plate  distance\n",
       "0    Gomez   1XZ2      3.70\n",
       "3    Lurch  Q38X3     -3.20\n",
       "4      NaN    03A     14.30\n",
       "6  Pugsley  ZF003    153.14"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# conditional selection with or operator using regex\n",
    "df = pd.read_csv('data/rides.csv')\n",
    "mask = df['plate'].str.match(r'[0-9A-Z]{3}', na=False)\n",
    "df[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>family</th>\n",
       "      <th>fav_ipl_team</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>i</th>\n",
       "      <td>upendra</td>\n",
       "      <td>26</td>\n",
       "      <td>it</td>\n",
       "      <td>badarvada</td>\n",
       "      <td>csk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      name  age job     family fav_ipl_team\n",
       "i  upendra   26  it  badarvada          csk"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# selection using string value  \n",
    "df[df.name.str.contains('upen')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>family</th>\n",
       "      <th>fav_ipl_team</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>i</th>\n",
       "      <td>Upendra</td>\n",
       "      <td>26</td>\n",
       "      <td>it</td>\n",
       "      <td>badarvada</td>\n",
       "      <td>csk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iv</th>\n",
       "      <td>Arjun</td>\n",
       "      <td>3</td>\n",
       "      <td>play</td>\n",
       "      <td>badarvada</td>\n",
       "      <td>csk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       name  age   job     family fav_ipl_team\n",
       "i   Upendra   26    it  badarvada          csk\n",
       "iv    Arjun    3  play  badarvada          csk"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['name'] = df['name'].str.capitalize()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     time name          value\n",
      "0 2021-07-13 14:36:52.380  mem 227,517,194.00\n",
      "1 2021-07-13 14:36:52.380  cpu          31.57\n",
      "2 2021-07-13 14:36:53.337  mem 227,519,176.00\n",
      "3 2021-07-13 14:36:53.337  cpu         300.90\n",
      "4 2021-07-13 14:36:54.294  mem 227,515,712.00 \n",
      "\n",
      "                     time name  value\n",
      "3 2021-07-13 14:36:53.337  cpu 300.90\n",
      "9 2021-07-13 14:36:56.208  cpu -32.14 \n",
      "\n",
      "       TV  Radio  Newspaper  Sales\n",
      "9  199.80   2.60      21.20  15.60\n",
      "21 237.40   5.10      23.50  17.50\n",
      "23 228.30  16.90      26.20  20.50\n",
      "25 262.90   3.50      19.50  17.00\n",
      "27 240.10  16.70      22.90  20.90\n"
     ]
    }
   ],
   "source": [
    "# selection using query\n",
    "df = pd.read_csv('data/metrics.csv', parse_dates=['time'])\n",
    "print(df.head(),'\\n')\n",
    "print(df.query('name == \"cpu\" & (value < 0 | value > 100)'),'\\n')\n",
    "df1 = pd.read_csv('data/advertising.csv')\n",
    "avg_radio_rev = df1['Radio'].mean()\n",
    "avg_tv_rev = df1['TV'].mean()\n",
    "# using local variables\n",
    "print(df1.query('TV > @avg_tv_rev & Radio < @avg_radio_rev').head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multi indexed columns & hierarchical indexing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   A     B   \n",
      "   a  b  a  b\n",
      "0  1  6  2  7\n",
      "1  2  7  3  8\n",
      "2  3  8  4  9\n",
      "3  4  9  5  1\n",
      "4  5  1  6  2\n",
      "5  6  9  8  4\n"
     ]
    }
   ],
   "source": [
    "dictionary = {'A' : {'a': [1,2,3,4,5,6],\n",
    "                     'b': [6,7,8,9,1,9]},\n",
    "\n",
    "              'B' : {'a': [2,3,4,5,6,8],\n",
    "                     'b': [7,8,9,1,2,4]}}\n",
    "# now reform the above nested dictionary using dict comprehension\n",
    "sorted_dict = {(outerkey,innerkey):values for outerkey,innerdict in dictionary.items() \n",
    "               for innerkey,values in innerdict.items()}\n",
    "dfs = pd.DataFrame(sorted_dict)\n",
    "print(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A  a    1\n",
      "   b    6\n",
      "B  a    2\n",
      "   b    7\n",
      "Name: (G1, 1), dtype: int64\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# indexing from multi indexed data frame \n",
    "print(dfs.loc[('G1',1)])\n",
    "print(dfs['A','a']['G1',1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year  discipline                      nobelist\n",
      "0  1901   Chemistry  Jacobus Henricus van 't Hoff\n",
      "1  1901  Literature               Sully Prudhomme\n",
      "2  1901    Medicine        Emil Adolf von Behring\n",
      "3  1901       Peace                Frédéric Passy\n",
      "4  1901       Peace                  Henry Dunant \n",
      "\n",
      "0  year                                  1901\n",
      "   discipline                       Chemistry\n",
      "   nobelist      Jacobus Henricus van 't Hoff\n",
      "1  year                                  1901\n",
      "   discipline                      Literature\n",
      "dtype: object \n",
      "\n",
      "                                     nobelist\n",
      "year discipline                              \n",
      "1901 Chemistry   Jacobus Henricus van 't Hoff\n",
      "     Literature               Sully Prudhomme\n",
      "     Medicine          Emil Adolf von Behring\n",
      "     Peace                     Frédéric Passy\n",
      "     Peace                       Henry Dunant \n",
      "\n",
      "year  discipline          \n",
      "1901  Chemistry   nobelist    Jacobus Henricus van 't Hoff\n",
      "      Literature  nobelist                 Sully Prudhomme\n",
      "      Medicine    nobelist          Emil Adolf von Behring\n",
      "      Peace       nobelist                  Frédéric Passy\n",
      "                  nobelist                    Henry Dunant\n",
      "Name: 0, dtype: object \n",
      "\n",
      "[\"Jacobus Henricus van 't Hoff\" 'Hermann Emil Fischer' 'Svante Arrhenius'\n",
      " 'William Ramsay' 'Adolf von Baeyer' 'Henri Moissan' 'Eduard Buchner'\n",
      " 'Ernest Rutherford' 'Wilhelm Ostwald' 'Otto Wallach'] \n",
      "\n",
      "[\"Jacobus Henricus van 't Hoff\" 'Wilhelm Röntgen' 'Hermann Emil Fischer'\n",
      " 'Hendrik Lorentz' 'Pieter Zeeman' 'Svante Arrhenius' 'Henri Becquerel'\n",
      " 'Marie Curie' 'Pierre Curie' 'William Ramsay' 'Lord Rayleigh'\n",
      " 'Adolf von Baeyer' 'Philipp Lenard' 'Henri Moissan' 'J. J. Thomson'\n",
      " 'Eduard Buchner' 'Albert Abraham Michelson' 'Ernest Rutherford'\n",
      " 'Gabriel Lippmann' 'Wilhelm Ostwald' 'Guglielmo Marconi'\n",
      " 'Karl Ferdinand Braun' 'Otto Wallach' 'Johannes Diderik van der Waals']\n"
     ]
    }
   ],
   "source": [
    "# set multi index from csv col names \n",
    "nobels = pd.read_csv('data/nobels.csv', names=['year','discipline','nobelist'])\n",
    "print(nobels.head(),'\\n')\n",
    "# stacks all the columns \n",
    "print(nobels.stack().head(),'\\n') # use unstack to reverse it   \n",
    "# converts normal df to multi indexed df\n",
    "nobels_multi = nobels.set_index(['year','discipline'])\n",
    "print(nobels_multi.head(),'\\n')\n",
    "# stack with multi index\n",
    "stacked = pd.DataFrame(nobels_multi.stack())\n",
    "print(stacked[0].head(),'\\n') \n",
    "# using slicing and selection to access a value\n",
    "print(nobels_multi.loc[(slice(1901,1910), 'Chemistry'), :]['nobelist'].values,'\\n')\n",
    "print(nobels_multi.loc[(slice(1901,1910), ['Chemistry','Physics']), :]['nobelist'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cities            NY      LA   SF\n",
      "Temp            cold hot hot cold\n",
      "INDEX_1 INDEX_2                  \n",
      "a       1          0   1   2    3\n",
      "        2          4   5   6    7\n",
      "b       1          8   9  10   11\n",
      "        2         12  13  14   15\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temp</th>\n",
       "      <th>cold</th>\n",
       "      <th>hot</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INDEX_1</th>\n",
       "      <th>INDEX_2</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">a</th>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">b</th>\n",
       "      <th>1</th>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Temp             cold  hot\n",
       "INDEX_1 INDEX_2           \n",
       "a       1           3    3\n",
       "        2          11   11\n",
       "b       1          19   19\n",
       "        2          27   27"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating hierarchical indexed df directly using matrices \n",
    "dframe2 = pd.DataFrame(np.arange(16).reshape(4,4),\n",
    "                    index=[['a','a','b','b'],[1,2,1,2]],\n",
    "                    columns=[['NY','NY','LA','SF'],\n",
    "                             ['cold','hot','hot','cold']])                                                   \n",
    "dframe2.index.names = ['INDEX_1','INDEX_2']\n",
    "dframe2.columns.names = ['Cities','Temp']\n",
    "dframe2.swaplevel('Cities','Temp',axis=1)\n",
    "print(dframe2)\n",
    "# operations on different levels\n",
    "dframe2.sum(level='Temp',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing values(nan:- not a number) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "does the dataframe has missing values True\n",
      "  First Name  Gender Start Date Last Login Time  Salary  Bonus %  \\\n",
      "0     Thomas    Male  3/31/1996         6:53 AM   61933    4.170   \n",
      "1     Louise  Female  8/12/1980         9:01 AM   63241   15.132   \n",
      "2        NaN    Male  6/14/2012         4:19 PM  125792    5.042   \n",
      "3        NaN    Male  8/21/1998         2:27 PM  122340    6.417   \n",
      "4      James     NaN  1/26/2005        11:00 PM  128771    8.309   \n",
      "\n",
      "  Senior Management Team  \n",
      "0              True  NaN  \n",
      "1              True  NaN  \n",
      "2               NaN  NaN  \n",
      "3               NaN  NaN  \n",
      "4             False  NaN   \n",
      "\n",
      "  First Name  Gender Start Date Last Login Time  Salary  Bonus %  \\\n",
      "0    Douglas    Male   8/6/1993        12:42 PM   97308    6.945   \n",
      "2      Maria  Female  4/23/1993        11:17 AM  130590   11.858   \n",
      "3      Jerry    Male   3/4/2005         1:00 PM  138705    9.340   \n",
      "4      Larry    Male  1/24/1998         4:47 PM  101004    1.389   \n",
      "5     Dennis    Male  4/18/1987         1:35 AM  115163   10.125   \n",
      "\n",
      "  Senior Management             Team  \n",
      "0              True        Marketing  \n",
      "2             False          Finance  \n",
      "3              True          Finance  \n",
      "4              True  Client Services  \n",
      "5             False            Legal  \n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"data/employees.csv\")\n",
    "# get data frame with columns having nan\n",
    "bool_series = pd.isnull(data[\"Team\"])\n",
    "print('does the dataframe has missing values',bool_series.any())\n",
    "print(data[bool_series].head().reset_index(drop = True),'\\n')\n",
    "# get data frame with columns not having nan\n",
    "bool_series1 = pd.notnull(data[\"Team\"])\n",
    "print(data[bool_series1].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     A    B  C\n",
       "0 1.00 5.00  1\n",
       "1 2.00  NaN  2\n",
       "2  NaN  NaN  3"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfn = pd.DataFrame({'A':[1,2,nan],\n",
    "                  'B':[5,nan,nan],\n",
    "                  'C':[1,2,3]})\n",
    "dfn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A    1\n",
      "B    2\n",
      "C    0\n",
      "dtype: int64 \n",
      "\n",
      "True \n",
      "\n",
      "1\n",
      "       A      B      C\n",
      "0  False  False  False\n",
      "1  False   True  False\n",
      "2   True   True  False \n",
      "\n",
      "     A    B  C\n",
      "0 1.00 5.00  1\n"
     ]
    }
   ],
   "source": [
    "# count no of missing values\n",
    "print(dfn.isna().sum(),'\\n')\n",
    "print(dfn.isna().values.any(),'\\n') # check if there any missing values in df \n",
    "print(dfn['A'].isnull().sum())\n",
    "# check for missing values \n",
    "print(dfn.isna(),'\\n')\n",
    "#get rows with no missing values\n",
    "print(dfn[~dfn.isnull().any(axis = 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A    B  C\n",
      "0 1.00 5.00  1\n",
      "\n",
      "\n",
      "   C\n",
      "0  1\n",
      "1  2\n",
      "2  3\n",
      "\n",
      "       ID  FirstName    LastName                Major              Minor   Age  \\\n",
      "0   1869       Hana      Barton              Finance                NaN 22.00   \n",
      "1   2010     Alicia      Kanuri           Management                NaN 21.00   \n",
      "2   2075      Becca     Swanson            Marketing                NaN 22.00   \n",
      "3   2228     Halima       Aminu   Business Analytics                NaN 20.00   \n",
      "4   2442      Holly    Robinson              Finance                NaN 20.00   \n",
      "5   2858      Carla     Harding          Accountancy                NaN   nan   \n",
      "6   3459       Alex     Swanson          Accountancy                NaN   nan   \n",
      "7   3585     Aminah       Zalim            Marketing                NaN 20.00   \n",
      "8   5170        Gus  Cunningham              Finance         Innovation 21.00   \n",
      "9   5317     Rafael       Solis   Business Analytics               ACMS   nan   \n",
      "10  5336      Homer       White              Finance                NaN   nan   \n",
      "11  5495       Lara       Woods          Accountancy                NaN   nan   \n",
      "12  6453       Otis     Johnson           Management  Political Science 19.00   \n",
      "13  6504  Chantelle       Woods  Business Technology                NaN 18.00   \n",
      "14  6768   Caroline       Marsh   Business Analytics               ACMS 22.00   \n",
      "15  7511      Laila     Carroll            Marketing         Innovation 20.00   \n",
      "16  7965      Rocco      Decola              Finance         Innovation 21.00   \n",
      "17  9232      Julie      Holmes  Business Technology         Innovation 18.00   \n",
      "18  9268     Albert      Palmer           Management        Real Estate 21.00   \n",
      "19  9941       Zoya       Doyle   Business Analytics                NaN   nan   \n",
      "\n",
      "    Gender             City State       Zip  \n",
      "0   Female              NaN   NaN       nan  \n",
      "1   Female  Berrien Springs   NaN       nan  \n",
      "2   Female          Chicago    IL 60,608.00  \n",
      "3   Female          Atlanta    GA 30,303.00  \n",
      "4   Female        Charlotte    NC 28,202.00  \n",
      "5   Female       Youngstown    OH 44,502.00  \n",
      "6      NaN          Granger    IN       nan  \n",
      "7   Female          Ashburn    VA 20,147.00  \n",
      "8     Male        Massillon    OH 44,646.00  \n",
      "9      NaN       South Bend    IN 46,601.00  \n",
      "10    Male         St. Paul    MN 55,101.00  \n",
      "11     NaN           Dallas    TX 75,201.00  \n",
      "12    Male        Anchorage    AK 99,501.00  \n",
      "13  Female          Chicago   NaN 60,608.00  \n",
      "14  Female            Niles    MI       nan  \n",
      "15  Female         New York    NY 10,001.00  \n",
      "16    Male          Oakland    CA 94,603.00  \n",
      "17  Female          Webster    NY 14,580.00  \n",
      "18    Male          Detroit    MI 48,201.00  \n",
      "19  Female          Chicago    IL 60,608.00  \n",
      "\n",
      "       ID FirstName    LastName                Major              Minor   Age  \\\n",
      "2   2075     Becca     Swanson            Marketing                NaN 22.00   \n",
      "3   2228    Halima       Aminu   Business Analytics                NaN 20.00   \n",
      "4   2442     Holly    Robinson              Finance                NaN 20.00   \n",
      "5   2858     Carla     Harding          Accountancy                NaN   nan   \n",
      "7   3585    Aminah       Zalim            Marketing                NaN 20.00   \n",
      "8   5170       Gus  Cunningham              Finance         Innovation 21.00   \n",
      "9   5317    Rafael       Solis   Business Analytics               ACMS   nan   \n",
      "10  5336     Homer       White              Finance                NaN   nan   \n",
      "11  5495      Lara       Woods          Accountancy                NaN   nan   \n",
      "12  6453      Otis     Johnson           Management  Political Science 19.00   \n",
      "15  7511     Laila     Carroll            Marketing         Innovation 20.00   \n",
      "16  7965     Rocco      Decola              Finance         Innovation 21.00   \n",
      "17  9232     Julie      Holmes  Business Technology         Innovation 18.00   \n",
      "18  9268    Albert      Palmer           Management        Real Estate 21.00   \n",
      "19  9941      Zoya       Doyle   Business Analytics                NaN   nan   \n",
      "\n",
      "    Gender        City State       Zip  \n",
      "2   Female     Chicago    IL 60,608.00  \n",
      "3   Female     Atlanta    GA 30,303.00  \n",
      "4   Female   Charlotte    NC 28,202.00  \n",
      "5   Female  Youngstown    OH 44,502.00  \n",
      "7   Female     Ashburn    VA 20,147.00  \n",
      "8     Male   Massillon    OH 44,646.00  \n",
      "9      NaN  South Bend    IN 46,601.00  \n",
      "10    Male    St. Paul    MN 55,101.00  \n",
      "11     NaN      Dallas    TX 75,201.00  \n",
      "12    Male   Anchorage    AK 99,501.00  \n",
      "15  Female    New York    NY 10,001.00  \n",
      "16    Male     Oakland    CA 94,603.00  \n",
      "17  Female     Webster    NY 14,580.00  \n",
      "18    Male     Detroit    MI 48,201.00  \n",
      "19  Female     Chicago    IL 60,608.00  \n",
      "\n",
      "      0    1    2    3\n",
      "0 1.00 2.00 3.00  nan\n",
      "1 2.00  nan 5.00 6.00\n",
      "2  nan 7.00  nan 9.00\n",
      "3 1.00  nan  nan  nan \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.00</td>\n",
       "      <td>nan</td>\n",
       "      <td>5.00</td>\n",
       "      <td>6.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3\n",
       "0 1.00 2.00 3.00  nan\n",
       "1 2.00  nan 5.00 6.00"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop rows \n",
    "print(dfn.dropna())\n",
    "# drop columns\n",
    "print('\\n')\n",
    "print(dfn.dropna(axis=1))\n",
    "# drop rows based on certain columns\n",
    "students = pd.read_excel(\"data/students.xlsx\")\n",
    "print('\\n',students)\n",
    "students = students.dropna(subset = ['State', 'Zip'], how = 'any')\n",
    "print('\\n',students)\n",
    "# drop na with threshold \n",
    "dframe2 = pd.DataFrame([[1,2,3,np.nan],[2,np.nan,5,6],[np.nan,7,np.nan,9],[1,np.nan,np.nan,np.nan]])\n",
    "print('\\n',dframe2,'\\n')\n",
    "dframe2.dropna(thresh=3) # Require that many non-NA values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear interpolation\n",
    "\"\"\"\n",
    "Interpolation is a technique in Python used to estimate unknown data points between two known data points. \n",
    "Interpolation is mostly used to impute missing values in the dataframe or series while preprocessing data.\n",
    "Linear interpolation is an imputation technique that assumes a linear relationship between data points and utilises \n",
    "non-missing values from adjacent data points to compute a value for a missing data point.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     A    B  C\n",
       "0  1.0  5.0  1\n",
       "1  2.0  NaN  2\n",
       "2  NaN  NaN  3"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfn_copy = dfn.copy()\n",
    "dfn_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A    B  C\n",
      "0  1.0  5.0  1\n",
      "1  2.0  2.0  2\n",
      "2  2.0  2.0  3 \n",
      "\n",
      "     A      B  C\n",
      "0  1.0    5.0  1\n",
      "1  2.0  100.0  2\n",
      "2  NaN  100.0  3 \n",
      "\n",
      "      ID FirstName    LastName                Major              Minor   Age  \\\n",
      "2   2075     Becca     Swanson            Marketing                NaN  22.0   \n",
      "3   2228    Halima       Aminu   Business Analytics                NaN  20.0   \n",
      "4   2442     Holly    Robinson              Finance                NaN  20.0   \n",
      "5   2858     Carla     Harding          Accountancy                NaN  20.0   \n",
      "7   3585    Aminah       Zalim            Marketing                NaN  20.0   \n",
      "8   5170       Gus  Cunningham              Finance         Innovation  21.0   \n",
      "9   5317    Rafael       Solis   Business Analytics               ACMS  20.0   \n",
      "10  5336     Homer       White              Finance                NaN  20.0   \n",
      "11  5495      Lara       Woods          Accountancy                NaN  20.0   \n",
      "12  6453      Otis     Johnson           Management  Political Science  19.0   \n",
      "15  7511     Laila     Carroll            Marketing         Innovation  20.0   \n",
      "16  7965     Rocco      Decola              Finance         Innovation  21.0   \n",
      "17  9232     Julie      Holmes  Business Technology         Innovation  18.0   \n",
      "18  9268    Albert      Palmer           Management        Real Estate  21.0   \n",
      "19  9941      Zoya       Doyle   Business Analytics                NaN  20.0   \n",
      "\n",
      "    Gender        City State      Zip  \n",
      "2   Female     Chicago    IL  60608.0  \n",
      "3   Female     Atlanta    GA  30303.0  \n",
      "4   Female   Charlotte    NC  28202.0  \n",
      "5   Female  Youngstown    OH  44502.0  \n",
      "7   Female     Ashburn    VA  20147.0  \n",
      "8     Male   Massillon    OH  44646.0  \n",
      "9   Female  South Bend    IN  46601.0  \n",
      "10    Male    St. Paul    MN  55101.0  \n",
      "11  Female      Dallas    TX  75201.0  \n",
      "12    Male   Anchorage    AK  99501.0  \n",
      "15  Female    New York    NY  10001.0  \n",
      "16    Male     Oakland    CA  94603.0  \n",
      "17  Female     Webster    NY  14580.0  \n",
      "18    Male     Detroit    MI  48201.0  \n",
      "19  Female     Chicago    IL  60608.0   \n",
      "\n",
      "     A    B  C\n",
      "0  1.0  5.0  1\n",
      "1  2.0  5.0  2\n",
      "2  2.0  5.0  3 \n",
      "\n",
      "     A    B  C\n",
      "0  1.0  5.0  1\n",
      "1  2.0  5.0  2\n",
      "2  2.0  5.0  3 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# missing values to be filled by either of the two methods \n",
    "print(dfn.fillna(dfn.iloc[:,2].mean()),'\\n')\n",
    "# fill missing values in a column with a specific value\n",
    "print(dfn.fillna({'B':100}),'\\n')\n",
    "students = students.fillna({'Gender':'Female'})\n",
    "students = students.fillna({'Age':students['Age'].median()})\n",
    "print(students,'\\n')\n",
    "# impute missing values in linear forward direction\n",
    "print(dfn_copy.fillna(method='ffill'),'\\n')\n",
    "dfn_copy.interpolate(inplace=True)\n",
    "print(dfn_copy,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>-3.27</td>\n",
       "      <td>-0.72</td>\n",
       "      <td>-0.73</td>\n",
       "      <td>-0.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.06</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>0.67</td>\n",
       "      <td>-1.63</td>\n",
       "      <td>0.81</td>\n",
       "      <td>-3.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>-0.04</td>\n",
       "      <td>-3.03</td>\n",
       "      <td>-0.17</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>-1.09</td>\n",
       "      <td>0.59</td>\n",
       "      <td>-3.06</td>\n",
       "      <td>1.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>2.23</td>\n",
       "      <td>1.39</td>\n",
       "      <td>0.13</td>\n",
       "      <td>-4.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>0.29</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>3.07</td>\n",
       "      <td>-1.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>632</th>\n",
       "      <td>3.16</td>\n",
       "      <td>-1.10</td>\n",
       "      <td>-1.61</td>\n",
       "      <td>-0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>719</th>\n",
       "      <td>-3.29</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>723</th>\n",
       "      <td>-0.62</td>\n",
       "      <td>3.69</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>1.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>0.13</td>\n",
       "      <td>1.49</td>\n",
       "      <td>0.22</td>\n",
       "      <td>3.11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0     1     2     3\n",
       "86  -3.27 -0.72 -0.73 -0.77\n",
       "159  0.25  0.06  3.00  1.17\n",
       "205  0.67 -1.63  0.81 -3.23\n",
       "277 -0.04 -3.03 -0.17  0.08\n",
       "351 -1.09  0.59 -3.06  1.88\n",
       "445  2.23  1.39  0.13 -4.05\n",
       "463  0.29 -0.02  3.07 -1.65\n",
       "632  3.16 -1.10 -1.61 -0.80\n",
       "719 -3.29 -0.06  0.60  0.20\n",
       "723 -0.62  3.69 -0.06  1.01\n",
       "764  0.13  1.49  0.22  3.11"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finding outliers here in this scenario outlier is < -3 and > 3 \n",
    "dframe = pd.DataFrame(np.random.randn(1000,4))\n",
    "dframe[(np.abs(dframe)>3).any(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.95</th>\n",
       "      <td>4.80</td>\n",
       "      <td>4.00</td>\n",
       "      <td>6.40</td>\n",
       "      <td>11.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.99</th>\n",
       "      <td>4.96</td>\n",
       "      <td>4.00</td>\n",
       "      <td>6.88</td>\n",
       "      <td>11.80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        A    B    C     D\n",
       "0.95 4.80 4.00 6.40 11.00\n",
       "0.99 4.96 4.00 6.88 11.80"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# quantile\n",
    "df = pd.DataFrame({\"A\":[1, 5, 3, 4, 2],\n",
    "                   \"B\":[3, 2, 4, 3, 4],\n",
    "                   \"C\":[2, 2, 7, 3, 4],\n",
    "                   \"D\":[4, 3, 6, 12, 7]})\n",
    "  \n",
    "# using quantile() function to\n",
    "# find the quantiles over the index axis\n",
    "df.quantile([.95,.99], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number           8,079.00\n",
      "Age             12,311.00\n",
      "Weight         101,236.00\n",
      "Salary   2,159,837,111.00\n",
      "dtype: float64 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0   7,730,542.00\n",
       "1   6,796,476.00\n",
       "2         262.00\n",
       "3   1,148,875.00\n",
       "4   5,000,268.00\n",
       "dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sum of df row wise/ col wise\n",
    "# similarly min, max, cumsum\n",
    "df = pd.read_csv(\"data/nba.csv\")\n",
    "print(df.sum(axis = 0, skipna = True),'\\n') # col\n",
    "df.sum(axis = 1, skipna = True).head(5) # row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group by "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'Company':['GOOG','GOOG','MSFT','MSFT','FB','FB'],\n",
    "       'Person':['Sam','Charlie','Amy','Vanessa','Carl','Sarah'],\n",
    "       'Sales':[200,120,340,124,243,350]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Person</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GOOG</td>\n",
       "      <td>Sam</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GOOG</td>\n",
       "      <td>Charlie</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MSFT</td>\n",
       "      <td>Amy</td>\n",
       "      <td>340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MSFT</td>\n",
       "      <td>Vanessa</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FB</td>\n",
       "      <td>Carl</td>\n",
       "      <td>243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>FB</td>\n",
       "      <td>Sarah</td>\n",
       "      <td>350</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Company   Person  Sales\n",
       "0    GOOG      Sam    200\n",
       "1    GOOG  Charlie    120\n",
       "2    MSFT      Amy    340\n",
       "3    MSFT  Vanessa    124\n",
       "4      FB     Carl    243\n",
       "5      FB    Sarah    350"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfg = pd.DataFrame(data)\n",
    "dfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "group = dfg.groupby('Company') # if you want index to be reset you can use as_index = False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Person</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GOOG</td>\n",
       "      <td>Sam</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GOOG</td>\n",
       "      <td>Charlie</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Company   Person  Sales\n",
       "0    GOOG      Sam    200\n",
       "1    GOOG  Charlie    120"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get respective group\n",
    "group.get_group('GOOG').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min \n",
      "\n",
      "           Person  Sales\n",
      "Company                \n",
      "FB          Carl    243\n",
      "GOOG     Charlie    120\n",
      "MSFT         Amy    124 \n",
      "\n",
      "max \n",
      "\n",
      "           Person  Sales\n",
      "Company                \n",
      "FB         Sarah    350\n",
      "GOOG         Sam    200\n",
      "MSFT     Vanessa    340 \n",
      "\n",
      "count \n",
      "\n",
      "          Person  Sales\n",
      "Company               \n",
      "FB            2      2\n",
      "GOOG          2      2\n",
      "MSFT          2      2 \n",
      "\n",
      "size \n",
      "\n",
      " Company\n",
      "FB      2\n",
      "GOOG    2\n",
      "MSFT    2\n",
      "dtype: int64 \n",
      "\n",
      "mean \n",
      "\n",
      "          Sales\n",
      "Company       \n",
      "FB      296.50\n",
      "GOOG    160.00\n",
      "MSFT    232.00 \n",
      "\n",
      "std \n",
      "\n",
      "          Sales\n",
      "Company       \n",
      "FB       75.66\n",
      "GOOG     56.57\n",
      "MSFT    152.74 \n",
      "\n",
      "25% - 75% quantile \n",
      "\n",
      " Company      \n",
      "FB       0.25   269.75\n",
      "         0.75   323.25\n",
      "GOOG     0.25   140.00\n",
      "         0.75   180.00\n",
      "MSFT     0.25   178.00\n",
      "         0.75   286.00\n",
      "Name: Sales, dtype: float64 \n",
      "\n",
      "describe \n",
      "\n",
      " Company         FB   GOOG   MSFT\n",
      "Sales count   2.00   2.00   2.00\n",
      "      mean  296.50 160.00 232.00\n",
      "      std    75.66  56.57 152.74\n",
      "      min   243.00 120.00 124.00\n",
      "      25%   269.75 140.00 178.00\n",
      "      50%   296.50 160.00 232.00\n",
      "      75%   323.25 180.00 286.00\n",
      "      max   350.00 200.00 340.00 \n",
      "\n",
      "describe \n",
      "\n",
      "               Company\n",
      "Sales  count  FB          2.00\n",
      "              GOOG        2.00\n",
      "              MSFT        2.00\n",
      "       mean   FB        296.50\n",
      "              GOOG      160.00\n",
      "              MSFT      232.00\n",
      "       std    FB         75.66\n",
      "              GOOG       56.57\n",
      "              MSFT      152.74\n",
      "       min    FB        243.00\n",
      "              GOOG      120.00\n",
      "              MSFT      124.00\n",
      "       25%    FB        269.75\n",
      "              GOOG      140.00\n",
      "              MSFT      178.00\n",
      "       50%    FB        296.50\n",
      "              GOOG      160.00\n",
      "              MSFT      232.00\n",
      "       75%    FB        323.25\n",
      "              GOOG      180.00\n",
      "              MSFT      286.00\n",
      "       max    FB        350.00\n",
      "              GOOG      200.00\n",
      "              MSFT      340.00\n",
      "dtype: float64 \n",
      "\n",
      "sum \n",
      "\n",
      " Company\n",
      "FB      593\n",
      "GOOG    320\n",
      "MSFT    464\n",
      "Name: Sales, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# aggregate operations \n",
    "print('min','\\n\\n',group.min(),'\\n')\n",
    "print('max','\\n\\n',group.max(),'\\n')\n",
    "print('count','\\n\\n',group.count(),'\\n') # returns a df\n",
    "print('size','\\n\\n',group.size(),'\\n')# returns a series \n",
    "print('mean','\\n\\n',group.mean(),'\\n')\n",
    "print('std','\\n\\n',group.std(),'\\n')\n",
    "print('25% - 75% quantile','\\n\\n',group['Sales'].quantile([0.25,0.75]),'\\n')\n",
    "print('describe','\\n\\n',group.describe().T,'\\n') # you can get stats based on dt also with include attr\n",
    "# convert multi indexed df to normal df(pivot table)\n",
    "print('describe','\\n\\n',group.describe().unstack(),'\\n') \n",
    "print('sum','\\n\\n',group['Sales'].sum()) # sum is applicable in series only  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>dataset2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k1</th>\n",
       "      <th>k2</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">X</th>\n",
       "      <th>alpha</th>\n",
       "      <td>-0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta</th>\n",
       "      <td>-1.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Y</th>\n",
       "      <th>alpha</th>\n",
       "      <td>1.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta</th>\n",
       "      <td>-1.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Z</th>\n",
       "      <th>alpha</th>\n",
       "      <td>-0.20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          dataset2\n",
       "k1 k2             \n",
       "X  alpha     -0.02\n",
       "   beta      -1.67\n",
       "Y  alpha      1.38\n",
       "   beta      -1.29\n",
       "Z  alpha     -0.20"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# multi key groupby\n",
    "dframe = pd.DataFrame({'k1':['X','X','Y','Y','Z'],\n",
    "                    'k2':['alpha','beta','alpha','beta','alpha'],\n",
    "                    'dataset1':np.random.randn(5),\n",
    "                    'dataset2':np.random.randn(5)})\n",
    "dataset2_group = dframe.groupby(['k1','k2'])[['dataset2']]\n",
    "dataset2_group.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          W   X     Y   Z\n",
      "Dog    0.00   1  2.00   3\n",
      "Cat     nan   5   nan   7\n",
      "Bird    nan   9   nan  11\n",
      "Mouse 12.00  13 14.00  15 \n",
      "\n",
      "       bad  good\n",
      "Dog      2     2\n",
      "Cat      2     0\n",
      "Bird     2     0\n",
      "Mouse    2     2 \n",
      "\n",
      "        bad  good\n",
      "Dog    4.00  2.00\n",
      "Cat   12.00  0.00\n",
      "Bird  20.00  0.00\n",
      "Mouse 28.00 26.00 \n",
      "\n",
      "      W   X     Y   Z\n",
      "3  0.00   6  2.00  10\n",
      "4  0.00   9  0.00  11\n",
      "5 12.00  13 14.00  15\n"
     ]
    }
   ],
   "source": [
    "# groupby on dict and series \n",
    "animals = pd.DataFrame(np.arange(16).reshape(4, 4),\n",
    "                   columns=['W', 'X', 'Y', 'Z'],\n",
    "                   index=['Dog', 'Cat', 'Bird', 'Mouse'])\n",
    "#Now lets add some NAN values\n",
    "animals.loc[['Cat','Bird'],['W','Y']] = np.nan \n",
    "print(animals,'\\n')\n",
    "\n",
    "# Now let's say I had a dictionary with ebhavior values in it\n",
    "behavior_map = {'W': 'good', 'X': 'bad', 'Y': 'good','Z': 'bad'}\n",
    "behav_series = pd.Series(behavior_map)\n",
    "print(animals.groupby(behav_series, axis=1).count(),'\\n')\n",
    "print(animals.groupby(behav_series, axis=1).sum(),'\\n')\n",
    "print(animals.groupby(len).sum()) # groupby length of names/indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Salary</th>\n",
       "      <th>Bonus %</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Team</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>90657.644723</td>\n",
       "      <td>10.199609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>90763.139535</td>\n",
       "      <td>10.384395</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Salary    Bonus %\n",
       "Team                          \n",
       "False  90657.644723  10.199609\n",
       "True   90763.139535  10.384395"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# groupby with is null filter(true/false)\n",
    "data = pd.read_csv(\"data/employees.csv\")\n",
    "data.groupby(data['Team'].isnull()).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# operations over grouped data :- aggregation, transform, filter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         sum   mean    std\n",
      "Team                      \n",
      "Devils  1536 768.00 134.35\n",
      "Kings   2285 761.67  24.01\n",
      "Riders  3049 762.25  88.57\n",
      "Royals  1505 752.50  72.83\n",
      "kings    812 812.00    nan\n",
      "\n",
      "      Rank   Year  Points\n",
      "0  -15.00 -11.62   12.84\n",
      "1    5.00  -3.87    3.02\n",
      "2   -7.07  -7.07    7.07\n",
      "3    7.07   7.07   -7.07\n",
      "4   11.55 -10.91   -8.61\n",
      "5     nan    nan     nan\n",
      "6   -5.77   2.18   -2.36\n",
      "7   -5.77   8.73   10.97\n",
      "8    5.00   3.87   -7.71\n",
      "9    7.07  -7.07   -7.07\n",
      "10  -7.07   7.07    7.07\n",
      "11   5.00  11.62   -8.16\n",
      "\n",
      "       Team  Rank  Year  Points\n",
      "0   Riders     1  2014     876\n",
      "1   Riders     2  2015     789\n",
      "4    Kings     3  2014     741\n",
      "6    Kings     1  2016     756\n",
      "7    Kings     1  2017     788\n",
      "8   Riders     2  2016     694\n",
      "11  Riders     2  2017     690\n",
      "\n",
      "       Team  Rank  Year  Points\n",
      "0   Riders     1  2014     876\n",
      "1   Riders     2  2015     789\n",
      "2   Devils     2  2014     863\n",
      "3   Devils     3  2015     673\n",
      "4    Kings     3  2014     741\n",
      "5    kings     4  2015     812\n",
      "6    Kings     1  2016     756\n",
      "7    Kings     1  2017     788\n",
      "8   Riders     2  2016     694\n",
      "9   Royals     4  2014     701\n",
      "10  Royals     1  2015     804\n",
      "11  Riders     2  2017     690\n",
      "\n",
      "        Rank Points     \n",
      "        sum    min  max\n",
      "Team                   \n",
      "Devils    5    673  863\n",
      "Kings     5    741  788\n",
      "Riders    7    690  876\n",
      "Royals    5    701  804\n",
      "kings     4    812  812\n"
     ]
    }
   ],
   "source": [
    "# agg:- multiple functions at a time \n",
    "ipl_data = {'Team': ['Riders', 'Riders', 'Devils', 'Devils', 'Kings',\n",
    "   'kings', 'Kings', 'Kings', 'Riders', 'Royals', 'Royals', 'Riders'],\n",
    "   'Rank': [1, 2, 2, 3, 3,4 ,1 ,1,2 , 4,1,2],\n",
    "   'Year': [2014,2015,2014,2015,2014,2015,2016,2017,2016,2014,2015,2017],\n",
    "   'Points':[876,789,863,673,741,812,756,788,694,701,804,690]}\n",
    "df = pd.DataFrame(ipl_data)\n",
    "grouped = df.groupby('Team')\n",
    "print(grouped['Points'].agg([sum, mean, std]))\n",
    "# transform:- custom fn\n",
    "print('\\n',grouped.transform(lambda x: (x - x.mean()) / x.std()*10))\n",
    "# filter:- condition \n",
    "# repeats more than equal to 3 times here team \n",
    "print('\\n',grouped.filter(lambda x: len(x) >= 3))\n",
    "# teams with average points > 500\n",
    "print('\\n',grouped.filter(lambda x: x['Points'].mean() > 500))\n",
    "# agg:- each function for each column \n",
    "print('\\n',grouped.agg({'Rank' : ['sum'], 'Points' : ['min', 'max']}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# sum on data frame columns \n",
    "df = pd.DataFrame({'team': ['A', 'A', 'A', 'B', 'B', 'C'],\n",
    "                   'conference': ['East', 'East', 'East', 'West', 'West', 'East'],\n",
    "                   'points_A': [11, 8, 10, 6, 6, 5],\n",
    "                   'points_B': [12, 8, 10, 7, 5, 6],\n",
    "                   'rebounds': [7, 7, 6, 9, 12, 8]})\n",
    "print(df.loc[(df['team'] == 'A') & (df['conference'] == 'East'), 'points_A'].sum()) # sum of values in a column\n",
    "print((df['points_A'] == df['points_B']).sum()) # no of true values in the given condition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate same as union in sql and it takes iterable as an input  \n",
    "# merge(same as sql join) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>23</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24</td>\n",
       "      <td>25</td>\n",
       "      <td>26</td>\n",
       "      <td>27</td>\n",
       "      <td>28</td>\n",
       "      <td>29</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>30</td>\n",
       "      <td>31</td>\n",
       "      <td>32</td>\n",
       "      <td>33</td>\n",
       "      <td>34</td>\n",
       "      <td>35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0   1   2   3   4   5     0     1     2\n",
       "0   0   1   2   3   4   5   0.0   1.0   2.0\n",
       "1   6   7   8   9  10  11   3.0   4.0   5.0\n",
       "2  12  13  14  15  16  17   6.0   7.0   8.0\n",
       "3  18  19  20  21  22  23   9.0  10.0  11.0\n",
       "4  24  25  26  27  28  29  12.0  13.0  14.0\n",
       "5  30  31  32  33  34  35   NaN   NaN   NaN"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concatenating columns \n",
    "DF_obj = pd.DataFrame(arange(36).reshape(6,6))\n",
    "DF_obj_2 = pd.DataFrame(arange(15).reshape(5,3))\n",
    "# you can even sort while concatenating & ignore indexes \n",
    "pd.concat([DF_obj, DF_obj_2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A0</td>\n",
       "      <td>B0</td>\n",
       "      <td>C0</td>\n",
       "      <td>D0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A1</td>\n",
       "      <td>B1</td>\n",
       "      <td>C1</td>\n",
       "      <td>D1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A2</td>\n",
       "      <td>B2</td>\n",
       "      <td>C2</td>\n",
       "      <td>D2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A3</td>\n",
       "      <td>B3</td>\n",
       "      <td>C3</td>\n",
       "      <td>D3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A4</td>\n",
       "      <td>B4</td>\n",
       "      <td>C4</td>\n",
       "      <td>D4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A5</td>\n",
       "      <td>B5</td>\n",
       "      <td>C5</td>\n",
       "      <td>D5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A6</td>\n",
       "      <td>B6</td>\n",
       "      <td>C6</td>\n",
       "      <td>D6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>A7</td>\n",
       "      <td>B7</td>\n",
       "      <td>C7</td>\n",
       "      <td>D7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    A   B   C   D\n",
       "0  A0  B0  C0  D0\n",
       "1  A1  B1  C1  D1\n",
       "2  A2  B2  C2  D2\n",
       "3  A3  B3  C3  D3\n",
       "4  A4  B4  C4  D4\n",
       "5  A5  B5  C5  D5\n",
       "6  A6  B6  C6  D6\n",
       "7  A7  B7  C7  D7"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concatenating rows \n",
    "# we can ignore_index if index not directly specified \n",
    "df1 = pd.DataFrame({'A': ['A0', 'A1', 'A2', 'A3'],\n",
    "                        'B': ['B0', 'B1', 'B2', 'B3'],\n",
    "                        'C': ['C0', 'C1', 'C2', 'C3'],\n",
    "                        'D': ['D0', 'D1', 'D2', 'D3']},\n",
    "                        index=[0, 1, 2, 3])\n",
    "df2 = pd.DataFrame({'A': ['A4', 'A5', 'A6', 'A7'],\n",
    "                        'B': ['B4', 'B5', 'B6', 'B7'],\n",
    "                        'C': ['C4', 'C5', 'C6', 'C7'],\n",
    "                        'D': ['D4', 'D5', 'D6', 'D7']},\n",
    "                         index=[4, 5, 6, 7]) \n",
    "pd.concat([df1,df2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>Address</th>\n",
       "      <th>Qualification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>K0</th>\n",
       "      <td>Jai</td>\n",
       "      <td>27</td>\n",
       "      <td>Allahabad</td>\n",
       "      <td>MCA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K1</th>\n",
       "      <td>Princi</td>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K2</th>\n",
       "      <td>Gaurav</td>\n",
       "      <td>22</td>\n",
       "      <td>Kannuaj</td>\n",
       "      <td>Phd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K3</th>\n",
       "      <td>Anuj</td>\n",
       "      <td>32</td>\n",
       "      <td>Allahabad</td>\n",
       "      <td>Bcom</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Name  Age    Address Qualification\n",
       "K0     Jai   27  Allahabad           MCA\n",
       "K1  Princi   24        NaN           NaN\n",
       "K2  Gaurav   22    Kannuaj           Phd\n",
       "K3    Anuj   32  Allahabad          Bcom"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# join columns of different indexes \n",
    "data1 = {'Name':['Jai', 'Princi', 'Gaurav', 'Anuj'], \n",
    "        'Age':[27, 24, 22, 32]} \n",
    "    \n",
    "# Define a dictionary containing employee data \n",
    "data2 = {'Address':['Allahabad', 'Kannuaj', 'Allahabad', 'Kannuaj'], \n",
    "        'Qualification':['MCA', 'Phd', 'Bcom', 'B.hons']} \n",
    "  \n",
    "# Convert the dictionary into DataFrame  \n",
    "df = pd.DataFrame(data1,index=['K0', 'K1', 'K2', 'K3'])\n",
    "  \n",
    "# Convert the dictionary into DataFrame  \n",
    "df1 = pd.DataFrame(data2, index=['K0', 'K2', 'K3', 'K4'])\n",
    "df.join(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>Address</th>\n",
       "      <th>Qualification</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>key</th>\n",
       "      <th>Y</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>K0</th>\n",
       "      <th>Y0</th>\n",
       "      <td>Jai</td>\n",
       "      <td>27</td>\n",
       "      <td>Allahabad</td>\n",
       "      <td>MCA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K1</th>\n",
       "      <th>Y1</th>\n",
       "      <td>Princi</td>\n",
       "      <td>24</td>\n",
       "      <td>Kannuaj</td>\n",
       "      <td>Phd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">K2</th>\n",
       "      <th>Y2</th>\n",
       "      <td>Gaurav</td>\n",
       "      <td>22</td>\n",
       "      <td>Allahabad</td>\n",
       "      <td>Bcom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Y3</th>\n",
       "      <td>Gaurav</td>\n",
       "      <td>22</td>\n",
       "      <td>Kanpur</td>\n",
       "      <td>B.hons</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Name  Age    Address Qualification\n",
       "key Y                                       \n",
       "K0  Y0     Jai   27  Allahabad           MCA\n",
       "K1  Y1  Princi   24    Kannuaj           Phd\n",
       "K2  Y2  Gaurav   22  Allahabad          Bcom\n",
       "    Y3  Gaurav   22     Kanpur        B.hons"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# join columns of a simple and multi index df\n",
    "data1 = {'Name':['Jai', 'Princi', 'Gaurav'], \n",
    "        'Age':[27, 24, 22]} \n",
    "# Define a dictionary containing employee data \n",
    "data2 = {'Address':['Allahabad', 'Kannuaj', 'Allahabad', 'Kanpur'], \n",
    "        'Qualification':['MCA', 'Phd', 'Bcom', 'B.hons']} \n",
    "# Convert the dictionary into DataFrame  \n",
    "df = pd.DataFrame(data1, index=pd.Index(['K0', 'K1', 'K2'], name='key'))\n",
    " \n",
    "index = pd.MultiIndex.from_tuples([('K0', 'Y0'), ('K1', 'Y1'),\n",
    "                                   ('K2', 'Y2'), ('K2', 'Y3')],\n",
    "                                   names=['key', 'Y'])\n",
    "# Convert the dictionary into DataFrame  \n",
    "df1 = pd.DataFrame(data2, index= index)\n",
    "result = df.join(df1, how='inner')\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>Address</th>\n",
       "      <th>Qualification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">x</th>\n",
       "      <th>0</th>\n",
       "      <td>Jai</td>\n",
       "      <td>27</td>\n",
       "      <td>Nagpur</td>\n",
       "      <td>Msc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Princi</td>\n",
       "      <td>24</td>\n",
       "      <td>Kanpur</td>\n",
       "      <td>MA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gaurav</td>\n",
       "      <td>22</td>\n",
       "      <td>Allahabad</td>\n",
       "      <td>MCA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anuj</td>\n",
       "      <td>32</td>\n",
       "      <td>Kannuaj</td>\n",
       "      <td>Phd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">y</th>\n",
       "      <th>4</th>\n",
       "      <td>Abhi</td>\n",
       "      <td>17</td>\n",
       "      <td>Nagpur</td>\n",
       "      <td>Btech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ayushi</td>\n",
       "      <td>14</td>\n",
       "      <td>Kanpur</td>\n",
       "      <td>B.A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Dhiraj</td>\n",
       "      <td>12</td>\n",
       "      <td>Allahabad</td>\n",
       "      <td>Bcom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Hitesh</td>\n",
       "      <td>52</td>\n",
       "      <td>Kannuaj</td>\n",
       "      <td>B.hons</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Name  Age    Address Qualification\n",
       "x 0     Jai   27     Nagpur           Msc\n",
       "  1  Princi   24     Kanpur            MA\n",
       "  2  Gaurav   22  Allahabad           MCA\n",
       "  3    Anuj   32    Kannuaj           Phd\n",
       "y 4    Abhi   17     Nagpur         Btech\n",
       "  5  Ayushi   14     Kanpur           B.A\n",
       "  6  Dhiraj   12  Allahabad          Bcom\n",
       "  7  Hitesh   52    Kannuaj        B.hons"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concat rows into a multi index\n",
    "data1 = {'Name':['Jai', 'Princi', 'Gaurav', 'Anuj'], \n",
    "        'Age':[27, 24, 22, 32], \n",
    "        'Address':['Nagpur', 'Kanpur', 'Allahabad', 'Kannuaj'], \n",
    "        'Qualification':['Msc', 'MA', 'MCA', 'Phd']} \n",
    "# Define a dictionary containing employee data \n",
    "data2 = {'Name':['Abhi', 'Ayushi', 'Dhiraj', 'Hitesh'], \n",
    "        'Age':[17, 14, 12, 52], \n",
    "        'Address':['Nagpur', 'Kanpur', 'Allahabad', 'Kannuaj'], \n",
    "        'Qualification':['Btech', 'B.A', 'Bcom', 'B.hons']} \n",
    "# Convert the dictionary into DataFrame  \n",
    "df = pd.DataFrame(data1,index=[0, 1, 2, 3])\n",
    "# Convert the dictionary into DataFrame  \n",
    "df1 = pd.DataFrame(data2, index=[4, 5, 6, 7])\n",
    "res = pd.concat([df, df1], keys=['x', 'y'])\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>Address</th>\n",
       "      <th>Qualification</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jai</td>\n",
       "      <td>27</td>\n",
       "      <td>Nagpur</td>\n",
       "      <td>Msc</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Princi</td>\n",
       "      <td>24</td>\n",
       "      <td>Kanpur</td>\n",
       "      <td>MA</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gaurav</td>\n",
       "      <td>22</td>\n",
       "      <td>Allahabad</td>\n",
       "      <td>MCA</td>\n",
       "      <td>3000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anuj</td>\n",
       "      <td>32</td>\n",
       "      <td>Kannuaj</td>\n",
       "      <td>Phd</td>\n",
       "      <td>4000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Name  Age    Address Qualification  Salary\n",
       "0     Jai   27     Nagpur           Msc    1000\n",
       "1  Princi   24     Kanpur            MA    2000\n",
       "2  Gaurav   22  Allahabad           MCA    3000\n",
       "3    Anuj   32    Kannuaj           Phd    4000"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concat df and a series \n",
    "data1 = {'Name':['Jai', 'Princi', 'Gaurav', 'Anuj'], \n",
    "        'Age':[27, 24, 22, 32], \n",
    "        'Address':['Nagpur', 'Kanpur', 'Allahabad', 'Kannuaj'], \n",
    "        'Qualification':['Msc', 'MA', 'MCA', 'Phd']} \n",
    "# Convert the dictionary into DataFrame  \n",
    "df = pd.DataFrame(data1,index=[0, 1, 2, 3])\n",
    "# creating a series\n",
    "s1 = pd.Series([1000, 2000, 3000, 4000], name='Salary')\n",
    "res = pd.concat([df, s1], axis=1)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id   name  age sex\n",
      "0   2  Jenny   31   F\n",
      "1   3  James   20   M\n",
      "2   4    Dan   40   M \n",
      "\n",
      "   id   name   age  sex\n",
      "0   1    Tom   nan  NaN\n",
      "1   2  Jenny 31.00    F\n",
      "2   3  James 20.00    M\n",
      "3   4    Dan 40.00    M \n",
      "\n",
      "   id   name  age sex\n",
      "0   2  Jenny   31   F\n",
      "1   3  James   20   M\n",
      "2   4    Dan   40   M\n",
      "3   5    NaN   70   F \n",
      "\n",
      "   id   name   age  sex\n",
      "0   1    Tom   nan  NaN\n",
      "1   2  Jenny 31.00    F\n",
      "2   3  James 20.00    M\n",
      "3   4    Dan 40.00    M\n",
      "4   5    NaN 70.00    F\n"
     ]
    }
   ],
   "source": [
    "# merge: inner, fully outer, left outer, right outer \n",
    "df_customer = pd.DataFrame({\n",
    "    'id': [1, 2, 3, 4],\n",
    "    'name': ['Tom', 'Jenny', 'James', 'Dan'],\n",
    "})\n",
    "df_info = pd.DataFrame({\n",
    "    'id': [2, 3, 4, 5],\n",
    "    'age': [31, 20, 40, 70],\n",
    "    'sex': ['F', 'M', 'M', 'F']\n",
    "})\n",
    "print(pd.merge(df_customer, df_info, on='id'),'\\n')\n",
    "print(pd.merge(df_customer, df_info, how='left', on='id'),'\\n')\n",
    "print(pd.merge(df_customer, df_info, how='right', on='id'),'\\n')\n",
    "print(pd.merge(df_customer, df_info, how='outer', on='id'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge on multiple keys\n",
    "data1 = {'key': ['K0', 'K1', 'K2', 'K3'],\n",
    "         'key1': ['K0', 'K1', 'K0', 'K1'],\n",
    "         'Name':['Jai', 'Princi', 'Gaurav', 'Anuj'], \n",
    "        'Age':[27, 24, 22, 32],} \n",
    "# Define a dictionary containing employee data \n",
    "data2 = {'key': ['K0', 'K1', 'K2', 'K3'],\n",
    "         'key1': ['K0', 'K0', 'K0', 'K0'],\n",
    "         'Address':['Nagpur', 'Kanpur', 'Allahabad', 'Kannuaj'], \n",
    "        'Qualification':['Btech', 'B.A', 'Bcom', 'B.hons']} \n",
    "# Convert the dictionary into DataFrame  \n",
    "df = pd.DataFrame(data1)\n",
    "# Convert the dictionary into DataFrame  \n",
    "df1 = pd.DataFrame(data2) \n",
    "print(df, \"\\n\\n\", df1) \n",
    "print(pd.merge(df, df1, on=['key', 'key1']),'\\n')\n",
    "print(pd.merge(df, df1, how='left', on=['key', 'key1']),'\\n')\n",
    "print(pd.merge(df, df1, how='right', on=['key', 'key1']),'\\n')\n",
    "print(pd.merge(df, df1, how='outer', on=['key', 'key1']),'\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   name  grade  height  max_height\n",
      "1  Beth      1   74.90       32.00\n"
     ]
    }
   ],
   "source": [
    "#left join with comparison conditional selection\n",
    "df = pd.read_csv('data/heights.csv')\n",
    "max_heights = pd.DataFrame([[1, 32],], columns=['grade', 'max_height'])\n",
    "df = pd.merge(df, max_heights, how='left', on = 'grade')\n",
    "print(df[df['height'] > df['max_height']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.00</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>9.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.00</td>\n",
       "      <td>12.00</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>11.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.00</td>\n",
       "      <td>16.00</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     X     Y     Z\n",
       "0 1.00   nan   nan\n",
       "1 4.00  5.00  9.00\n",
       "2 3.00 12.00   nan\n",
       "3 6.00  7.00 11.00\n",
       "4 8.00 16.00   nan"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine first \n",
    "# combine using first df values, unless theres a NAN, then put the second df values\n",
    "\n",
    "dframe_odds = pd.DataFrame({'X': [1., np.nan, 3., np.nan],\n",
    "                     'Y': [np.nan, 5., np.nan, 7.],\n",
    "                     'Z': [np.nan, 9., np.nan, 11.]})\n",
    "dframe_evens = pd.DataFrame({'X': [2., 4., np.nan, 6., 8.],\n",
    "                     'Y': [np.nan, 10., 12., 14., 16.]})\n",
    "dframe_odds.combine_first(dframe_evens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# operations \n",
    "dfo = pd.DataFrame({'col1':[1,2,3,4],'col2':[444,555,666,444],'col3':['abc','def','ghi','xyz']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique values\n",
      "[444 555 666]\n",
      "no of unique values\n",
      "3\n",
      "value counts\n",
      "444    2\n",
      "555    1\n",
      "666    1\n",
      "Name: col2, dtype: int64\n",
      "normalized value counts\n",
      "444   0.50\n",
      "555   0.25\n",
      "666   0.25\n",
      "Name: col2, dtype: float64\n",
      "sorting\n",
      "   col1  col2 col3\n",
      "0     1   444  abc\n",
      "3     4   444  xyz\n",
      "1     2   555  def\n",
      "2     3   666  ghi\n"
     ]
    }
   ],
   "source": [
    "# unique and count\n",
    "print('unique values')\n",
    "print(dfo['col2'].unique())\n",
    "print('no of unique values')\n",
    "print(dfo['col2'].nunique())\n",
    "print('value counts')\n",
    "print(dfo['col2'].value_counts()) \n",
    "print('normalized value counts')\n",
    "print(dfo['col2'].value_counts(normalize = True)) # we can even normalize it to val b/w 0 to 1\n",
    "print('sorting')\n",
    "print(dfo.sort_values(by='col2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      A     B    C     D\n",
      "0  2.50 25.00 2.00  2.50\n",
      "1  1.50  1.00 1.50  2.00\n",
      "2 25.00  2.00 4.00  1.00\n",
      "3  2.00  1.50 2.50 25.00 \n",
      "\n",
      "0   0.70\n",
      "1   0.53\n",
      "2   1.40\n",
      "3   0.88\n",
      "Name: C, dtype: float64\n",
      "\n",
      "      A    B    C    D\n",
      "0 1.00 2.20 0.80 1.00\n",
      "1 1.00 0.67 1.00 1.33\n",
      "2 1.00 0.67 1.33 0.33\n",
      "3 1.00 0.75 1.25 2.00 \n",
      "\n",
      "0    55\n",
      "1     6\n",
      "2    24\n",
      "3    12\n",
      "dtype: int64 \n",
      "\n",
      "0   -6\n",
      "1    1\n",
      "2    2\n",
      "3    1\n",
      "dtype: int64 \n",
      "\n",
      "0    5_11\n",
      "1     3_2\n",
      "2     6_4\n",
      "3     4_3\n",
      "dtype: object \n",
      "\n",
      "      A     B     C     D\n",
      "0   nan   nan   nan   nan\n",
      "1 -2.00 -9.00 -1.00 -1.00\n",
      "2  3.00  2.00  5.00 -2.00\n",
      "3 -2.00 -1.00 -3.00  6.00 \n",
      "\n",
      "A   3.00\n",
      "B   2.00\n",
      "C   5.00\n",
      "D   6.00\n",
      "dtype: float64\n",
      "\n",
      "     A     B     C     D\n",
      "0 nan  6.00 -7.00  1.00\n",
      "1 nan -1.00  1.00  1.00\n",
      "2 nan -2.00  4.00 -6.00\n",
      "3 nan -1.00  2.00  3.00\n"
     ]
    }
   ],
   "source": [
    "# arith operations on data frame(div, multiply, add, subtract)\n",
    "df = pd.DataFrame({\"A\":[5, 3, None, 4],\n",
    "                   \"B\":[None, 2, 4, 3],\n",
    "                   \"C\":[4, 3, 8, 5],\n",
    "                   \"D\":[5, 4, 2, None]})\n",
    "print(df.div(2, fill_value = 50),'\\n') # fill na by a value \n",
    "print((df.C / 5.7).round(2)) # broadcasting(both div and round)\n",
    "# div of a df by series(by one of df's col)\n",
    "df = pd.DataFrame({\"A\":[5, 3, 6, 4],\n",
    "                   \"B\":[11, 2, 4, 3],\n",
    "                   \"C\":[4, 3, 8, 5],\n",
    "                   \"D\":[5, 4, 2, 8]}) \n",
    "print('\\n',df.div(df['A'], axis = 0),'\\n')\n",
    "print(df['A'].multiply(df['B']),'\\n') # mul of two col's\n",
    "print(df['A'] - df['B'],'\\n') # subtract two col's\n",
    "print(df['A'].astype(str) + '_' + df['B'].astype(str),'\\n') # add two col's\n",
    "print(df.diff(),'\\n') # subtract row wise\n",
    "print(df.diff().max()) # get max of above subtraction\n",
    "print('\\n',df.diff(axis = 1, periods = 1)) # subtract col wise "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LA</th>\n",
       "      <td>8.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>7.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NYC</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SF</th>\n",
       "      <td>3.00</td>\n",
       "      <td>nan</td>\n",
       "      <td>5.00</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       A    B    C    D\n",
       "LA  8.00 3.00 8.00 7.00\n",
       "NYC 0.00 1.00 2.00 1.00\n",
       "SF  3.00  nan 5.00 4.00"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add two df's and fill na values\n",
    "dframe1 = pd.DataFrame(np.arange(4).reshape(2,2),columns=list('AB'),index=['NYC','LA'])\n",
    "dframe2 = pd.DataFrame(np.arange(9).reshape(3,3),columns=list('ADC'),index=['NYC','SF','LA'])\n",
    "dframe1.add(dframe2,fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   column 1 column 2 column 3\n",
      "0         1        a        A\n",
      "1         1        a        A\n",
      "2         2        b        B\n",
      "3         2        b        B\n",
      "4         3        c        C\n",
      "5         3        c        C\n",
      "6         3        c        C \n",
      "\n",
      "0    False\n",
      "1     True\n",
      "2    False\n",
      "3     True\n",
      "4    False\n",
      "5     True\n",
      "6     True\n",
      "dtype: bool \n",
      "\n",
      "True \n",
      "\n",
      "4\n",
      "   column 1 column 2 column 3\n",
      "0         1        a        A\n",
      "2         2        b        B\n",
      "4         3        c        C \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k1</th>\n",
       "      <th>k2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>two</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    k1  k2\n",
       "0  one   2\n",
       "1  two   3"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop duplicates\n",
    "data = pd.DataFrame({'k1': ['one', 'two', 'one', 'two'],\n",
    "                     'k2': [1, 1, 2, 3]})\n",
    "\n",
    "DF_obj= pd.DataFrame({'column 1':[1,1,2,2,3,3,3],\n",
    "                   'column 2':['a', 'a','b', 'b', 'c', 'c', 'c'],\n",
    "                   'column 3':['A', 'A', 'B', 'B', 'C', 'C', 'C']})\n",
    "\n",
    "# find duplicate rows\n",
    "print(DF_obj,'\\n')\n",
    "print(DF_obj.duplicated(),'\\n')\n",
    "# find if df has duplicates at all \n",
    "print(DF_obj.duplicated().values.any(),'\\n')\n",
    "# no of duplicate rows \n",
    "print(len(DF_obj[DF_obj.duplicated()]))\n",
    "# drop duplictaes in entire df \n",
    "print(DF_obj.drop_duplicates(),'\\n')\n",
    "# drop duplicates in a particular column, you can give list of columns also as a subset for del dup\n",
    "dfs = data.drop_duplicates('k1',keep='last').reset_index(drop = True)\n",
    "dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   col1  col2 col3\n",
      "0     1   444  abc\n",
      "1     2   555  def\n",
      "2     3   666  ghi\n",
      "3     4   444  xyz \n",
      "\n",
      "0     1\n",
      "1     4\n",
      "2     9\n",
      "3    16\n",
      "Name: col1, dtype: int64 \n",
      "\n",
      "col1      10\n",
      "col2    2109\n",
      "dtype: int64 \n",
      "\n",
      "0    3\n",
      "1    3\n",
      "2    3\n",
      "3    3\n",
      "Name: col3, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Company\n",
       "FB      243\n",
       "GOOG    120\n",
       "MSFT    124\n",
       "Name: Sales, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# applying custom fns to columns \n",
    "print(dfo,'\\n')\n",
    "print(dfo['col1'].apply(lambda x:x**2),'\\n')\n",
    "print(dfo[['col1','col2']].apply(sum),'\\n')\n",
    "print(dfo['col3'].apply(len))\n",
    "# apply custom fns to group\n",
    "def second(values):\n",
    "    \"\"\"Return second highest value\n",
    "\n",
    "    >>> second([1, 7, 9, 3, 5])\n",
    "    7\n",
    "    \"\"\"\n",
    "    top, second = -1, -1\n",
    "    for value in values:\n",
    "        if value > top:\n",
    "            top, second = value, top\n",
    "        elif value > second:\n",
    "            second = value\n",
    "    return second\n",
    "group['Sales'].apply(second)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.00% bad rows\n",
      "bad rows:\n",
      "                 time symbol  price side\n",
      "0 2027-06-01 08:06:32    NaN 265.44  ask\n"
     ]
    }
   ],
   "source": [
    "# conditional selection using custom fn\n",
    "df = pd.read_csv('data/orders.csv', parse_dates=['time'])\n",
    "def is_valid_row(row):\n",
    "    if row['time'] < pd.Timestamp('1900'):\n",
    "        return False\n",
    "    if pd.isnull(row['symbol']) or row['symbol'].strip() == '':\n",
    "        return False\n",
    "    if row['price'] <= 0:\n",
    "        return False\n",
    "    return True\n",
    "ok_df = df[df.apply(is_valid_row, axis=1)] # axis 1 :- col \n",
    "num_bad = len(df) - len(ok_df)\n",
    "percent_bad = num_bad/len(df) * 100\n",
    "print(f'{percent_bad:.2f}% bad rows')\n",
    "if num_bad > 0:\n",
    "    bad_rows = df[~df.index.isin(ok_df.index)]\n",
    "    print('bad rows:')\n",
    "    print(bad_rows.reset_index(drop = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    11\n",
       "3    15\n",
       "4    18\n",
       "dtype: int64"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# custom functions with arguments \n",
    "ser = pd.Series([11, 22, 33, 15, 18])\n",
    "def between(x, low, high):\n",
    "    return x >= low and x <= high\n",
    "ser[ser.apply(between, args=(10,20))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Region Team Squad  Revenue  Cost  Profit\n",
      "0  North  One     A     7500  5200  Profit\n",
      "1   West  One     B     5500  5100  Profit\n",
      "2   East  One     C     2750  4400    Loss\n",
      "3  South  One     D     6400  5300  Profit\n",
      "4  North  Two     E     2300  1250  Profit\n",
      "5   West  Two     F     3750  1300  Profit\n",
      "6   East  Two     G     1900  2100    Loss\n",
      "7  South  Two     H      575    50  Profit \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Region</th>\n",
       "      <th>Team</th>\n",
       "      <th>Squad</th>\n",
       "      <th>Revenue</th>\n",
       "      <th>Cost</th>\n",
       "      <th>Profit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Region  Team  Squad  Revenue  Cost  Profit\n",
       "0       5     3      1        4     4       6\n",
       "1       4     3      1        4     4       6\n",
       "2       4     3      1        4     4       4\n",
       "3       5     3      1        4     4       6\n",
       "4       5     3      1        4     4       6\n",
       "5       4     3      1        4     4       6\n",
       "6       4     3      1        4     4       4\n",
       "7       5     3      1        3     2       6"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# applying fns with ternary condition on df columns \n",
    "df = pd.DataFrame({\"Region\":['North','West','East','South','North','West','East','South'],\n",
    "          \"Team\":['One','One','One','One','Two','Two','Two','Two'],\n",
    "          \"Squad\":['A','B','C','D','E','F','G','H'],\n",
    "          \"Revenue\":[7500,5500,2750,6400,2300,3750,1900,575],\n",
    "            \"Cost\":[5200,5100,4400,5300,1250,1300,2100,50]})\n",
    "df['Profit'] = df.apply(lambda x: 'Profit' if x['Revenue']>x['Cost'] else 'Loss',axis=1)\n",
    "print(df,'\\n')\n",
    "# applying custom fn to whole data frame \n",
    "df = df.applymap(lambda x: len(str(x)))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col1</th>\n",
       "      <th>col2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sum</th>\n",
       "      <td>10.0</td>\n",
       "      <td>2109.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.5</td>\n",
       "      <td>527.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      col1     col2\n",
       "sum   10.0  2109.00\n",
       "mean   2.5   527.25"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# aggregation (applying many functions at a time)\n",
    "dfo[['col1','col2']].aggregate([sum,mean])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   A  B   C   D     E\n",
      "0  1  5  10  16   9.0\n",
      "1  5  8   4  17  13.5\n",
      "2  7  4   9  20  17.0\n",
      "3  8  3   3  14  15.0\n"
     ]
    }
   ],
   "source": [
    "# evaluate expressions \n",
    "df=pd.DataFrame({\"A\":[1,5,7,8],\n",
    "                 \"B\":[5,8,4,3],\n",
    "                 \"C\":[10,4,9,3]})\n",
    "df.eval('D = A + B + C', inplace = True)\n",
    "avg_cols = df.mean(1) # average of cols, 0->average of rows \n",
    "# using local variables\n",
    "result2 = df.eval('A + @avg_cols')\n",
    "df['E'] = result2\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>plate</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gomez</td>\n",
       "      <td>1XZ2</td>\n",
       "      <td>3.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Morticia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fester</td>\n",
       "      <td></td>\n",
       "      <td>3.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Wednesday</td>\n",
       "      <td>A</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Pugsley</td>\n",
       "      <td>ZF003</td>\n",
       "      <td>153.14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        name  plate  distance\n",
       "0      Gomez   1XZ2      3.70\n",
       "1   Morticia    NaN      2.10\n",
       "2     Fester             3.40\n",
       "5  Wednesday      A      0.30\n",
       "6    Pugsley  ZF003    153.14"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# conditional selection with eval\n",
    "df = pd.read_csv('data/ride.csv')\n",
    "mask = df.eval('name.isnull() | distance <= 0')\n",
    "df = df[~mask]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  student school  english   math  physics\n",
      "0    Andy      Z       10     20       30\n",
      "1  Bernie      Y      100    200      300\n",
      "2   Cindy      Z     1000   2000     3000\n",
      "3     Deb      Y    10000  20000    30000 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student</th>\n",
       "      <th>school</th>\n",
       "      <th>cLaSs</th>\n",
       "      <th>gRaDe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Andy</td>\n",
       "      <td>Z</td>\n",
       "      <td>english</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bernie</td>\n",
       "      <td>Y</td>\n",
       "      <td>english</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cindy</td>\n",
       "      <td>Z</td>\n",
       "      <td>english</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Deb</td>\n",
       "      <td>Y</td>\n",
       "      <td>english</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Andy</td>\n",
       "      <td>Z</td>\n",
       "      <td>math</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Bernie</td>\n",
       "      <td>Y</td>\n",
       "      <td>math</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Cindy</td>\n",
       "      <td>Z</td>\n",
       "      <td>math</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Deb</td>\n",
       "      <td>Y</td>\n",
       "      <td>math</td>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Andy</td>\n",
       "      <td>Z</td>\n",
       "      <td>physics</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Bernie</td>\n",
       "      <td>Y</td>\n",
       "      <td>physics</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Cindy</td>\n",
       "      <td>Z</td>\n",
       "      <td>physics</td>\n",
       "      <td>3000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Deb</td>\n",
       "      <td>Y</td>\n",
       "      <td>physics</td>\n",
       "      <td>30000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   student school    cLaSs  gRaDe\n",
       "0     Andy      Z  english     10\n",
       "1   Bernie      Y  english    100\n",
       "2    Cindy      Z  english   1000\n",
       "3      Deb      Y  english  10000\n",
       "4     Andy      Z     math     20\n",
       "5   Bernie      Y     math    200\n",
       "6    Cindy      Z     math   2000\n",
       "7      Deb      Y     math  20000\n",
       "8     Andy      Z  physics     30\n",
       "9   Bernie      Y  physics    300\n",
       "10   Cindy      Z  physics   3000\n",
       "11     Deb      Y  physics  30000"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# wide to long format \n",
    "df_wide = pd.DataFrame(\n",
    "  {\"student\": [\"Andy\", \"Bernie\", \"Cindy\", \"Deb\"],\n",
    "   \"school\":  [\"Z\", \"Y\", \"Z\", \"Y\"],\n",
    "   \"english\": [10, 100, 1000, 10000],  # eng grades\n",
    "   \"math\":    [20, 200, 2000, 20000],  # math grades\n",
    "   \"physics\": [30, 300, 3000, 30000]   # physics grades\n",
    "  }\n",
    ")\n",
    "print(df_wide,'\\n')\n",
    "df_wide.melt(id_vars=[\"student\", \"school\"],\n",
    "             var_name=\"cLaSs\",  \n",
    "             value_name=\"gRaDe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.970725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>-0.970725</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          A         B\n",
       "A  1.000000 -0.970725\n",
       "B -0.970725  1.000000"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# correlation b/w two columns \n",
    "dfn[['A','B']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A   -0.041703\n",
      "B   -0.151186\n",
      "C    0.395437\n",
      "dtype: float64 \n",
      "\n",
      "0   -0.195254\n",
      "1   -0.970725\n",
      "2    0.993399\n",
      "3    0.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# corr b/w two data frames \n",
    "corr_df1 = pd.DataFrame({\"A\":[1, 5, 7, 8],\n",
    "                    \"B\":[5, 8, 4, 3],\n",
    "                    \"C\":[10, 4, 9, 3]})\n",
    "  \n",
    "# Creating the second dataframe \n",
    "corr_df2 = pd.DataFrame({\"A\":[5, 3, 6, 4],\n",
    "                    \"B\":[11, 2, 4, 3], \n",
    "                    \"C\":[4, 3, 8, 5]})\n",
    "  \n",
    "# To find the correlation among the columns of df1 and df2 \n",
    "print(corr_df1.corrwith(corr_df2),'\\n')\n",
    "# To find the correlation among the rows of df1 and df2 \n",
    "print(corr_df1.corrwith(corr_df2,axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       grade\n",
      "0   3.648651\n",
      "1   5.959915\n",
      "2   7.387370\n",
      "3   4.047515\n",
      "4   2.846912\n",
      "..       ...\n",
      "95  3.940691\n",
      "96  9.120705\n",
      "97  7.842357\n",
      "98  3.920676\n",
      "99  5.485459\n",
      "\n",
      "[100 rows x 1 columns] \n",
      "\n",
      "       grade\n",
      "33  5.663904\n",
      "1   5.959915\n",
      "75  4.204147\n",
      "87  7.712100\n",
      "44  3.791128\n",
      "..       ...\n",
      "16  3.267280\n",
      "29  6.229383\n",
      "57  3.784574\n",
      "72  4.413451\n",
      "78  5.085034\n",
      "\n",
      "[100 rows x 1 columns] \n",
      "\n",
      "5.066896    3\n",
      "8.419049    3\n",
      "4.081780    3\n",
      "6.053939    3\n",
      "4.912927    3\n",
      "           ..\n",
      "5.959915    1\n",
      "8.019990    1\n",
      "7.993867    1\n",
      "2.130382    1\n",
      "8.467353    1\n",
      "Name: grade, Length: 68, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# randomly Return a random sample of items from an object.\n",
    "pop = pd.read_csv('data/grades.csv')\n",
    "print(pop,'\\n')\n",
    "pop1 = pop.sample(100,replace = True) #replace allows sampling of the same row more than once.\n",
    "print(pop1,'\\n')\n",
    "print(pop1.grade.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# practice example's "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count no of values in each column w.r.t coditional selection \n",
    "ecom = pd.read_csv('data/Ecommerce Purchases')\n",
    "ecom[(ecom['CC Provider']=='American Express') & (ecom['Purchase Price']>95)].count()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hotmail.com     1638\n",
       "yahoo.com       1616\n",
       "gmail.com       1605\n",
       "smith.com         42\n",
       "williams.com      37\n",
       "Name: Email, dtype: int64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get 5 top most emails \n",
    "ecom['Email'].apply(lambda x: x.split('@')[1]).value_counts().head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# excel writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team</th>\n",
       "      <th>Rank</th>\n",
       "      <th>Year</th>\n",
       "      <th>Points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Riders</td>\n",
       "      <td>1</td>\n",
       "      <td>2014</td>\n",
       "      <td>876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Riders</td>\n",
       "      <td>2</td>\n",
       "      <td>2015</td>\n",
       "      <td>789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Devils</td>\n",
       "      <td>2</td>\n",
       "      <td>2014</td>\n",
       "      <td>863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Devils</td>\n",
       "      <td>3</td>\n",
       "      <td>2015</td>\n",
       "      <td>673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kings</td>\n",
       "      <td>3</td>\n",
       "      <td>2014</td>\n",
       "      <td>741</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Team  Rank  Year  Points\n",
       "0  Riders     1  2014     876\n",
       "1  Riders     2  2015     789\n",
       "2  Devils     2  2014     863\n",
       "3  Devils     3  2015     673\n",
       "4   Kings     3  2014     741"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ipl_data = {'Team': ['Riders', 'Riders', 'Devils', 'Devils', 'Kings',\n",
    "   'kings', 'Kings', 'Kings', 'Riders', 'Royals', 'Royals', 'Riders'],\n",
    "   'Rank': [1, 2, 2, 3, 3,4 ,1 ,1,2 , 4,1,2],\n",
    "   'Year': [2014,2015,2014,2015,2014,2015,2016,2017,2016,2014,2015,2017],\n",
    "   'Points':[876,789,863,673,741,812,756,788,694,701,804,690]}\n",
    "df = pd.DataFrame(ipl_data)\n",
    "writer = pd.ExcelWriter('biodata.xlsx')\n",
    "df.to_excel(writer, 'Sheet1',header=True,index=None)\n",
    "writer.save()\n",
    "df = pd.read_excel('biodata.xlsx', sheet_name='Sheet1')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>animal</th>\n",
       "      <th>ounces</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pig</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pig</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pig</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cow</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cow</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>pig</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cow</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>pig</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>salmon</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   animal  ounces\n",
       "0     pig     4.0\n",
       "1     pig     3.0\n",
       "2     pig    12.0\n",
       "3     cow     6.0\n",
       "4     cow     7.5\n",
       "5     pig     8.0\n",
       "6     cow     3.0\n",
       "7     pig     5.0\n",
       "8  salmon     6.0"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transforming data using mapping \n",
    "# works as a replace function \n",
    "# replace column name \n",
    "data = pd.DataFrame({'food': ['bacon', 'pulled pork', 'bacon',\n",
    "                              'Pastrami', 'corned beef', 'Bacon',\n",
    "                              'pastrami', 'honey ham', 'nova lox'],\n",
    "                     'ounces': [4, 3, 12, 6, 7.5, 8, 3, 5, 6]})\n",
    "data\n",
    "meat_to_animal = {\n",
    "  'bacon': 'pig',\n",
    "  'pulled pork': 'pig',\n",
    "  'pastrami': 'cow',\n",
    "  'corned beef': 'cow',\n",
    "  'honey ham': 'pig',\n",
    "  'nova lox': 'salmon'\n",
    "}\n",
    "data['food'] = data['food'].map(lambda x: meat_to_animal[x.lower()])\n",
    "data.rename(columns={'food':'animal'},inplace=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1. First Name 2. Last Name  3. Donation Amount\n",
      "0           Amy         Wang                 200\n",
      "1        Bender    Rodriguez                  12\n",
      "2        Philip          Fry                  70 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>donation_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Amy</td>\n",
       "      <td>Wang</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bender</td>\n",
       "      <td>Rodriguez</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Philip</td>\n",
       "      <td>Fry</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  first_name  last_name  donation_amount\n",
       "0        Amy       Wang              200\n",
       "1     Bender  Rodriguez               12\n",
       "2     Philip        Fry               70"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# renaming with custom fn \n",
    "import re\n",
    "df = pd.read_csv('data/donations.csv')\n",
    "print(df,'\\n')\n",
    "def fix_col(col):\n",
    "    \"\"\"Fix column name\n",
    "    >>> fix_col('1. First Name')\n",
    "    'first_name'\n",
    "    \"\"\"\n",
    "    return re.sub(r'\\d+\\.\\s+', '', col).lower().replace(' ', '_')\n",
    "df.rename(columns=fix_col, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Name           Team  Number Position   Age Height  Weight  \\\n",
      "0     Avery Bradley  Omega Warrior    0.00       PG 25.00    6-2  180.00   \n",
      "1       Jae Crowder  Omega Warrior   99.00       SF 25.00    6-6  235.00   \n",
      "2      John Holland  Omega Warrior   30.00       SG 27.00    6-5  205.00   \n",
      "3       R.J. Hunter  Omega Warrior   28.00       SG 22.00    6-5  185.00   \n",
      "4     Jonas Jerebko  Omega Warrior    8.00       PF 29.00   6-10  231.00   \n",
      "5      Amir Johnson  Omega Warrior   90.00       PF 29.00    6-9  240.00   \n",
      "6     Jordan Mickey  Omega Warrior   55.00       PF 21.00    6-8  235.00   \n",
      "7      Kelly Olynyk  Omega Warrior   41.00        C 25.00    7-0  238.00   \n",
      "8      Terry Rozier  Omega Warrior   12.00       PG 22.00    6-2  190.00   \n",
      "9      Marcus Smart  Omega Warrior   36.00       PG 22.00    6-4  220.00   \n",
      "10  Jared Sullinger  Omega Warrior    7.00        C 24.00    6-9  260.00   \n",
      "11    Isaiah Thomas  Omega Warrior    4.00       PG 27.00    5-9  185.00   \n",
      "12      Evan Turner  Omega Warrior   11.00       SG 27.00    6-7  220.00   \n",
      "13      James Young  Omega Warrior   13.00       SG 20.00    6-6  215.00   \n",
      "14     Tyler Zeller  Omega Warrior   44.00        C 26.00    7-0  253.00   \n",
      "\n",
      "              College        Salary  \n",
      "0               Texas  7,730,337.00  \n",
      "1           Marquette  6,796,117.00  \n",
      "2   Boston University           nan  \n",
      "3       Georgia State  1,148,640.00  \n",
      "4                 NaN  5,000,000.00  \n",
      "5                 NaN 12,000,000.00  \n",
      "6                 LSU  1,170,960.00  \n",
      "7             Gonzaga  2,165,160.00  \n",
      "8          Louisville  1,824,360.00  \n",
      "9      Oklahoma State  3,431,040.00  \n",
      "10         Ohio State  2,569,260.00  \n",
      "11         Washington  6,912,869.00  \n",
      "12         Ohio State  3,425,510.00  \n",
      "13           Kentucky  1,749,840.00  \n",
      "14     North Carolina  2,616,975.00  \n"
     ]
    }
   ],
   "source": [
    "# replace data \n",
    "# it can replace a list also\n",
    "df = pd.read_csv(\"data/nba.csv\")\n",
    "df['Team'].replace(to_replace =\"Boston Celtics\", \n",
    "                            value = \"Omega Warrior\", inplace = True)\n",
    "print(df[df['Team'] == 'Omega Warrior'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Typ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0 GL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Raptor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mach-E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mach-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Typ\n",
       "0  2.0 GL\n",
       "1  Raptor\n",
       "2  Mach-E\n",
       "2  Mach-1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converts each column specified into a row\n",
    "data = {\n",
    "  \"Brand\": [\"Ford\", \"Ford\", \"Ford\"],\n",
    "  \"Model\": [\"Sierra\", \"F-150\", \"Mustang\"],\n",
    "  \"Typ\" : [\"2.0 GL\", \"Raptor\", [\"Mach-E\", \"Mach-1\"]]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "newdf = df.Typ.explode().to_frame('Typ')\n",
    "newdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Page</th>\n",
       "      <th>Pageviews</th>\n",
       "      <th>Unique Pageviews</th>\n",
       "      <th>Avg. Time on Page</th>\n",
       "      <th>Entrances</th>\n",
       "      <th>Bounce Rate</th>\n",
       "      <th>% Exit</th>\n",
       "      <th>Page Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://miratrix.co.uk/</td>\n",
       "      <td>813</td>\n",
       "      <td>665</td>\n",
       "      <td>00:02:05</td>\n",
       "      <td>641</td>\n",
       "      <td>14.35%</td>\n",
       "      <td>55.97%</td>\n",
       "      <td>£0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://miratrix.co.uk/</td>\n",
       "      <td>515</td>\n",
       "      <td>388</td>\n",
       "      <td>00:02:17</td>\n",
       "      <td>373</td>\n",
       "      <td>59.25%</td>\n",
       "      <td>56.89%</td>\n",
       "      <td>£0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://miratrix.co.uk/get-in-touch/</td>\n",
       "      <td>336</td>\n",
       "      <td>163</td>\n",
       "      <td>00:01:06</td>\n",
       "      <td>23</td>\n",
       "      <td>10.53%</td>\n",
       "      <td>33.04%</td>\n",
       "      <td>£0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://miratrix.co.uk/app-marketing-agency/</td>\n",
       "      <td>140</td>\n",
       "      <td>120</td>\n",
       "      <td>00:02:04</td>\n",
       "      <td>73</td>\n",
       "      <td>18.31%</td>\n",
       "      <td>57.86%</td>\n",
       "      <td>£0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://miratrix.co.uk/app-store-optimization-...</td>\n",
       "      <td>136</td>\n",
       "      <td>105</td>\n",
       "      <td>00:01:30</td>\n",
       "      <td>22</td>\n",
       "      <td>14.29%</td>\n",
       "      <td>47.79%</td>\n",
       "      <td>£0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Page  Pageviews  \\\n",
       "0                            https://miratrix.co.uk/        813   \n",
       "1                            https://miratrix.co.uk/        515   \n",
       "2               https://miratrix.co.uk/get-in-touch/        336   \n",
       "3       https://miratrix.co.uk/app-marketing-agency/        140   \n",
       "4  https://miratrix.co.uk/app-store-optimization-...        136   \n",
       "\n",
       "   Unique Pageviews Avg. Time on Page  Entrances Bounce Rate  % Exit  \\\n",
       "0               665          00:02:05        641      14.35%  55.97%   \n",
       "1               388          00:02:17        373      59.25%  56.89%   \n",
       "2               163          00:01:06         23      10.53%  33.04%   \n",
       "3               120          00:02:04         73      18.31%  57.86%   \n",
       "4               105          00:01:30         22      14.29%  47.79%   \n",
       "\n",
       "  Page Value  \n",
       "0      £0.00  \n",
       "1      £0.00  \n",
       "2      £0.00  \n",
       "3      £0.00  \n",
       "4      £0.00  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split column and append them by shifting their pos after replacing the words\n",
    "# esp used for url's\n",
    "ga_page_data = pd.read_csv('data/ga_pages.csv', skiprows=6, nrows=376)\n",
    "split_dom = ga_page_data.Page.str.rpartition(\"/\")\n",
    "split_dom[2].replace(\"\", \"miratrix.co.uk\", inplace=True)\n",
    "split_dom[2].replace(\"www.miratrix.co.uk\", \"miratrix.co.uk\", inplace=True)\n",
    "ga_page_data.Page = \"https://\" + split_dom[2] + split_dom[0] + \"/\"\n",
    "ga_page_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time series "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2011-01-02    0.282415\n",
       "2011-01-05   -0.300013\n",
       "2011-01-07    0.306791\n",
       "2011-01-08   -0.342515\n",
       "2011-01-10   -1.003663\n",
       "2011-01-12   -0.193869\n",
       "dtype: float64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "dates = [datetime(2011, 1, 2), datetime(2011, 1, 5),\n",
    "         datetime(2011, 1, 7), datetime(2011, 1, 8),\n",
    "         datetime(2011, 1, 10), datetime(2011, 1, 12)]\n",
    "ts = pd.Series(random.randn(6), index=dates)\n",
    "ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000-01-01   -1.36\n",
       "2000-01-03   -0.75\n",
       "2000-01-05   -0.63\n",
       "2000-01-07    2.05\n",
       "2000-01-09    0.88\n",
       "2000-01-11    2.06\n",
       "2000-01-13    0.29\n",
       "2000-01-15    0.33\n",
       "2000-01-17   -0.15\n",
       "2000-01-19   -0.05\n",
       "Freq: 2D, dtype: float64"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "longer_ts = pd.Series(random.randn(1000),\n",
    "                      index=pd.date_range('1/1/2000', periods=1000))\n",
    "longer_ts[:20:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Colorado</th>\n",
       "      <th>Texas</th>\n",
       "      <th>New York</th>\n",
       "      <th>Ohio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-01-05</th>\n",
       "      <td>0.343955</td>\n",
       "      <td>0.706824</td>\n",
       "      <td>-0.224731</td>\n",
       "      <td>0.007099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-12</th>\n",
       "      <td>0.568859</td>\n",
       "      <td>-0.814084</td>\n",
       "      <td>0.576943</td>\n",
       "      <td>-0.572930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-19</th>\n",
       "      <td>-0.110129</td>\n",
       "      <td>-0.355832</td>\n",
       "      <td>-0.480219</td>\n",
       "      <td>0.541110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-26</th>\n",
       "      <td>-0.953903</td>\n",
       "      <td>-1.419825</td>\n",
       "      <td>-1.886654</td>\n",
       "      <td>2.134744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-02-02</th>\n",
       "      <td>-0.011643</td>\n",
       "      <td>0.836294</td>\n",
       "      <td>-0.139921</td>\n",
       "      <td>0.076219</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Colorado     Texas  New York      Ohio\n",
       "2000-01-05  0.343955  0.706824 -0.224731  0.007099\n",
       "2000-01-12  0.568859 -0.814084  0.576943 -0.572930\n",
       "2000-01-19 -0.110129 -0.355832 -0.480219  0.541110\n",
       "2000-01-26 -0.953903 -1.419825 -1.886654  2.134744\n",
       "2000-02-02 -0.011643  0.836294 -0.139921  0.076219"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# periods gives no of values and freq tells the difference between any two values\n",
    "# w-wed means week wednesday \n",
    "dates = pd.date_range('1/1/2000', periods=100, freq='W-WED')\n",
    "long_df = pd.DataFrame(random.randn(100, 4),\n",
    "                       index=dates,\n",
    "                       columns=['Colorado', 'Texas',\n",
    "                                'New York', 'Ohio'])\n",
    "long_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1993-10-05 07:30:00\n",
      "2021-11-19 01:39:10.090366\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    Wednesday\n",
       "1       Friday\n",
       "2       Sunday\n",
       "3      Tuesday\n",
       "Name: sample date, dtype: object"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert to time stamp(pandas equivalent of python’s Datetime)\n",
    "print(pd.Timestamp(1993,10,5,7,30,00))\n",
    "print(pd.Timestamp.now()) # current date and time \n",
    "daterange = pd.period_range('1/1/2020', freq='30d', periods=4)\n",
    "date_df = pd.DataFrame(data=daterange,columns=['sample date'])\n",
    "date_df['sample date'] = date_df['sample date'].dt.to_timestamp()\n",
    "date_df['sample date'].dt.day_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Date      Time\n",
      "0   8/6/1993  12:42 PM\n",
      "1  3/31/1996   6:53 AM\n",
      "2  4/23/1993  11:17 AM\n",
      "3   3/4/2005   1:00 PM\n",
      "4  1/24/1998   4:47 PM\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1993-08-06</td>\n",
       "      <td>12:42 PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1996-03-31</td>\n",
       "      <td>6:53 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1993-04-23</td>\n",
       "      <td>11:17 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2005-03-04</td>\n",
       "      <td>1:00 PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1998-01-24</td>\n",
       "      <td>4:47 PM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date      Time\n",
       "0 1993-08-06  12:42 PM\n",
       "1 1996-03-31   6:53 AM\n",
       "2 1993-04-23  11:17 AM\n",
       "3 2005-03-04   1:00 PM\n",
       "4 1998-01-24   4:47 PM"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convert normal string column to date time column \n",
    "data = pd.read_csv(\"data/todatetime.csv\")  \n",
    "print(data.head())\n",
    "# overwriting data after changing format\n",
    "data[\"Date\"]= pd.to_datetime(data[\"Date\"])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time series index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              A     B\n",
      "2016-03-15 01:00:00+01:00 -0.43 -0.62\n",
      "2017-05-24 02:00:00+02:00  0.70 -0.61\n",
      "2018-08-09 02:00:00+02:00 -0.30 -1.12 \n",
      "\n",
      "DatetimeIndex(['2016-03-15 01:00:00+01:00', '2017-05-24 02:00:00+02:00',\n",
      "               '2018-08-09 02:00:00+02:00'],\n",
      "              dtype='datetime64[ns, Europe/Berlin]', freq=None)\n"
     ]
    }
   ],
   "source": [
    "import pytz\n",
    "some_dates = array(['2016-03-15', '2017-05-24', '2018-08-09'], dtype='datetime64[D]')\n",
    "idx = pd.DatetimeIndex(some_dates)\n",
    "data = random.randn(3,2)\n",
    "cols = ['A','B']\n",
    "df = pd.DataFrame(data,idx,cols)\n",
    "# set a specific time zone \n",
    "df.index = df.index.tz_localize(pytz.UTC).tz_convert(pytz.timezone('Europe/Berlin'))\n",
    "print(df,'\\n')\n",
    "print(df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatetimeIndex(['2020-01-04', '2020-01-05', '2020-01-06', '2020-01-07',\n",
      "               '2020-01-08'],\n",
      "              dtype='datetime64[ns]', freq='D')\n",
      "            Col1  Col2  Col3\n",
      "2020-01-04    10    13    17\n",
      "2020-01-05    20    23    27\n",
      "2020-01-06    15    18    22\n",
      "2020-01-07    30    33    37\n",
      "2020-01-08    45    48    52\n",
      "DatetimeIndex(['2020-01-01', '2020-01-02', '2020-01-03', '2020-01-04',\n",
      "               '2020-01-05'],\n",
      "              dtype='datetime64[ns]', freq='D') \n",
      " 2020-01-01 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# shifting time series index(like timedelta) \n",
    "df = pd.DataFrame({\"Col1\": [10, 20, 15, 30, 45],\n",
    "                   \"Col2\": [13, 23, 18, 33, 48],\n",
    "                   \"Col3\": [17, 27, 22, 37, 52]},\n",
    "                  index=pd.date_range(\"2020-01-01\", \"2020-01-05\"))\n",
    "print(df.index + pd.Timedelta('3 d'))\n",
    "print(df.shift(periods=3, freq=\"D\"))\n",
    "print(df.index, '\\n', df.index.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Col1  Col2  Col3\n",
      "3 days    10    13    17\n",
      "3 days    20    23    27\n",
      "3 days    15    18    22\n",
      "3 days    30    33    37\n",
      "3 days    45    48    52\n",
      "TimedeltaIndex(['3 days', '3 days', '3 days', '3 days', '3 days'], dtype='timedelta64[ns]', freq=None)\n"
     ]
    }
   ],
   "source": [
    "# time delta index(which is 3 here clearly)\n",
    "df.index = df.shift(periods=3, freq=\"D\").index - df.index \n",
    "print(df)\n",
    "print(df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   price  volume week_starting\n",
      "0     10      50    2018-01-07\n",
      "1     11      60    2018-01-14\n",
      "2      9      40    2018-01-21\n",
      "3     13     100    2018-01-28\n",
      "4     14      50    2018-02-04\n",
      "5     18     100    2018-02-11\n",
      "6     17      40    2018-02-18\n",
      "7     19      50    2018-02-25\n",
      "               price  volume\n",
      "week_starting               \n",
      "2018-01-31     10.75    62.5\n",
      "2018-02-28     17.00    60.0\n"
     ]
    }
   ],
   "source": [
    "# resampling (method of drawing repeated samples from the original data) based on time series data and creating bins \n",
    "d = {'price': [10, 11, 9, 13, 14, 18, 17, 19],\n",
    "     'volume': [50, 60, 40, 100, 50, 100, 40, 50]}\n",
    "df = pd.DataFrame(d)\n",
    "df['week_starting'] = pd.date_range('01/01/2018',\n",
    "                                    periods=8,\n",
    "                                    freq='W')\n",
    "print(df)\n",
    "print(df.resample('M', on='week_starting').mean())#monthly "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rolling window \n",
    "# we take a window size of k at a time and perform some desired mathematical operation on it. A window of size k means\n",
    "# k consecutive values at a time. In a very simple case all the ‘k’ values are equally weighted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     close         volume   open   high    low\n",
      "date                                                          \n",
      "2021-11-29 16:00:00 192.23     46,541,444 191.72 197.18 191.45\n",
      "2018-11-13 00:00:00 192.23  46725710.0000 191.63 197.18 191.45\n",
      "2018-11-12 00:00:00 194.17  50991030.0000 199.00 199.85 193.79\n",
      "2018-11-09 00:00:00 204.47  34317760.0000 205.55 206.01 202.25\n",
      "2018-11-08 00:00:00 208.49  25289270.0000 209.98 210.12 206.75\n",
      "\n",
      " date\n",
      "2021-11-29 16:00:00      nan\n",
      "2018-11-13 00:00:00   384.46\n",
      "2018-11-12 00:00:00   386.40\n",
      "2018-11-09 00:00:00   398.64\n",
      "2018-11-08 00:00:00   412.96\n",
      "Name: close, dtype: float64\n",
      "\n",
      " date\n",
      "2021-11-29 16:00:00      nan\n",
      "2018-11-13 00:00:00   192.23\n",
      "2018-11-12 00:00:00   193.20\n",
      "2018-11-09 00:00:00   199.32\n",
      "2018-11-08 00:00:00   206.48\n",
      "Name: close, dtype: float64\n",
      "\n",
      " date\n",
      "2021-11-29 16:00:00    nan\n",
      "2018-11-13 00:00:00   0.00\n",
      "2018-11-12 00:00:00   1.37\n",
      "2018-11-09 00:00:00   7.28\n",
      "2018-11-08 00:00:00   2.84\n",
      "Name: close, dtype: float64\n",
      "\n",
      " 2018-10-02 00:00:00 : 230.67500000000007\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/apple.csv\", parse_dates =[\"date\"], index_col =\"date\")\n",
    "print(df.head())\n",
    "print('\\n',df.close.rolling(2).sum().head())\n",
    "print('\\n',df.close.rolling(2, center=True).mean().head()) # moving average\n",
    "print('\\n',df.close.rolling(2).std().head())\n",
    "print('\\n',df.close.rolling(2).mean().idxmax(),':',df.close.rolling(2).mean().max()) # moving avg max and its index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DateTime</th>\n",
       "      <th>Trip ID</th>\n",
       "      <th>Membership Type</th>\n",
       "      <th>Bicycle ID</th>\n",
       "      <th>Checkout Kiosk ID</th>\n",
       "      <th>Checkout Kiosk</th>\n",
       "      <th>Return Kiosk ID</th>\n",
       "      <th>Return Kiosk</th>\n",
       "      <th>Trip Duration Minutes</th>\n",
       "      <th>Month</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4410</th>\n",
       "      <td>2016-11-13 16:09:46</td>\n",
       "      <td>12814168</td>\n",
       "      <td>Walk Up</td>\n",
       "      <td>872.0</td>\n",
       "      <td>2,499.00</td>\n",
       "      <td>City Hall / Lavaca &amp; 2nd</td>\n",
       "      <td>2498.0</td>\n",
       "      <td>Convention Center / 4th St. @ MetroRail</td>\n",
       "      <td>24</td>\n",
       "      <td>11.00</td>\n",
       "      <td>2,016.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4411</th>\n",
       "      <td>2016-11-13 14:27:07</td>\n",
       "      <td>12812573</td>\n",
       "      <td>Walk Up</td>\n",
       "      <td>72.0</td>\n",
       "      <td>2,503.00</td>\n",
       "      <td>South Congress &amp; James</td>\n",
       "      <td>2497.0</td>\n",
       "      <td>Capitol Station / Congress &amp; 11th</td>\n",
       "      <td>19</td>\n",
       "      <td>11.00</td>\n",
       "      <td>2,016.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4429</th>\n",
       "      <td>2016-11-20 14:32:21</td>\n",
       "      <td>12904946</td>\n",
       "      <td>Walk Up</td>\n",
       "      <td>37.0</td>\n",
       "      <td>2,549.00</td>\n",
       "      <td>Long Center @ South 1st &amp; Riverside</td>\n",
       "      <td>2711.0</td>\n",
       "      <td>Barton Springs @ Kinney Ave</td>\n",
       "      <td>29</td>\n",
       "      <td>11.00</td>\n",
       "      <td>2,016.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4438</th>\n",
       "      <td>2016-11-24 15:11:33</td>\n",
       "      <td>12958195</td>\n",
       "      <td>Walk Up</td>\n",
       "      <td>832.0</td>\n",
       "      <td>3,377.00</td>\n",
       "      <td>MoPac Pedestrian Bridge @ Veterans Drive</td>\n",
       "      <td>3377.0</td>\n",
       "      <td>MoPac Pedestrian Bridge @ Veterans Drive</td>\n",
       "      <td>532</td>\n",
       "      <td>11.00</td>\n",
       "      <td>2,016.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4439</th>\n",
       "      <td>2016-11-24 14:01:08</td>\n",
       "      <td>12956844</td>\n",
       "      <td>Walk Up</td>\n",
       "      <td>116.0</td>\n",
       "      <td>2,707.00</td>\n",
       "      <td>Rainey St @ Cummings</td>\n",
       "      <td>2549.0</td>\n",
       "      <td>Long Center @ South 1st &amp; Riverside</td>\n",
       "      <td>32</td>\n",
       "      <td>11.00</td>\n",
       "      <td>2,016.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4443</th>\n",
       "      <td>2016-11-26 13:26:27</td>\n",
       "      <td>12980542</td>\n",
       "      <td>Walk Up</td>\n",
       "      <td>855.0</td>\n",
       "      <td>2,502.00</td>\n",
       "      <td>Barton Springs &amp; Riverside</td>\n",
       "      <td>2537.0</td>\n",
       "      <td>West &amp; 6th St.</td>\n",
       "      <td>11</td>\n",
       "      <td>11.00</td>\n",
       "      <td>2,016.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4444</th>\n",
       "      <td>2016-11-26 13:07:43</td>\n",
       "      <td>12980363</td>\n",
       "      <td>Walk Up</td>\n",
       "      <td>410.0</td>\n",
       "      <td>2,494.00</td>\n",
       "      <td>2nd &amp; Congress</td>\n",
       "      <td>2494.0</td>\n",
       "      <td>2nd &amp; Congress</td>\n",
       "      <td>2</td>\n",
       "      <td>11.00</td>\n",
       "      <td>2,016.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4446</th>\n",
       "      <td>2016-11-27 14:31:26</td>\n",
       "      <td>12989946</td>\n",
       "      <td>Walk Up</td>\n",
       "      <td>520.0</td>\n",
       "      <td>2,575.00</td>\n",
       "      <td>Riverside @ S. Lamar</td>\n",
       "      <td>2549.0</td>\n",
       "      <td>Long Center @ South 1st &amp; Riverside</td>\n",
       "      <td>16</td>\n",
       "      <td>11.00</td>\n",
       "      <td>2,016.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4447</th>\n",
       "      <td>2016-11-27 15:36:53</td>\n",
       "      <td>12990581</td>\n",
       "      <td>Local365</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2,496.00</td>\n",
       "      <td>8th &amp; Congress</td>\n",
       "      <td>2494.0</td>\n",
       "      <td>2nd &amp; Congress</td>\n",
       "      <td>6</td>\n",
       "      <td>11.00</td>\n",
       "      <td>2,016.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4448</th>\n",
       "      <td>2016-11-27 14:20:11</td>\n",
       "      <td>12989842</td>\n",
       "      <td>Walk Up</td>\n",
       "      <td>226.0</td>\n",
       "      <td>2,563.00</td>\n",
       "      <td>Davis at Rainey Street</td>\n",
       "      <td>2570.0</td>\n",
       "      <td>South Congress &amp; Academy</td>\n",
       "      <td>20</td>\n",
       "      <td>11.00</td>\n",
       "      <td>2,016.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                DateTime   Trip ID Membership Type Bicycle ID  \\\n",
       "4410 2016-11-13 16:09:46  12814168         Walk Up      872.0   \n",
       "4411 2016-11-13 14:27:07  12812573         Walk Up       72.0   \n",
       "4429 2016-11-20 14:32:21  12904946         Walk Up       37.0   \n",
       "4438 2016-11-24 15:11:33  12958195         Walk Up      832.0   \n",
       "4439 2016-11-24 14:01:08  12956844         Walk Up      116.0   \n",
       "4443 2016-11-26 13:26:27  12980542         Walk Up      855.0   \n",
       "4444 2016-11-26 13:07:43  12980363         Walk Up      410.0   \n",
       "4446 2016-11-27 14:31:26  12989946         Walk Up      520.0   \n",
       "4447 2016-11-27 15:36:53  12990581        Local365       15.0   \n",
       "4448 2016-11-27 14:20:11  12989842         Walk Up      226.0   \n",
       "\n",
       "      Checkout Kiosk ID                            Checkout Kiosk  \\\n",
       "4410           2,499.00                  City Hall / Lavaca & 2nd   \n",
       "4411           2,503.00                    South Congress & James   \n",
       "4429           2,549.00       Long Center @ South 1st & Riverside   \n",
       "4438           3,377.00  MoPac Pedestrian Bridge @ Veterans Drive   \n",
       "4439           2,707.00                      Rainey St @ Cummings   \n",
       "4443           2,502.00                Barton Springs & Riverside   \n",
       "4444           2,494.00                            2nd & Congress   \n",
       "4446           2,575.00                      Riverside @ S. Lamar   \n",
       "4447           2,496.00                            8th & Congress   \n",
       "4448           2,563.00                    Davis at Rainey Street   \n",
       "\n",
       "     Return Kiosk ID                              Return Kiosk  \\\n",
       "4410          2498.0   Convention Center / 4th St. @ MetroRail   \n",
       "4411          2497.0         Capitol Station / Congress & 11th   \n",
       "4429          2711.0               Barton Springs @ Kinney Ave   \n",
       "4438          3377.0  MoPac Pedestrian Bridge @ Veterans Drive   \n",
       "4439          2549.0       Long Center @ South 1st & Riverside   \n",
       "4443          2537.0                            West & 6th St.   \n",
       "4444          2494.0                            2nd & Congress   \n",
       "4446          2549.0       Long Center @ South 1st & Riverside   \n",
       "4447          2494.0                            2nd & Congress   \n",
       "4448          2570.0                  South Congress & Academy   \n",
       "\n",
       "      Trip Duration Minutes  Month     Year  \n",
       "4410                     24  11.00 2,016.00  \n",
       "4411                     19  11.00 2,016.00  \n",
       "4429                     29  11.00 2,016.00  \n",
       "4438                    532  11.00 2,016.00  \n",
       "4439                     32  11.00 2,016.00  \n",
       "4443                     11  11.00 2,016.00  \n",
       "4444                      2  11.00 2,016.00  \n",
       "4446                     16  11.00 2,016.00  \n",
       "4447                      6  11.00 2,016.00  \n",
       "4448                     20  11.00 2,016.00  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# conditional selection using time series data \n",
    "from calendar import SATURDAY, SUNDAY\n",
    "holidays_2016 = pd.to_datetime([\n",
    "    '2016-01-01',  # new year\n",
    "    '2016-01-18',  # MLK\n",
    "    '2016-05-30',  # memorial\n",
    "    '2016-07-04',  # independence\n",
    "    '2016-09-05',  # labor\n",
    "    '2016-11-11',  # veterans\n",
    "    '2016-11-24',  # thanksgiving\n",
    "    '2016-12-26',  # christmas\n",
    "])\n",
    "\n",
    "aust_df = pd.read_csv(\n",
    "        'data/austin-bikes.csv',\n",
    "        parse_dates=[['Checkout Date', 'Checkout Time']]\n",
    "    )\n",
    "aust_df.rename(columns = {'Checkout Date_Checkout Time':'DateTime'},inplace = True)\n",
    "mask_2016 = aust_df['DateTime'].dt.year == 2016\n",
    "holiday_mask = (\n",
    "        (aust_df['DateTime'].dt.floor('D').isin(holidays_2016)) |\n",
    "        (aust_df['DateTime'].dt.weekday.isin([SATURDAY, SUNDAY]))\n",
    "    )\n",
    "afternoon_mask = (aust_df['DateTime'].dt.hour >= 12) & (aust_df['DateTime'].dt.hour < 18)\n",
    "aust_df[mask_2016 & holiday_mask & afternoon_mask].tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#Passengers</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Month</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1949-01-01</th>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1949-02-01</th>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1949-03-01</th>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1949-04-01</th>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1949-05-01</th>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            #Passengers\n",
       "Month                  \n",
       "1949-01-01          112\n",
       "1949-02-01          118\n",
       "1949-03-01          132\n",
       "1949-04-01          129\n",
       "1949-05-01          121"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# conditional selection using time series index values \n",
    "df = pd.read_csv('data/AirPassengers.csv', parse_dates=['Month'], index_col=['Month'])\n",
    "trn = df.loc[df.index < '1958-01-01']\n",
    "trn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-01-02</th>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-09</th>\n",
       "      <td>-0.71</td>\n",
       "      <td>-0.60</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-16</th>\n",
       "      <td>0.25</td>\n",
       "      <td>26.00</td>\n",
       "      <td>-0.65</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-23</th>\n",
       "      <td>-0.20</td>\n",
       "      <td>-0.94</td>\n",
       "      <td>2.00</td>\n",
       "      <td>-0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-30</th>\n",
       "      <td>-0.75</td>\n",
       "      <td>-0.33</td>\n",
       "      <td>-0.62</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-02-06</th>\n",
       "      <td>54.00</td>\n",
       "      <td>15.00</td>\n",
       "      <td>-0.38</td>\n",
       "      <td>-0.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               A     B     C     D\n",
       "2000-01-02   nan   nan   nan   nan\n",
       "2000-01-09 -0.71 -0.60  0.00 -0.79\n",
       "2000-01-16  0.25 26.00 -0.65  1.00\n",
       "2000-01-23 -0.20 -0.94  2.00 -0.67\n",
       "2000-01-30 -0.75 -0.33 -0.62  2.00\n",
       "2000-02-06 54.00 15.00 -0.38 -0.33"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# percentage change b/w rows\n",
    "# Creating the time-series index\n",
    "ind = pd.date_range('01/01/2000', periods = 6, freq ='W')\n",
    "# Creating the dataframe \n",
    "df = pd.DataFrame({\"A\":[14, 4, 5, 4, 1, 55],\n",
    "                   \"B\":[5, 2, 54, 3, 2, 32], \n",
    "                   \"C\":[20, 20, 7, 21, 8, 5],\n",
    "                   \"D\":[14, 3, 6, 2, 6, 4]}, index = ind)\n",
    "df.pct_change()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   basket_id    fruit  count  weight    Fruit\n",
      "0          0   apples      8    0.59   Apples\n",
      "1          1  oranges     11    1.14  Oranges\n",
      "2          2   apples      6    2.64   Apples\n",
      "3          3  oranges      8    0.03  Oranges\n",
      "4          4   apples     10    1.38   Apples\n",
      "5          5  oranges      6    3.75  Oranges\n",
      "6          6   apples     10    3.37   Apples\n",
      "7          7  oranges     13    0.05  Oranges\n",
      "Index(['apples', 'oranges'], dtype='object') [0 1 0 1 0 1 0 1]\n",
      "Index(['Apples', 'Oranges'], dtype='object') [0 1 0 1 0 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "fruits = ['apple', 'orange', 'apple', 'orange'] * 2\n",
    "N = len(fruits)\n",
    "df = pd.DataFrame({'fruit': fruits,\n",
    "                   'basket_id': arange(N),\n",
    "                   'count': random.randint(3, 15, size=N),\n",
    "                   'weight': random.uniform(0, 4, size=N)},\n",
    "                  columns=['basket_id', 'fruit', 'count', 'weight'])\n",
    "df['fruit'] = pd.Categorical(df['fruit'],ordered=True,categories=['apple','orange'])\n",
    "# cat -> accessor for categorical values of a series \n",
    "df['fruit'].cat.categories = [\"apples\", \"oranges\"] # rename categries \n",
    "df['Fruit'] = df['fruit'].apply(str.capitalize).astype('category')\n",
    "print(df)\n",
    "print(df['fruit'].values.categories,df['fruit'].values.codes)\n",
    "print(df['Fruit'].values.categories,df['Fruit'].values.codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>bins</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>42</td>\n",
       "      <td>41 to 60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>93</td>\n",
       "      <td>81 to 100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>89</td>\n",
       "      <td>81 to 100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>1 to 20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>80</td>\n",
       "      <td>61 to 80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>67</td>\n",
       "      <td>61 to 80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>71</td>\n",
       "      <td>61 to 80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>33</td>\n",
       "      <td>21 to 40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>56</td>\n",
       "      <td>41 to 60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>65</td>\n",
       "      <td>61 to 80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   number       bins\n",
       "0      42   41 to 60\n",
       "1      93  81 to 100\n",
       "2      89  81 to 100\n",
       "3       2    1 to 20\n",
       "4      80   61 to 80\n",
       "5      67   61 to 80\n",
       "6      71   61 to 80\n",
       "7      33   21 to 40\n",
       "8      56   41 to 60\n",
       "9      65   61 to 80"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cutting df into categories(bins) \n",
    "df = pd.DataFrame({'number': np.random.randint(1, 100, 10)})\n",
    "df['bins'] = pd.cut(x=df['number'], bins=[1, 20, 40, 60, 80, 100],\n",
    "                    labels=['1 to 20', '21 to 40', '41 to 60',\n",
    "                            '61 to 80', '81 to 100'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   R_a  R_c  R_d  T_a  T_c  T_d\n",
      "0    1    0    0    0    0    1\n",
      "1    0    1    0    1    0    0\n",
      "2    0    0    1    0    1    0\n"
     ]
    }
   ],
   "source": [
    "# converts categorical data into dummy variables \n",
    "diff = pd.DataFrame({'R': ['a', 'c', 'd'],\n",
    "                     'T': ['d', 'a', 'c']})\n",
    "print(pd.get_dummies(diff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     nan\n",
      "1   11.00\n",
      "2   22.70\n",
      "3   33.00\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# convert dataframe to numbers(int or floats) and place str as nan\n",
    "ser = pd.Series(['Geeks', 11, 22.7, 33])\n",
    "print(pd.to_numeric(ser,errors = 'coerce'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>-3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A  B  C\n",
       "0  1  1  6\n",
       "1  2 -3  2\n",
       "2  7  6  2\n",
       "3  3  4  7\n",
       "4  3  3  3\n",
       "5  3  3 -1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clip data frame based on range(used to remove outliers) \n",
    "# Trim values at input threshold, Assigns values outside boundary to boundary values\n",
    "# Minimum threshold value. All values below this threshold will be set to it.\n",
    "# Maximum threshold value. All values above this threshold will be set to it.\n",
    "df = pd.DataFrame({\"A\":[-5, 8, 12, -9, 5, 3],\n",
    "                   \"B\":[-1, -4, 6, 4, 11, 3],\n",
    "                   \"C\":[11, 4, -8, 7, 3, -2]})\n",
    "lower_limit = pd.Series([1, -3, 2, 3, -2, -1])\n",
    "# upper limit for each individual column element.\n",
    "upper_limit = lower_limit + 5\n",
    "df.clip(lower_limit, upper_limit, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    k1  k2\n",
      "0  one   2\n",
      "1  two   3 \n",
      "\n",
      "k1 : one\n",
      "k2 : 2\n",
      "k1 : two\n",
      "k2 : 3\n"
     ]
    }
   ],
   "source": [
    "# iterating dataframes\n",
    "# iteritems:- columns\n",
    "# iterrows:- rows \n",
    "print(dfs,'\\n')\n",
    "for rowNo,row in dfs.iterrows():\n",
    "    for colName, col in row.iteritems():\n",
    "        print(colName,':',col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a  b\n",
       "0  1  1\n",
       "1  1  1\n",
       "2  1  1"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importance of copy\n",
    "# df2 = df1 is not making a copy of df1 and assign it to df2, \n",
    "# but setting up a pointer pointing to df1. So any changes in df2 would result in changes in df1\n",
    "df1 = pd.DataFrame({ 'a':[0,0,0], 'b': [1,1,1]})\n",
    "df2 = df1\n",
    "df2['a'] = df2['a'] + 1\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a  b\n",
       "0  0  1\n",
       "1  0  1\n",
       "2  0  1"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# so use copy()\n",
    "df1 = pd.DataFrame({ 'a':[0,0,0], 'b': [1,1,1]})\n",
    "df2 = df1.copy()\n",
    "df2['a'] = df2['a'] + 1\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Name            Team  Number Position   Age Height  Weight  \\\n",
      "0  Avery Bradley  Boston Celtics    0.00       PG 25.00    6-2  180.00   \n",
      "1    Jae Crowder  Boston Celtics   99.00       SF 25.00    6-6  235.00   \n",
      "2   John Holland  Boston Celtics   30.00       SG 27.00    6-5  205.00   \n",
      "3    R.J. Hunter  Boston Celtics   28.00       SG 22.00    6-5  185.00   \n",
      "4  Jonas Jerebko  Boston Celtics    8.00       PF 29.00   6-10  231.00   \n",
      "\n",
      "             College       Salary  \n",
      "0              Texas 7,730,337.00  \n",
      "1          Marquette 6,796,117.00  \n",
      "2  Boston University          nan  \n",
      "3      Georgia State 1,148,640.00  \n",
      "4                NaN 5,000,000.00  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Team</th>\n",
       "      <th>Number</th>\n",
       "      <th>Position</th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>College</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Avery Bradley</td>\n",
       "      <td>Boston Celtics</td>\n",
       "      <td>0.00</td>\n",
       "      <td>PG</td>\n",
       "      <td>25.00</td>\n",
       "      <td>6-2</td>\n",
       "      <td>180.00</td>\n",
       "      <td>Texas, Boston Celtics</td>\n",
       "      <td>7,730,337.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jae Crowder</td>\n",
       "      <td>Boston Celtics</td>\n",
       "      <td>99.00</td>\n",
       "      <td>SF</td>\n",
       "      <td>25.00</td>\n",
       "      <td>6-6</td>\n",
       "      <td>235.00</td>\n",
       "      <td>Marquette, Boston Celtics</td>\n",
       "      <td>6,796,117.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>John Holland</td>\n",
       "      <td>Boston Celtics</td>\n",
       "      <td>30.00</td>\n",
       "      <td>SG</td>\n",
       "      <td>27.00</td>\n",
       "      <td>6-5</td>\n",
       "      <td>205.00</td>\n",
       "      <td>Boston University, Boston Celtics</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>R.J. Hunter</td>\n",
       "      <td>Boston Celtics</td>\n",
       "      <td>28.00</td>\n",
       "      <td>SG</td>\n",
       "      <td>22.00</td>\n",
       "      <td>6-5</td>\n",
       "      <td>185.00</td>\n",
       "      <td>Georgia State, Boston Celtics</td>\n",
       "      <td>1,148,640.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jonas Jerebko</td>\n",
       "      <td>Boston Celtics</td>\n",
       "      <td>8.00</td>\n",
       "      <td>PF</td>\n",
       "      <td>29.00</td>\n",
       "      <td>6-10</td>\n",
       "      <td>231.00</td>\n",
       "      <td>No College, Boston Celtics</td>\n",
       "      <td>5,000,000.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Name            Team  Number Position   Age Height  Weight  \\\n",
       "0  Avery Bradley  Boston Celtics    0.00       PG 25.00    6-2  180.00   \n",
       "1    Jae Crowder  Boston Celtics   99.00       SF 25.00    6-6  235.00   \n",
       "2   John Holland  Boston Celtics   30.00       SG 27.00    6-5  205.00   \n",
       "3    R.J. Hunter  Boston Celtics   28.00       SG 22.00    6-5  185.00   \n",
       "4  Jonas Jerebko  Boston Celtics    8.00       PF 29.00   6-10  231.00   \n",
       "\n",
       "                             College       Salary  \n",
       "0              Texas, Boston Celtics 7,730,337.00  \n",
       "1          Marquette, Boston Celtics 6,796,117.00  \n",
       "2  Boston University, Boston Celtics          nan  \n",
       "3      Georgia State, Boston Celtics 1,148,640.00  \n",
       "4         No College, Boston Celtics 5,000,000.00  "
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concat 2 columns into a column in a data frame with a seperator\n",
    "data = pd.read_csv(\"https://media.geeksforgeeks.org/wp-content/uploads/nba.csv\")\n",
    "print(data.head())\n",
    "# making copy of team column\n",
    "new = data[\"Team\"].copy()\n",
    "# string to replace null values with\n",
    "na_string =\"No College\"\n",
    "# concatenating team with name column\n",
    "# overwriting name column\n",
    "data[\"College\"]= data[\"College\"].str.cat(new, sep =\", \", na_rep = na_string)\n",
    "# display\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data standardization:-\n",
    "# normalizing the data to remove outliers so the data mean is 0 and variance is 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col1</th>\n",
       "      <th>col2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.26</td>\n",
       "      <td>-0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.63</td>\n",
       "      <td>-0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.63</td>\n",
       "      <td>-0.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.26</td>\n",
       "      <td>1.49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   col1  col2\n",
       "0 -1.26 -0.74\n",
       "1 -0.63 -0.87\n",
       "2  0.00  0.54\n",
       "3  0.63 -0.42\n",
       "4  1.26  1.49"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "details = {\n",
    "    'col1': [1, 3, 5, 7, 9],\n",
    "    'col2': [7, 4, 35, 14, 56]\n",
    "}\n",
    "  \n",
    "# creating a Dataframe object\n",
    "df = pd.DataFrame(details)\n",
    "\n",
    "dfs = df.apply(lambda test: (test- test.mean())/test.std())\n",
    "dfs  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           num_legs  num_wings\n",
      "class  animal  locomotion                     \n",
      "mammal tiger   walks              4          0\n",
      "       lion    walks              4          0\n",
      "       fox     walks              4          0\n",
      "bird   eagle   flies              2          2\n",
      "       penguin walks              2          2 \n",
      "\n",
      "                   num_legs  num_wings\n",
      "class  locomotion                     \n",
      "mammal walks              4          0 \n",
      "\n",
      "class   animal   locomotion\n",
      "mammal  tiger    walks         0\n",
      "        lion     walks         0\n",
      "        fox      walks         0\n",
      "bird    eagle    flies         2\n",
      "        penguin  walks         2\n",
      "Name: num_wings, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# cross section\n",
    "d = {'num_legs': [4, 4, 4, 2, 2],\n",
    "     'num_wings': [0, 0, 0, 2, 2],\n",
    "     'class': ['mammal', 'mammal', 'mammal', 'bird', 'bird'],\n",
    "     'animal': ['tiger', 'lion', 'fox', 'eagle', 'penguin'],\n",
    "     'locomotion': ['walks', 'walks', 'walks', 'flies', 'walks']}\n",
    "df = pd.DataFrame(data=d)\n",
    "df = df.set_index(['class', 'animal', 'locomotion'])\n",
    "print(df,'\\n')\n",
    "print(df.xs('lion',level=1),'\\n')\n",
    "print(df.xs('num_wings', axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data ingestion(ETL(extract transform load))\n",
    "\"\"\"\n",
    "ETL is a process that extracts the data from different source systems, then transforms the data \n",
    "(like applying calculations, concatenations, etc.) and finally loads the data into the Data Warehouse system\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Team  Rank  Year  Points\n",
      "0  Riders     1  2014     876\n",
      "1  Riders     2  2015     789\n",
      "2  Devils     2  2014     863\n",
      "3  Devils     3  2015     673\n",
      "4   Kings     3  2014     741\n"
     ]
    }
   ],
   "source": [
    "# to csv(use encoding='utf-8' in case of any error)\n",
    "ipl_data = {'Team': ['Riders', 'Riders', 'Devils', 'Devils', 'Kings',\n",
    "   'kings', 'Kings', 'Kings', 'Riders', 'Royals', 'Royals', 'Riders'],\n",
    "   'Rank': [1, 2, 2, 3, 3,4 ,1 ,1,2 , 4,1,2],\n",
    "   'Year': [2014,2015,2014,2015,2014,2015,2016,2017,2016,2014,2015,2017],\n",
    "   'Points':[876,789,863,673,741,812,756,788,694,701,804,690]}\n",
    "df = pd.DataFrame(ipl_data)\n",
    "df.to_csv('data/ipl.csv',header=True,index=None)\n",
    "print(pd.read_csv('data/ipl.csv').head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>body_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>I've been searching for the right words to tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>I HAVE A DATE ON SUNDAY WITH WILL!!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                          body_text\n",
       "0   ham  I've been searching for the right words to tha...\n",
       "1  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "2   ham  Nah I don't think he goes to usf, he lives aro...\n",
       "3   ham  Even my brother is not like to speak with me. ...\n",
       "4   ham                I HAVE A DATE ON SUNDAY WITH WILL!!"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reading tsv files\n",
    "data = pd.read_csv(\"data/spam.tsv\", sep='\\t', header=None)\n",
    "data.columns = ['label', 'body_text']\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "   VendorID tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\n",
      "0         2  2018-10-31 07:10:55   2018-11-01 06:43:24                1   \n",
      "1         2  2018-10-31 16:38:25   2018-10-31 16:50:10                5   \n",
      "2         2  2018-10-31 20:23:41   2018-10-31 20:31:47                1   \n",
      "3         2  2018-10-31 22:44:24   2018-10-31 22:48:28                1   \n",
      "4         2  2018-10-31 23:22:18   2018-10-31 23:35:30                1   \n",
      "\n",
      "   trip_distance  RatecodeID store_and_fwd_flag  PULocationID  DOLocationID  \\\n",
      "0           2.57           1                  N           211            48   \n",
      "1           3.58           1                  N           237           144   \n",
      "2           2.39           1                  N           163           107   \n",
      "3           0.50           1                  N           246           246   \n",
      "4           1.81           1                  N            79            90   \n",
      "\n",
      "   payment_type  fare_amount  extra  mta_tax  tip_amount  tolls_amount  \\\n",
      "0             1         14.5    0.5      0.5        4.74           0.0   \n",
      "1             2         12.5    0.5      0.5        0.00           0.0   \n",
      "2             1          9.0    0.5      0.5        1.00           0.0   \n",
      "3             2          4.5    0.5      0.5        0.00           0.0   \n",
      "4             1         10.0    0.5      0.5        2.26           0.0   \n",
      "\n",
      "   improvement_surcharge  total_amount  \n",
      "0                    0.3         20.54  \n",
      "1                    0.3         13.80  \n",
      "2                    0.3         11.30  \n",
      "3                    0.3          5.80  \n",
      "4                    0.3         13.56  \n"
     ]
    }
   ],
   "source": [
    "# reading csv's by parsing dates\n",
    "time_cols = ['tpep_dropoff_datetime', 'tpep_pickup_datetime']\n",
    "df = pd.read_csv('data/taxi.csv.bz2', parse_dates=time_cols)\n",
    "print(len(df))\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>email</th>\n",
       "      <th>grade</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>John</td>\n",
       "      <td>john@mail.com</td>\n",
       "      <td>A</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alice</td>\n",
       "      <td>alice@mail.com</td>\n",
       "      <td>B</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bob</td>\n",
       "      <td>bob@mail.com</td>\n",
       "      <td>C</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hannah</td>\n",
       "      <td>hannah@mail.com</td>\n",
       "      <td>A</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     name            email grade age\n",
       "0    John    john@mail.com     A  16\n",
       "1   Alice   alice@mail.com     B  17\n",
       "2     Bob     bob@mail.com     C  16\n",
       "3  Hannah  hannah@mail.com     A  17"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# xml to data frame \n",
    "import pandas as pd \n",
    "import xml.etree.ElementTree as et \n",
    "\n",
    "xtree = et.parse(\"data/data.xml\")\n",
    "xroot = xtree.getroot() \n",
    "\n",
    "df_cols = [\"name\", \"email\", \"grade\", \"age\"]\n",
    "rows = []\n",
    "\n",
    "for node in xroot: \n",
    "    s_name = node.attrib.get(\"name\")\n",
    "    s_mail = node.find(\"email\").text if node is not None else None\n",
    "    s_grade = node.find(\"grade\").text if node is not None else None\n",
    "    s_age = node.find(\"age\").text if node is not None else None\n",
    "    \n",
    "    rows.append({\"name\": s_name, \"email\": s_mail, \n",
    "                 \"grade\": s_grade, \"age\": s_age})\n",
    "\n",
    "pd.DataFrame(rows, columns = df_cols).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>None</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>None</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>None</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500  None        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250  None        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500  None        S  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to/from json \n",
    "df = pd.read_csv('data/titanic.csv')\n",
    "df.to_json('data/titanic.json')\n",
    "df = pd.read_json('data/titanic.json')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex  Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male   22      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female   38      1   \n",
       "2                             Heikkinen, Miss. Laina  female   26      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female   35      1   \n",
       "4                           Allen, Mr. William Henry    male   35      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read csv with filters \n",
    "df = pd.read_csv('data/titanic.csv',nrows=5)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   distance\n",
      "0      7.91\n",
      "1      3.23\n",
      "2      1.46\n",
      "3      2.74\n",
      "4      0.84\n",
      "average distance: 3.0miles\n"
     ]
    }
   ],
   "source": [
    "# reading from sql to data frame using sqlite3\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "conn = sqlite3.connect('data/rides.db', detect_types=sqlite3.PARSE_DECLTYPES)\n",
    "params = {\n",
    "    'vendor': 'VeriFone',\n",
    "}\n",
    "sql = 'SELECT distance FROM rides WHERE vendor = :vendor'\n",
    "rides_df = pd.read_sql(sql, conn, params=params)\n",
    "print(rides_df.head())\n",
    "avg_distance = rides_df['distance'].mean()\n",
    "print(f'average distance: {avg_distance:.1f}miles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to sqlite by creating table first with schema and then converting later from data frame \n",
    "from contextlib import closing\n",
    "\n",
    "df = pd.read_csv('data/ship.csv')\n",
    "df.interpolate(inplace=True)\n",
    "schema = '''\n",
    "CREATE TABLE Ship (\n",
    "    name TEXT,\n",
    "    lat FLOAT NOT NULL,\n",
    "    lng FLOAT NOT NULL\n",
    ");\n",
    "'''\n",
    "db_file = 'data/ship.db'\n",
    "with closing(sqlite3.connect(db_file)) as conn:\n",
    "    conn.executescript(schema)\n",
    "    try:\n",
    "        with conn as cur:\n",
    "            cur.execute('BEGIN')\n",
    "            df.to_sql('Ship', conn, if_exists='append', index=False)\n",
    "    except:\n",
    "        print('sql error')\n",
    "    finally:\n",
    "        conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>name</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Black Pearl</td>\n",
       "      <td>20.66</td>\n",
       "      <td>-80.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Cobra</td>\n",
       "      <td>20.66</td>\n",
       "      <td>-80.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Flying Dutchman</td>\n",
       "      <td>20.66</td>\n",
       "      <td>-80.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Empress</td>\n",
       "      <td>20.66</td>\n",
       "      <td>-80.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Upendra</td>\n",
       "      <td>30.55</td>\n",
       "      <td>-80.67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID             name   lat    lng\n",
       "0   0      Black Pearl 20.66 -80.71\n",
       "1   1            Cobra 20.66 -80.71\n",
       "2   2  Flying Dutchman 20.66 -80.71\n",
       "3   3          Empress 20.66 -80.71\n",
       "4   4          Upendra 30.55 -80.67"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to sqlite using sqlalchemy and insert a row using pandas inbuilt sql io module   \n",
    "from sqlalchemy import create_engine \n",
    "from pandas.io import sql\n",
    "engine = create_engine('sqlite:///data/titanic.db', echo=False)\n",
    "df.to_sql('titanic', con=engine, index_label='ID')\n",
    "sql.execute('INSERT INTO titanic VALUES(?,?,?,?)', engine, params=[(4,'Upendra',30.55,-80.67)])\n",
    "titanic_data = pd.read_sql('select * from titanic', engine)\n",
    "titanic_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# csv to html\n",
    "import pandas\n",
    "import webbrowser\n",
    "import os\n",
    "# Read the dataset into a data table using Pandas\n",
    "data_table = pandas.read_csv(\"data/movies.csv\", index_col=\"movie_id\")\n",
    "# Create a web page view of the data for easy viewing\n",
    "html = data_table.to_html()\n",
    "# Save the html to a temporary file\n",
    "with open(\"data/movies_list.html\", \"w\") as f:\n",
    "    f.write(html)\n",
    "# Open the web page in our web browser\n",
    "full_filename = os.path.abspath(\"data/movies_list.html\")\n",
    "webbrowser.open(\"file://{}\".format(full_filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data frame validation\n",
    "# by setting data type, null check, and conditional checks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Black Pearl</td>\n",
       "      <td>20.664865</td>\n",
       "      <td>-80.709747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cobra</td>\n",
       "      <td>20.664868</td>\n",
       "      <td>-80.709740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Flying Dutchman</td>\n",
       "      <td>20.664878</td>\n",
       "      <td>-80.709941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Empress</td>\n",
       "      <td>20.664878</td>\n",
       "      <td>-80.709941</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              name        lat        lng\n",
       "0      Black Pearl  20.664865 -80.709747\n",
       "1            Cobra  20.664868 -80.709740\n",
       "2  Flying Dutchman  20.664878 -80.709941\n",
       "3          Empress  20.664878 -80.709941"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandera as pa\n",
    "import numpy as np\n",
    "df = pd.read_csv('data/ships.csv')\n",
    "schema = pa.DataFrameSchema({\n",
    "    'name': pa.Column(pa.String),\n",
    "    'lat': pa.Column(\n",
    "        pa.Float,\n",
    "        nullable=True,\n",
    "        checks=pa.Check(\n",
    "            lambda v: v >= -90 and v <= 90,\n",
    "            element_wise=True,\n",
    "        ),\n",
    "    ),\n",
    "    'lng': pa.Column(\n",
    "        pa.Float,\n",
    "        nullable=True,\n",
    "        checks=pa.Check(\n",
    "            lambda v: v >= -180 and v <= 180,\n",
    "            element_wise=True,\n",
    "        ),\n",
    "    ),\n",
    "})\n",
    "df.interpolate(inplace=True)\n",
    "schema.validate(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2.806575266061271,2.816776727785882, [-0.67008425 -0.9159855  -0.62015811 -0.05423158  0.23833257  0.38841283\n",
      " -0.88047513  0.43795014 -0.63382917 -0.14389094  2.17735466 -0.3431815\n",
      " -0.01487825  0.23111682 -0.4426593 ]\n"
     ]
    }
   ],
   "source": [
    "# hdf5 file handling \n",
    "import h5py\n",
    "arr1 = np.random.randn(10000)\n",
    "arr2 = np.random.randn(10000)\n",
    " \n",
    "with h5py.File('test_read.hdf5', 'w') as f:\n",
    "    f.create_dataset('array_1', data = arr1)\n",
    "    f.create_dataset('array_2', data = arr2)\n",
    "\n",
    "with h5py.File('test_read.hdf5', 'r') as f:\n",
    "    d1 = f['array_1']\n",
    "    d2 = f['array_2'] \n",
    "    data = d2[d1[:]>1]\n",
    "\n",
    "print(f'{min(data)},{max(data)}, {data[:15]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parquet format(columnar data storage)\n",
    "\"\"\"\n",
    "It means that data is encoded and stored by columns instead of by rows. This pattern allows for \n",
    "analytical queries to select a subset of columns for all rows. Parquet stores columns as chunks \n",
    "and can further split files within each chunk too. This allows restricting the disk i/o operations \n",
    "to a minimum.\n",
    "The second feature to mention is data schema and types. Parquet is a binary format and allows \n",
    "encoded data types. Unlike some formats, it is possible to store data with a specific type of \n",
    "numeric( int32, int64, int96, float, double) and byte array. This allows clients to easily \n",
    "and efficiently serialise and deserialise the data when reading and writing to parquet format.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>name</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-01 00:00:00</td>\n",
       "      <td>cpu</td>\n",
       "      <td>24.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-01 00:00:17</td>\n",
       "      <td>cpu</td>\n",
       "      <td>28.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-01-01 00:00:34</td>\n",
       "      <td>cpu</td>\n",
       "      <td>35.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-01-01 00:00:51</td>\n",
       "      <td>cpu</td>\n",
       "      <td>30.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-01-01 00:01:08</td>\n",
       "      <td>cpu</td>\n",
       "      <td>12.91</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 time name  value\n",
       "0 2021-01-01 00:00:00  cpu  24.23\n",
       "1 2021-01-01 00:00:17  cpu  28.33\n",
       "2 2021-01-01 00:00:34  cpu  35.22\n",
       "3 2021-01-01 00:00:51  cpu  30.46\n",
       "4 2021-01-01 00:01:08  cpu  12.91"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pandas optimization using apache paraquet with the help of apache arrow used in storing data in\n",
    "# columnar format where you can even give a schema \n",
    "#rand:- Create an array of the given shape and populate it with random samples from a uniform \n",
    "#distribution over [0, 1). \n",
    "import pyarrow as pa\n",
    "size = 5\n",
    "df = pd.DataFrame({\n",
    "    'time': pd.date_range('2021', freq='17s', periods=size),\n",
    "    'name': ['cpu'] * size,\n",
    "    'value': np.random.rand(size) * 40,\n",
    "})\n",
    "schema = pa.schema([\n",
    "    ('time', pa.timestamp('ms')),\n",
    "    ('name', pa.string()),\n",
    "    ('value', pa.float64()),\n",
    "])\n",
    "out_file = 'data/metrics.parquet'\n",
    "df.to_parquet(out_file, schema=schema)\n",
    "pd.read_parquet(out_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sql comparison "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "airports = pd.read_csv('data/airports.csv')\n",
    "airport_freq = pd.read_csv('data/airport-frequencies.csv')\n",
    "runways = pd.read_csv('data/runways.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ident</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>latitude_deg</th>\n",
       "      <th>longitude_deg</th>\n",
       "      <th>elevation_ft</th>\n",
       "      <th>continent</th>\n",
       "      <th>iso_country</th>\n",
       "      <th>iso_region</th>\n",
       "      <th>municipality</th>\n",
       "      <th>scheduled_service</th>\n",
       "      <th>gps_code</th>\n",
       "      <th>iata_code</th>\n",
       "      <th>local_code</th>\n",
       "      <th>home_link</th>\n",
       "      <th>wikipedia_link</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6523</td>\n",
       "      <td>00A</td>\n",
       "      <td>heliport</td>\n",
       "      <td>Total Rf Heliport</td>\n",
       "      <td>40.070801</td>\n",
       "      <td>-74.933601</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-PA</td>\n",
       "      <td>Bensalem</td>\n",
       "      <td>no</td>\n",
       "      <td>00A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>323361</td>\n",
       "      <td>00AA</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Aero B Ranch Airport</td>\n",
       "      <td>38.704022</td>\n",
       "      <td>-101.473911</td>\n",
       "      <td>3435.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-KS</td>\n",
       "      <td>Leoti</td>\n",
       "      <td>no</td>\n",
       "      <td>00AA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6524</td>\n",
       "      <td>00AK</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Lowell Field</td>\n",
       "      <td>59.949200</td>\n",
       "      <td>-151.695999</td>\n",
       "      <td>450.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AK</td>\n",
       "      <td>Anchor Point</td>\n",
       "      <td>no</td>\n",
       "      <td>00AK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id ident           type                  name  latitude_deg  \\\n",
       "0    6523   00A       heliport     Total Rf Heliport     40.070801   \n",
       "1  323361  00AA  small_airport  Aero B Ranch Airport     38.704022   \n",
       "2    6524  00AK  small_airport          Lowell Field     59.949200   \n",
       "\n",
       "   longitude_deg  elevation_ft continent iso_country iso_region  municipality  \\\n",
       "0     -74.933601          11.0       NaN          US      US-PA      Bensalem   \n",
       "1    -101.473911        3435.0       NaN          US      US-KS         Leoti   \n",
       "2    -151.695999         450.0       NaN          US      US-AK  Anchor Point   \n",
       "\n",
       "  scheduled_service gps_code iata_code local_code home_link wikipedia_link  \\\n",
       "0                no      00A       NaN        00A       NaN            NaN   \n",
       "1                no     00AA       NaN       00AA       NaN            NaN   \n",
       "2                no     00AK       NaN       00AK       NaN            NaN   \n",
       "\n",
       "  keywords  \n",
       "0      NaN  \n",
       "1      NaN  \n",
       "2      NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select * from airports limit 3  \n",
    "airports.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 56059 entries, 0 to 56059\n",
      "Data columns (total 18 columns):\n",
      "id                   56059 non-null int64\n",
      "ident                56059 non-null object\n",
      "type                 56059 non-null object\n",
      "name                 56059 non-null object\n",
      "latitude_deg         56059 non-null float64\n",
      "longitude_deg        56059 non-null float64\n",
      "elevation_ft         48826 non-null float64\n",
      "continent            27997 non-null object\n",
      "iso_country          55813 non-null object\n",
      "iso_region           56059 non-null object\n",
      "municipality         50270 non-null object\n",
      "scheduled_service    56059 non-null object\n",
      "gps_code             41070 non-null object\n",
      "iata_code            9234 non-null object\n",
      "local_code           29075 non-null object\n",
      "home_link            3039 non-null object\n",
      "wikipedia_link       10006 non-null object\n",
      "keywords             10014 non-null object\n",
      "dtypes: float64(3), int64(1), object(14)\n",
      "memory usage: 8.1+ MB\n",
      "None\n",
      "Index(['id', 'ident', 'type', 'name', 'latitude_deg', 'longitude_deg',\n",
      "       'elevation_ft', 'continent', 'iso_country', 'iso_region',\n",
      "       'municipality', 'scheduled_service', 'gps_code', 'iata_code',\n",
      "       'local_code', 'home_link', 'wikipedia_link', 'keywords'],\n",
      "      dtype='object')\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# desc airports \n",
    "print(airports.info())\n",
    "print(airports.columns)\n",
    "print(airports.empty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28336    3632\n",
       "Name: id, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select id from airports where ident = 'KLAX'\n",
    "airports[airports['ident'] == 'KLAX']['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['heliport', 'small_airport', 'closed', 'seaplane_base',\n",
       "       'balloonport', 'medium_airport', 'large_airport'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select distinct type from airport\n",
    "airports['type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ident</th>\n",
       "      <th>name</th>\n",
       "      <th>municipality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>0O0</td>\n",
       "      <td>San Luis Reservoir Seaplane Base</td>\n",
       "      <td>Los Banos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2499</th>\n",
       "      <td>22CA</td>\n",
       "      <td>Commodore Center Seaplane Base</td>\n",
       "      <td>Sausalito</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6265</th>\n",
       "      <td>5CA9</td>\n",
       "      <td>Konocti  - Clear Lake Seaplane Base</td>\n",
       "      <td>Kelseyville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13156</th>\n",
       "      <td>C39</td>\n",
       "      <td>Folsom Lake Seaplane Base</td>\n",
       "      <td>Folsom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15493</th>\n",
       "      <td>CN20</td>\n",
       "      <td>Ferndale Resort Seaplane Base</td>\n",
       "      <td>Kelseyville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17878</th>\n",
       "      <td>E20</td>\n",
       "      <td>Lake Berryessa Seaplane Base</td>\n",
       "      <td>Napa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23298</th>\n",
       "      <td>H77</td>\n",
       "      <td>Bridge Bay Resort Seaplane Base</td>\n",
       "      <td>Redding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31072</th>\n",
       "      <td>L11</td>\n",
       "      <td>Pebbly Beach Seaplane Base</td>\n",
       "      <td>Avalon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37810</th>\n",
       "      <td>O06</td>\n",
       "      <td>Lake Oroville Landing Area Seaplane Base</td>\n",
       "      <td>Oroville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41501</th>\n",
       "      <td>S74</td>\n",
       "      <td>Lost Isle Seaplane Base</td>\n",
       "      <td>Stockton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48967</th>\n",
       "      <td>TWH</td>\n",
       "      <td>Two Harbors Amphibious Terminal</td>\n",
       "      <td>Two Harbors</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ident                                      name municipality\n",
       "980     0O0          San Luis Reservoir Seaplane Base    Los Banos\n",
       "2499   22CA            Commodore Center Seaplane Base    Sausalito\n",
       "6265   5CA9       Konocti  - Clear Lake Seaplane Base  Kelseyville\n",
       "13156   C39                 Folsom Lake Seaplane Base       Folsom\n",
       "15493  CN20             Ferndale Resort Seaplane Base  Kelseyville\n",
       "17878   E20              Lake Berryessa Seaplane Base         Napa\n",
       "23298   H77           Bridge Bay Resort Seaplane Base      Redding\n",
       "31072   L11                Pebbly Beach Seaplane Base       Avalon\n",
       "37810   O06  Lake Oroville Landing Area Seaplane Base     Oroville\n",
       "41501   S74                   Lost Isle Seaplane Base     Stockton\n",
       "48967   TWH           Two Harbors Amphibious Terminal  Two Harbors"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select ident, name, municipality from airports where iso_region = 'US-CA' and type = 'seaplane_base'\n",
    "airports[(airports['iso_region'] == 'US-CA') & (airports['type'] == 'seaplane_base')][['ident','name','municipality']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>airport_ref</th>\n",
       "      <th>airport_ident</th>\n",
       "      <th>type</th>\n",
       "      <th>description</th>\n",
       "      <th>frequency_mhz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11951</th>\n",
       "      <td>60776</td>\n",
       "      <td>3632</td>\n",
       "      <td>KLAX</td>\n",
       "      <td>UNIC</td>\n",
       "      <td>UNICOM</td>\n",
       "      <td>122.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11950</th>\n",
       "      <td>60775</td>\n",
       "      <td>3632</td>\n",
       "      <td>KLAX</td>\n",
       "      <td>TWR</td>\n",
       "      <td>TWR</td>\n",
       "      <td>119.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11949</th>\n",
       "      <td>60774</td>\n",
       "      <td>3632</td>\n",
       "      <td>KLAX</td>\n",
       "      <td>OPS</td>\n",
       "      <td>AF</td>\n",
       "      <td>37.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11947</th>\n",
       "      <td>60772</td>\n",
       "      <td>3632</td>\n",
       "      <td>KLAX</td>\n",
       "      <td>MISC</td>\n",
       "      <td>CG</td>\n",
       "      <td>34.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11948</th>\n",
       "      <td>60773</td>\n",
       "      <td>3632</td>\n",
       "      <td>KLAX</td>\n",
       "      <td>MISC</td>\n",
       "      <td>CG</td>\n",
       "      <td>898.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11946</th>\n",
       "      <td>60771</td>\n",
       "      <td>3632</td>\n",
       "      <td>KLAX</td>\n",
       "      <td>GND</td>\n",
       "      <td>GND</td>\n",
       "      <td>121.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11945</th>\n",
       "      <td>60770</td>\n",
       "      <td>3632</td>\n",
       "      <td>KLAX</td>\n",
       "      <td>DEP</td>\n",
       "      <td>SOCAL DEP</td>\n",
       "      <td>124.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11944</th>\n",
       "      <td>60769</td>\n",
       "      <td>3632</td>\n",
       "      <td>KLAX</td>\n",
       "      <td>CLD</td>\n",
       "      <td>CLNC DEL</td>\n",
       "      <td>121.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11943</th>\n",
       "      <td>60768</td>\n",
       "      <td>3632</td>\n",
       "      <td>KLAX</td>\n",
       "      <td>ATIS</td>\n",
       "      <td>ATIS</td>\n",
       "      <td>133.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11941</th>\n",
       "      <td>60767</td>\n",
       "      <td>3632</td>\n",
       "      <td>KLAX</td>\n",
       "      <td>APP</td>\n",
       "      <td>SOCAL APP</td>\n",
       "      <td>36.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11942</th>\n",
       "      <td>60766</td>\n",
       "      <td>3632</td>\n",
       "      <td>KLAX</td>\n",
       "      <td>APP</td>\n",
       "      <td>SOCAL APP</td>\n",
       "      <td>124.30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  airport_ref airport_ident  type description  frequency_mhz\n",
       "11951  60776         3632          KLAX  UNIC      UNICOM         122.95\n",
       "11950  60775         3632          KLAX   TWR         TWR         119.80\n",
       "11949  60774         3632          KLAX   OPS          AF          37.22\n",
       "11947  60772         3632          KLAX  MISC          CG          34.50\n",
       "11948  60773         3632          KLAX  MISC          CG         898.40\n",
       "11946  60771         3632          KLAX   GND         GND         121.65\n",
       "11945  60770         3632          KLAX   DEP   SOCAL DEP         124.30\n",
       "11944  60769         3632          KLAX   CLD    CLNC DEL         121.40\n",
       "11943  60768         3632          KLAX  ATIS        ATIS         133.80\n",
       "11941  60767         3632          KLAX   APP   SOCAL APP          36.07\n",
       "11942  60766         3632          KLAX   APP   SOCAL APP         124.30"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select * from airport_freq where airport_ident = 'KLAX' order by type desc\n",
    "airport_freq[airport_freq['airport_ident'] == 'KLAX'].sort_values(by = 'type',ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ident</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>latitude_deg</th>\n",
       "      <th>longitude_deg</th>\n",
       "      <th>elevation_ft</th>\n",
       "      <th>continent</th>\n",
       "      <th>iso_country</th>\n",
       "      <th>iso_region</th>\n",
       "      <th>municipality</th>\n",
       "      <th>scheduled_service</th>\n",
       "      <th>gps_code</th>\n",
       "      <th>iata_code</th>\n",
       "      <th>local_code</th>\n",
       "      <th>home_link</th>\n",
       "      <th>wikipedia_link</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>323361</td>\n",
       "      <td>00AA</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Aero B Ranch Airport</td>\n",
       "      <td>38.704022</td>\n",
       "      <td>-101.473911</td>\n",
       "      <td>3435.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-KS</td>\n",
       "      <td>Leoti</td>\n",
       "      <td>no</td>\n",
       "      <td>00AA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6524</td>\n",
       "      <td>00AK</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Lowell Field</td>\n",
       "      <td>59.949200</td>\n",
       "      <td>-151.695999</td>\n",
       "      <td>450.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AK</td>\n",
       "      <td>Anchor Point</td>\n",
       "      <td>no</td>\n",
       "      <td>00AK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6525</td>\n",
       "      <td>00AL</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Epps Airpark</td>\n",
       "      <td>34.864799</td>\n",
       "      <td>-86.770302</td>\n",
       "      <td>820.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AL</td>\n",
       "      <td>Harvest</td>\n",
       "      <td>no</td>\n",
       "      <td>00AL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6526</td>\n",
       "      <td>00AR</td>\n",
       "      <td>closed</td>\n",
       "      <td>Newport Hospital &amp; Clinic Heliport</td>\n",
       "      <td>35.608700</td>\n",
       "      <td>-91.254898</td>\n",
       "      <td>237.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AR</td>\n",
       "      <td>Newport</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>322127</td>\n",
       "      <td>00AS</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Fulton Airport</td>\n",
       "      <td>34.942803</td>\n",
       "      <td>-97.818019</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-OK</td>\n",
       "      <td>Alex</td>\n",
       "      <td>no</td>\n",
       "      <td>00AS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6527</td>\n",
       "      <td>00AZ</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Cordes Airport</td>\n",
       "      <td>34.305599</td>\n",
       "      <td>-112.165001</td>\n",
       "      <td>3810.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AZ</td>\n",
       "      <td>Cordes</td>\n",
       "      <td>no</td>\n",
       "      <td>00AZ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AZ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6528</td>\n",
       "      <td>00CA</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Goldstone /Gts/ Airport</td>\n",
       "      <td>35.350498</td>\n",
       "      <td>-116.888000</td>\n",
       "      <td>3038.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-CA</td>\n",
       "      <td>Barstow</td>\n",
       "      <td>no</td>\n",
       "      <td>00CA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00CA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>324424</td>\n",
       "      <td>00CL</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Williams Ag Airport</td>\n",
       "      <td>39.427188</td>\n",
       "      <td>-121.763427</td>\n",
       "      <td>87.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-CA</td>\n",
       "      <td>Biggs</td>\n",
       "      <td>no</td>\n",
       "      <td>00CL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00CL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>6529</td>\n",
       "      <td>00CO</td>\n",
       "      <td>closed</td>\n",
       "      <td>Cass Field</td>\n",
       "      <td>40.622202</td>\n",
       "      <td>-104.344002</td>\n",
       "      <td>4830.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-CO</td>\n",
       "      <td>Briggsdale</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00CO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>6531</td>\n",
       "      <td>00FA</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Grass Patch Airport</td>\n",
       "      <td>28.645500</td>\n",
       "      <td>-82.219002</td>\n",
       "      <td>53.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-FL</td>\n",
       "      <td>Bushnell</td>\n",
       "      <td>no</td>\n",
       "      <td>00FA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00FA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6533</td>\n",
       "      <td>00FL</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>River Oak Airport</td>\n",
       "      <td>27.230900</td>\n",
       "      <td>-80.969200</td>\n",
       "      <td>35.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-FL</td>\n",
       "      <td>Okeechobee</td>\n",
       "      <td>no</td>\n",
       "      <td>00FL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00FL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>6534</td>\n",
       "      <td>00GA</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Lt World Airport</td>\n",
       "      <td>33.767502</td>\n",
       "      <td>-84.068298</td>\n",
       "      <td>700.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-GA</td>\n",
       "      <td>Lithonia</td>\n",
       "      <td>no</td>\n",
       "      <td>00GA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00GA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>6537</td>\n",
       "      <td>00ID</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Delta Shores Airport</td>\n",
       "      <td>48.145302</td>\n",
       "      <td>-116.213997</td>\n",
       "      <td>2064.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-ID</td>\n",
       "      <td>Clark Fork</td>\n",
       "      <td>no</td>\n",
       "      <td>00ID</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00ID</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>322581</td>\n",
       "      <td>00IG</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Goltl Airport</td>\n",
       "      <td>39.724028</td>\n",
       "      <td>-101.395994</td>\n",
       "      <td>3359.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-KS</td>\n",
       "      <td>McDonald</td>\n",
       "      <td>no</td>\n",
       "      <td>00IG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00IG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>6539</td>\n",
       "      <td>00IL</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Hammer Airport</td>\n",
       "      <td>41.978401</td>\n",
       "      <td>-89.560402</td>\n",
       "      <td>840.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-IL</td>\n",
       "      <td>Polo</td>\n",
       "      <td>no</td>\n",
       "      <td>00IL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00IL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>6541</td>\n",
       "      <td>00IS</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Hayenga's Cant Find Farms Airport</td>\n",
       "      <td>40.025600</td>\n",
       "      <td>-89.122902</td>\n",
       "      <td>820.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-IL</td>\n",
       "      <td>Kings</td>\n",
       "      <td>no</td>\n",
       "      <td>00IS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00IS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>6542</td>\n",
       "      <td>00KS</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Hayden Farm Airport</td>\n",
       "      <td>38.727798</td>\n",
       "      <td>-94.930496</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-KS</td>\n",
       "      <td>Gardner</td>\n",
       "      <td>no</td>\n",
       "      <td>00KS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00KS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>6543</td>\n",
       "      <td>00KY</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Robbins Roost Airport</td>\n",
       "      <td>37.409401</td>\n",
       "      <td>-84.619698</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-KY</td>\n",
       "      <td>Stanford</td>\n",
       "      <td>no</td>\n",
       "      <td>00KY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00KY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>6545</td>\n",
       "      <td>00LS</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Lejeune Airport</td>\n",
       "      <td>30.136299</td>\n",
       "      <td>-92.429398</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-LA</td>\n",
       "      <td>Esterwood</td>\n",
       "      <td>no</td>\n",
       "      <td>00LS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00LS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>6546</td>\n",
       "      <td>00MD</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Slater Field</td>\n",
       "      <td>38.757099</td>\n",
       "      <td>-75.753799</td>\n",
       "      <td>45.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-MD</td>\n",
       "      <td>Federalsburg</td>\n",
       "      <td>no</td>\n",
       "      <td>00MD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00MD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>6548</td>\n",
       "      <td>00MN</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Battle Lake Municipal Airport</td>\n",
       "      <td>46.299999</td>\n",
       "      <td>-95.700302</td>\n",
       "      <td>1365.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-MN</td>\n",
       "      <td>Battle Lake</td>\n",
       "      <td>no</td>\n",
       "      <td>00MN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00MN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>6549</td>\n",
       "      <td>00MO</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Cooper Flying Service Airport</td>\n",
       "      <td>37.202801</td>\n",
       "      <td>-94.412399</td>\n",
       "      <td>970.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-MO</td>\n",
       "      <td>Alba</td>\n",
       "      <td>no</td>\n",
       "      <td>00MO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00MO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5K8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>6550</td>\n",
       "      <td>00MT</td>\n",
       "      <td>closed</td>\n",
       "      <td>Sands Ranch Airport</td>\n",
       "      <td>48.537210</td>\n",
       "      <td>-109.705492</td>\n",
       "      <td>2600.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-MT</td>\n",
       "      <td>Havre</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00MT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>6551</td>\n",
       "      <td>00N</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Bucks Airport</td>\n",
       "      <td>39.473202</td>\n",
       "      <td>-75.185204</td>\n",
       "      <td>105.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-NJ</td>\n",
       "      <td>Bridgeton</td>\n",
       "      <td>no</td>\n",
       "      <td>00N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>6552</td>\n",
       "      <td>00NC</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>North Raleigh Airport</td>\n",
       "      <td>36.085201</td>\n",
       "      <td>-78.371399</td>\n",
       "      <td>348.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-NC</td>\n",
       "      <td>Louisburg</td>\n",
       "      <td>no</td>\n",
       "      <td>00NC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00NC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>321919</td>\n",
       "      <td>00NK</td>\n",
       "      <td>seaplane_base</td>\n",
       "      <td>Cliche Cove Seaplane Base</td>\n",
       "      <td>44.811861</td>\n",
       "      <td>-73.369806</td>\n",
       "      <td>96.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-NY</td>\n",
       "      <td>Beekmantown</td>\n",
       "      <td>no</td>\n",
       "      <td>00NK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00NK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>6554</td>\n",
       "      <td>00NY</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Weiss Airfield</td>\n",
       "      <td>42.900101</td>\n",
       "      <td>-77.499702</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-NY</td>\n",
       "      <td>West Bloomfield</td>\n",
       "      <td>no</td>\n",
       "      <td>00NY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00NY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>6555</td>\n",
       "      <td>00OH</td>\n",
       "      <td>closed</td>\n",
       "      <td>Exit 3 Airport</td>\n",
       "      <td>41.590476</td>\n",
       "      <td>-84.141583</td>\n",
       "      <td>785.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-OH</td>\n",
       "      <td>Wauseon</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>64D, 00OH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>328503</td>\n",
       "      <td>00OK</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Gull Bay Landing Airport</td>\n",
       "      <td>36.198598</td>\n",
       "      <td>-96.217693</td>\n",
       "      <td>960.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-OK</td>\n",
       "      <td>Sandsprings</td>\n",
       "      <td>no</td>\n",
       "      <td>00OK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00OK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>45773</td>\n",
       "      <td>00PN</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Ferrell Field</td>\n",
       "      <td>41.299500</td>\n",
       "      <td>-80.211111</td>\n",
       "      <td>1301.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-PA</td>\n",
       "      <td>Mercer</td>\n",
       "      <td>no</td>\n",
       "      <td>00PN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00PN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56029</th>\n",
       "      <td>32725</td>\n",
       "      <td>ZWYN</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Yining Airport</td>\n",
       "      <td>43.955799</td>\n",
       "      <td>81.330299</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AS</td>\n",
       "      <td>CN</td>\n",
       "      <td>CN-65</td>\n",
       "      <td>Yining</td>\n",
       "      <td>yes</td>\n",
       "      <td>ZWYN</td>\n",
       "      <td>YIN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Yining_Airport</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56030</th>\n",
       "      <td>30646</td>\n",
       "      <td>ZYAS</td>\n",
       "      <td>medium_airport</td>\n",
       "      <td>Anshan Air Base</td>\n",
       "      <td>41.105301</td>\n",
       "      <td>122.853996</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AS</td>\n",
       "      <td>CN</td>\n",
       "      <td>CN-21</td>\n",
       "      <td>Anshan</td>\n",
       "      <td>yes</td>\n",
       "      <td>ZYAS</td>\n",
       "      <td>AOG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Anshan_Teng%27ao...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56031</th>\n",
       "      <td>27237</td>\n",
       "      <td>ZYCC</td>\n",
       "      <td>medium_airport</td>\n",
       "      <td>Longjia Airport</td>\n",
       "      <td>43.996201</td>\n",
       "      <td>125.684998</td>\n",
       "      <td>706.0</td>\n",
       "      <td>AS</td>\n",
       "      <td>CN</td>\n",
       "      <td>CN-22</td>\n",
       "      <td>Changchun</td>\n",
       "      <td>yes</td>\n",
       "      <td>ZYCC</td>\n",
       "      <td>CGQ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Changchun_Longji...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56032</th>\n",
       "      <td>300858</td>\n",
       "      <td>ZYCH</td>\n",
       "      <td>medium_airport</td>\n",
       "      <td>Changhai Airport</td>\n",
       "      <td>39.266667</td>\n",
       "      <td>122.666944</td>\n",
       "      <td>80.0</td>\n",
       "      <td>AS</td>\n",
       "      <td>CN</td>\n",
       "      <td>CN-21</td>\n",
       "      <td>Changhai</td>\n",
       "      <td>no</td>\n",
       "      <td>ZYCH</td>\n",
       "      <td>CNI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Changhai_Airport</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56033</th>\n",
       "      <td>30827</td>\n",
       "      <td>ZYCY</td>\n",
       "      <td>medium_airport</td>\n",
       "      <td>Chaoyang Airport</td>\n",
       "      <td>41.538101</td>\n",
       "      <td>120.434998</td>\n",
       "      <td>568.0</td>\n",
       "      <td>AS</td>\n",
       "      <td>CN</td>\n",
       "      <td>CN-21</td>\n",
       "      <td>Chaoyang</td>\n",
       "      <td>yes</td>\n",
       "      <td>ZYCY</td>\n",
       "      <td>CHG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Chaoyang_Airport</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56034</th>\n",
       "      <td>327349</td>\n",
       "      <td>ZYDU</td>\n",
       "      <td>medium_airport</td>\n",
       "      <td>Wudalianchi Dedu Airport</td>\n",
       "      <td>48.445000</td>\n",
       "      <td>126.133000</td>\n",
       "      <td>984.0</td>\n",
       "      <td>AS</td>\n",
       "      <td>CN</td>\n",
       "      <td>CN-23</td>\n",
       "      <td>Wudalianchi</td>\n",
       "      <td>yes</td>\n",
       "      <td>ZYDU</td>\n",
       "      <td>DTU</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Wudalianchi_Dedu...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56035</th>\n",
       "      <td>324338</td>\n",
       "      <td>ZYFX</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Fuxin Airport</td>\n",
       "      <td>42.069014</td>\n",
       "      <td>121.718122</td>\n",
       "      <td>548.0</td>\n",
       "      <td>AS</td>\n",
       "      <td>CN</td>\n",
       "      <td>CN-21</td>\n",
       "      <td>Fuxin</td>\n",
       "      <td>no</td>\n",
       "      <td>ZYFX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56036</th>\n",
       "      <td>313994</td>\n",
       "      <td>ZYFY</td>\n",
       "      <td>medium_airport</td>\n",
       "      <td>Dongji Aiport</td>\n",
       "      <td>48.199494</td>\n",
       "      <td>134.366447</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AS</td>\n",
       "      <td>CN</td>\n",
       "      <td>CN-23</td>\n",
       "      <td>Fuyuan</td>\n",
       "      <td>yes</td>\n",
       "      <td>ZYFY</td>\n",
       "      <td>FYJ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Fuyuan_Dongji_Ai...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56037</th>\n",
       "      <td>27238</td>\n",
       "      <td>ZYHB</td>\n",
       "      <td>large_airport</td>\n",
       "      <td>Taiping Airport</td>\n",
       "      <td>45.623402</td>\n",
       "      <td>126.250000</td>\n",
       "      <td>457.0</td>\n",
       "      <td>AS</td>\n",
       "      <td>CN</td>\n",
       "      <td>CN-23</td>\n",
       "      <td>Harbin</td>\n",
       "      <td>yes</td>\n",
       "      <td>ZYHB</td>\n",
       "      <td>HRB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Harbin_Taiping_I...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56038</th>\n",
       "      <td>31576</td>\n",
       "      <td>ZYHE</td>\n",
       "      <td>medium_airport</td>\n",
       "      <td>Heihe Airport</td>\n",
       "      <td>50.171621</td>\n",
       "      <td>127.308884</td>\n",
       "      <td>8530.0</td>\n",
       "      <td>AS</td>\n",
       "      <td>CN</td>\n",
       "      <td>CN-23</td>\n",
       "      <td>Heihe</td>\n",
       "      <td>yes</td>\n",
       "      <td>ZYHE</td>\n",
       "      <td>HEK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Heihe_Airport</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56039</th>\n",
       "      <td>31701</td>\n",
       "      <td>ZYJL</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Jilin Airport</td>\n",
       "      <td>44.002201</td>\n",
       "      <td>126.396004</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AS</td>\n",
       "      <td>CN</td>\n",
       "      <td>CN-22</td>\n",
       "      <td>Jilin</td>\n",
       "      <td>no</td>\n",
       "      <td>ZYJL</td>\n",
       "      <td>JIL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Jilin_Ertaizi_Ai...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56040</th>\n",
       "      <td>27239</td>\n",
       "      <td>ZYJM</td>\n",
       "      <td>medium_airport</td>\n",
       "      <td>Jiamusi Airport</td>\n",
       "      <td>46.843399</td>\n",
       "      <td>130.464996</td>\n",
       "      <td>262.0</td>\n",
       "      <td>AS</td>\n",
       "      <td>CN</td>\n",
       "      <td>CN-23</td>\n",
       "      <td>Jiamusi</td>\n",
       "      <td>yes</td>\n",
       "      <td>ZYJM</td>\n",
       "      <td>JMU</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Jiamusi_Airport</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56041</th>\n",
       "      <td>327450</td>\n",
       "      <td>ZYJS</td>\n",
       "      <td>medium_airport</td>\n",
       "      <td>Jiansanjiang Airport</td>\n",
       "      <td>47.110000</td>\n",
       "      <td>132.660278</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AS</td>\n",
       "      <td>CN</td>\n",
       "      <td>CN-23</td>\n",
       "      <td>Jiansanjiang</td>\n",
       "      <td>yes</td>\n",
       "      <td>ZYJS</td>\n",
       "      <td>JSJ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Jiansanjiang_Air...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56042</th>\n",
       "      <td>313337</td>\n",
       "      <td>ZYJX</td>\n",
       "      <td>medium_airport</td>\n",
       "      <td>Jixi Xingkaihu Airport</td>\n",
       "      <td>45.293000</td>\n",
       "      <td>131.193000</td>\n",
       "      <td>760.0</td>\n",
       "      <td>AS</td>\n",
       "      <td>CN</td>\n",
       "      <td>CN-23</td>\n",
       "      <td>Jixi</td>\n",
       "      <td>yes</td>\n",
       "      <td>ZYJX</td>\n",
       "      <td>JXA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Jixi_Xingkaihu_A...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56043</th>\n",
       "      <td>31706</td>\n",
       "      <td>ZYJZ</td>\n",
       "      <td>medium_airport</td>\n",
       "      <td>Jinzhou Airport</td>\n",
       "      <td>41.101398</td>\n",
       "      <td>121.061996</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AS</td>\n",
       "      <td>CN</td>\n",
       "      <td>CN-21</td>\n",
       "      <td>Jinzhou</td>\n",
       "      <td>yes</td>\n",
       "      <td>ZYJZ</td>\n",
       "      <td>JNZ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Jinzhou_Airport</td>\n",
       "      <td>Xiaolingzi Air Base</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56044</th>\n",
       "      <td>307012</td>\n",
       "      <td>ZYLD</td>\n",
       "      <td>medium_airport</td>\n",
       "      <td>Lindu Airport</td>\n",
       "      <td>47.752056</td>\n",
       "      <td>129.019125</td>\n",
       "      <td>791.0</td>\n",
       "      <td>AS</td>\n",
       "      <td>CN</td>\n",
       "      <td>CN-23</td>\n",
       "      <td>Yichun</td>\n",
       "      <td>yes</td>\n",
       "      <td>ZYLD</td>\n",
       "      <td>LDS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Yichun_Lindu_Air...</td>\n",
       "      <td>Yichun Shi Airport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56045</th>\n",
       "      <td>300516</td>\n",
       "      <td>ZYLS</td>\n",
       "      <td>medium_airport</td>\n",
       "      <td>Yushu Batang Airport</td>\n",
       "      <td>32.836389</td>\n",
       "      <td>97.036389</td>\n",
       "      <td>12816.0</td>\n",
       "      <td>AS</td>\n",
       "      <td>CN</td>\n",
       "      <td>CN-63</td>\n",
       "      <td>Yushu</td>\n",
       "      <td>no</td>\n",
       "      <td>ZYLS</td>\n",
       "      <td>YUS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Yushu_Batang_Air...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56046</th>\n",
       "      <td>27240</td>\n",
       "      <td>ZYMD</td>\n",
       "      <td>medium_airport</td>\n",
       "      <td>Mudanjiang Hailang International Airport</td>\n",
       "      <td>44.524101</td>\n",
       "      <td>129.569000</td>\n",
       "      <td>883.0</td>\n",
       "      <td>AS</td>\n",
       "      <td>CN</td>\n",
       "      <td>CN-23</td>\n",
       "      <td>Mudanjiang</td>\n",
       "      <td>yes</td>\n",
       "      <td>ZYMD</td>\n",
       "      <td>MDG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Mudanjiang_Airport</td>\n",
       "      <td>Mudanjiang</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56047</th>\n",
       "      <td>301193</td>\n",
       "      <td>ZYMH</td>\n",
       "      <td>medium_airport</td>\n",
       "      <td>Gu-Lian Airport</td>\n",
       "      <td>52.912778</td>\n",
       "      <td>122.430000</td>\n",
       "      <td>1836.0</td>\n",
       "      <td>AS</td>\n",
       "      <td>CN</td>\n",
       "      <td>CN-23</td>\n",
       "      <td>Mohe</td>\n",
       "      <td>yes</td>\n",
       "      <td>ZYMH</td>\n",
       "      <td>OHE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Mohe_Gulian_Airport</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56048</th>\n",
       "      <td>27241</td>\n",
       "      <td>ZYQQ</td>\n",
       "      <td>medium_airport</td>\n",
       "      <td>Qiqihar Sanjiazi Airport</td>\n",
       "      <td>47.239601</td>\n",
       "      <td>123.917999</td>\n",
       "      <td>477.0</td>\n",
       "      <td>AS</td>\n",
       "      <td>CN</td>\n",
       "      <td>CN-23</td>\n",
       "      <td>Qiqihar</td>\n",
       "      <td>yes</td>\n",
       "      <td>ZYQQ</td>\n",
       "      <td>NDG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Qiqihar_Airport</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56049</th>\n",
       "      <td>327451</td>\n",
       "      <td>ZYSQ</td>\n",
       "      <td>medium_airport</td>\n",
       "      <td>Songyuan Chaganhu Airport</td>\n",
       "      <td>44.938114</td>\n",
       "      <td>124.550178</td>\n",
       "      <td>459.0</td>\n",
       "      <td>AS</td>\n",
       "      <td>CN</td>\n",
       "      <td>CN-22</td>\n",
       "      <td>Qian Gorlos Mongol Autonomous County</td>\n",
       "      <td>yes</td>\n",
       "      <td>ZYSQ</td>\n",
       "      <td>YSQ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Songyuan_Chaganh...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56050</th>\n",
       "      <td>307017</td>\n",
       "      <td>ZYTH</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Tahe Airport</td>\n",
       "      <td>52.224444</td>\n",
       "      <td>124.720222</td>\n",
       "      <td>1240.0</td>\n",
       "      <td>AS</td>\n",
       "      <td>CN</td>\n",
       "      <td>CN-23</td>\n",
       "      <td>Tahe</td>\n",
       "      <td>no</td>\n",
       "      <td>ZYTH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56051</th>\n",
       "      <td>27242</td>\n",
       "      <td>ZYTL</td>\n",
       "      <td>large_airport</td>\n",
       "      <td>Zhoushuizi Airport</td>\n",
       "      <td>38.965698</td>\n",
       "      <td>121.539001</td>\n",
       "      <td>107.0</td>\n",
       "      <td>AS</td>\n",
       "      <td>CN</td>\n",
       "      <td>CN-21</td>\n",
       "      <td>Dalian</td>\n",
       "      <td>yes</td>\n",
       "      <td>ZYTL</td>\n",
       "      <td>DLC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Dalian_Zhoushuiz...</td>\n",
       "      <td>Dalian Air Base</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56052</th>\n",
       "      <td>307013</td>\n",
       "      <td>ZYTN</td>\n",
       "      <td>medium_airport</td>\n",
       "      <td>Tonghua Sanyuanpu Airport</td>\n",
       "      <td>42.253889</td>\n",
       "      <td>125.703333</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>AS</td>\n",
       "      <td>CN</td>\n",
       "      <td>CN-22</td>\n",
       "      <td>Tonghua</td>\n",
       "      <td>yes</td>\n",
       "      <td>ZYTN</td>\n",
       "      <td>TNH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Tonghua_Sanyuanp...</td>\n",
       "      <td>Tonghua Liuhe Airport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56053</th>\n",
       "      <td>27243</td>\n",
       "      <td>ZYTX</td>\n",
       "      <td>large_airport</td>\n",
       "      <td>Taoxian Airport</td>\n",
       "      <td>41.639801</td>\n",
       "      <td>123.483002</td>\n",
       "      <td>198.0</td>\n",
       "      <td>AS</td>\n",
       "      <td>CN</td>\n",
       "      <td>CN-21</td>\n",
       "      <td>Shenyang</td>\n",
       "      <td>yes</td>\n",
       "      <td>ZYTX</td>\n",
       "      <td>SHE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Shenyang_Taoxian...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56054</th>\n",
       "      <td>27244</td>\n",
       "      <td>ZYYJ</td>\n",
       "      <td>medium_airport</td>\n",
       "      <td>Yanji Chaoyangchuan Airport</td>\n",
       "      <td>42.882801</td>\n",
       "      <td>129.451004</td>\n",
       "      <td>624.0</td>\n",
       "      <td>AS</td>\n",
       "      <td>CN</td>\n",
       "      <td>CN-22</td>\n",
       "      <td>Yanji</td>\n",
       "      <td>yes</td>\n",
       "      <td>ZYYJ</td>\n",
       "      <td>YNJ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Yanji_Chaoyangch...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56055</th>\n",
       "      <td>317861</td>\n",
       "      <td>ZYYK</td>\n",
       "      <td>medium_airport</td>\n",
       "      <td>Yingkou Lanqi Airport</td>\n",
       "      <td>40.542524</td>\n",
       "      <td>122.358600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>AS</td>\n",
       "      <td>CN</td>\n",
       "      <td>CN-21</td>\n",
       "      <td>Yingkou</td>\n",
       "      <td>yes</td>\n",
       "      <td>ZYYK</td>\n",
       "      <td>YKH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Yingkou_Lanqi_Ai...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56056</th>\n",
       "      <td>32753</td>\n",
       "      <td>ZYYY</td>\n",
       "      <td>medium_airport</td>\n",
       "      <td>Shenyang Dongta Airport</td>\n",
       "      <td>41.784401</td>\n",
       "      <td>123.496002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AS</td>\n",
       "      <td>CN</td>\n",
       "      <td>CN-21</td>\n",
       "      <td>Shenyang</td>\n",
       "      <td>no</td>\n",
       "      <td>ZYYY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56058</th>\n",
       "      <td>307326</td>\n",
       "      <td>ZZ-0002</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Glorioso Islands Airstrip</td>\n",
       "      <td>-11.584278</td>\n",
       "      <td>47.296389</td>\n",
       "      <td>11.0</td>\n",
       "      <td>AF</td>\n",
       "      <td>TF</td>\n",
       "      <td>TF-U-A</td>\n",
       "      <td>Grande Glorieuse</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56059</th>\n",
       "      <td>313629</td>\n",
       "      <td>ZZZZ</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Satsuma Iōjima Airport</td>\n",
       "      <td>30.784722</td>\n",
       "      <td>130.270556</td>\n",
       "      <td>338.0</td>\n",
       "      <td>AS</td>\n",
       "      <td>JP</td>\n",
       "      <td>JP-46</td>\n",
       "      <td>Mishima-Mura</td>\n",
       "      <td>no</td>\n",
       "      <td>RJX7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://wikimapia.org/6705190/Satsuma-Iwo-jima-...</td>\n",
       "      <td>SATSUMA,IWOJIMA,RJX7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>44554 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id    ident            type  \\\n",
       "1      323361     00AA   small_airport   \n",
       "2        6524     00AK   small_airport   \n",
       "3        6525     00AL   small_airport   \n",
       "4        6526     00AR          closed   \n",
       "5      322127     00AS   small_airport   \n",
       "6        6527     00AZ   small_airport   \n",
       "7        6528     00CA   small_airport   \n",
       "8      324424     00CL   small_airport   \n",
       "10       6529     00CO          closed   \n",
       "11       6531     00FA   small_airport   \n",
       "13       6533     00FL   small_airport   \n",
       "14       6534     00GA   small_airport   \n",
       "17       6537     00ID   small_airport   \n",
       "18     322581     00IG   small_airport   \n",
       "20       6539     00IL   small_airport   \n",
       "22       6541     00IS   small_airport   \n",
       "23       6542     00KS   small_airport   \n",
       "24       6543     00KY   small_airport   \n",
       "27       6545     00LS   small_airport   \n",
       "28       6546     00MD   small_airport   \n",
       "30       6548     00MN   small_airport   \n",
       "31       6549     00MO   small_airport   \n",
       "32       6550     00MT          closed   \n",
       "33       6551      00N   small_airport   \n",
       "34       6552     00NC   small_airport   \n",
       "36     321919     00NK   seaplane_base   \n",
       "37       6554     00NY   small_airport   \n",
       "38       6555     00OH          closed   \n",
       "40     328503     00OK   small_airport   \n",
       "43      45773     00PN   small_airport   \n",
       "...       ...      ...             ...   \n",
       "56029   32725     ZWYN   small_airport   \n",
       "56030   30646     ZYAS  medium_airport   \n",
       "56031   27237     ZYCC  medium_airport   \n",
       "56032  300858     ZYCH  medium_airport   \n",
       "56033   30827     ZYCY  medium_airport   \n",
       "56034  327349     ZYDU  medium_airport   \n",
       "56035  324338     ZYFX   small_airport   \n",
       "56036  313994     ZYFY  medium_airport   \n",
       "56037   27238     ZYHB   large_airport   \n",
       "56038   31576     ZYHE  medium_airport   \n",
       "56039   31701     ZYJL   small_airport   \n",
       "56040   27239     ZYJM  medium_airport   \n",
       "56041  327450     ZYJS  medium_airport   \n",
       "56042  313337     ZYJX  medium_airport   \n",
       "56043   31706     ZYJZ  medium_airport   \n",
       "56044  307012     ZYLD  medium_airport   \n",
       "56045  300516     ZYLS  medium_airport   \n",
       "56046   27240     ZYMD  medium_airport   \n",
       "56047  301193     ZYMH  medium_airport   \n",
       "56048   27241     ZYQQ  medium_airport   \n",
       "56049  327451     ZYSQ  medium_airport   \n",
       "56050  307017     ZYTH   small_airport   \n",
       "56051   27242     ZYTL   large_airport   \n",
       "56052  307013     ZYTN  medium_airport   \n",
       "56053   27243     ZYTX   large_airport   \n",
       "56054   27244     ZYYJ  medium_airport   \n",
       "56055  317861     ZYYK  medium_airport   \n",
       "56056   32753     ZYYY  medium_airport   \n",
       "56058  307326  ZZ-0002   small_airport   \n",
       "56059  313629     ZZZZ   small_airport   \n",
       "\n",
       "                                           name  latitude_deg  longitude_deg  \\\n",
       "1                          Aero B Ranch Airport     38.704022    -101.473911   \n",
       "2                                  Lowell Field     59.949200    -151.695999   \n",
       "3                                  Epps Airpark     34.864799     -86.770302   \n",
       "4            Newport Hospital & Clinic Heliport     35.608700     -91.254898   \n",
       "5                                Fulton Airport     34.942803     -97.818019   \n",
       "6                                Cordes Airport     34.305599    -112.165001   \n",
       "7                       Goldstone /Gts/ Airport     35.350498    -116.888000   \n",
       "8                           Williams Ag Airport     39.427188    -121.763427   \n",
       "10                                   Cass Field     40.622202    -104.344002   \n",
       "11                          Grass Patch Airport     28.645500     -82.219002   \n",
       "13                            River Oak Airport     27.230900     -80.969200   \n",
       "14                             Lt World Airport     33.767502     -84.068298   \n",
       "17                         Delta Shores Airport     48.145302    -116.213997   \n",
       "18                                Goltl Airport     39.724028    -101.395994   \n",
       "20                               Hammer Airport     41.978401     -89.560402   \n",
       "22            Hayenga's Cant Find Farms Airport     40.025600     -89.122902   \n",
       "23                          Hayden Farm Airport     38.727798     -94.930496   \n",
       "24                        Robbins Roost Airport     37.409401     -84.619698   \n",
       "27                              Lejeune Airport     30.136299     -92.429398   \n",
       "28                                 Slater Field     38.757099     -75.753799   \n",
       "30                Battle Lake Municipal Airport     46.299999     -95.700302   \n",
       "31                Cooper Flying Service Airport     37.202801     -94.412399   \n",
       "32                          Sands Ranch Airport     48.537210    -109.705492   \n",
       "33                                Bucks Airport     39.473202     -75.185204   \n",
       "34                        North Raleigh Airport     36.085201     -78.371399   \n",
       "36                    Cliche Cove Seaplane Base     44.811861     -73.369806   \n",
       "37                               Weiss Airfield     42.900101     -77.499702   \n",
       "38                               Exit 3 Airport     41.590476     -84.141583   \n",
       "40                     Gull Bay Landing Airport     36.198598     -96.217693   \n",
       "43                                Ferrell Field     41.299500     -80.211111   \n",
       "...                                         ...           ...            ...   \n",
       "56029                            Yining Airport     43.955799      81.330299   \n",
       "56030                           Anshan Air Base     41.105301     122.853996   \n",
       "56031                           Longjia Airport     43.996201     125.684998   \n",
       "56032                          Changhai Airport     39.266667     122.666944   \n",
       "56033                          Chaoyang Airport     41.538101     120.434998   \n",
       "56034                  Wudalianchi Dedu Airport     48.445000     126.133000   \n",
       "56035                             Fuxin Airport     42.069014     121.718122   \n",
       "56036                             Dongji Aiport     48.199494     134.366447   \n",
       "56037                           Taiping Airport     45.623402     126.250000   \n",
       "56038                             Heihe Airport     50.171621     127.308884   \n",
       "56039                             Jilin Airport     44.002201     126.396004   \n",
       "56040                           Jiamusi Airport     46.843399     130.464996   \n",
       "56041                      Jiansanjiang Airport     47.110000     132.660278   \n",
       "56042                    Jixi Xingkaihu Airport     45.293000     131.193000   \n",
       "56043                           Jinzhou Airport     41.101398     121.061996   \n",
       "56044                             Lindu Airport     47.752056     129.019125   \n",
       "56045                      Yushu Batang Airport     32.836389      97.036389   \n",
       "56046  Mudanjiang Hailang International Airport     44.524101     129.569000   \n",
       "56047                           Gu-Lian Airport     52.912778     122.430000   \n",
       "56048                  Qiqihar Sanjiazi Airport     47.239601     123.917999   \n",
       "56049                 Songyuan Chaganhu Airport     44.938114     124.550178   \n",
       "56050                              Tahe Airport     52.224444     124.720222   \n",
       "56051                        Zhoushuizi Airport     38.965698     121.539001   \n",
       "56052                 Tonghua Sanyuanpu Airport     42.253889     125.703333   \n",
       "56053                           Taoxian Airport     41.639801     123.483002   \n",
       "56054               Yanji Chaoyangchuan Airport     42.882801     129.451004   \n",
       "56055                     Yingkou Lanqi Airport     40.542524     122.358600   \n",
       "56056                   Shenyang Dongta Airport     41.784401     123.496002   \n",
       "56058                 Glorioso Islands Airstrip    -11.584278      47.296389   \n",
       "56059                    Satsuma Iōjima Airport     30.784722     130.270556   \n",
       "\n",
       "       elevation_ft continent iso_country iso_region  \\\n",
       "1            3435.0       NaN          US      US-KS   \n",
       "2             450.0       NaN          US      US-AK   \n",
       "3             820.0       NaN          US      US-AL   \n",
       "4             237.0       NaN          US      US-AR   \n",
       "5            1100.0       NaN          US      US-OK   \n",
       "6            3810.0       NaN          US      US-AZ   \n",
       "7            3038.0       NaN          US      US-CA   \n",
       "8              87.0       NaN          US      US-CA   \n",
       "10           4830.0       NaN          US      US-CO   \n",
       "11             53.0       NaN          US      US-FL   \n",
       "13             35.0       NaN          US      US-FL   \n",
       "14            700.0       NaN          US      US-GA   \n",
       "17           2064.0       NaN          US      US-ID   \n",
       "18           3359.0       NaN          US      US-KS   \n",
       "20            840.0       NaN          US      US-IL   \n",
       "22            820.0       NaN          US      US-IL   \n",
       "23           1100.0       NaN          US      US-KS   \n",
       "24           1265.0       NaN          US      US-KY   \n",
       "27             12.0       NaN          US      US-LA   \n",
       "28             45.0       NaN          US      US-MD   \n",
       "30           1365.0       NaN          US      US-MN   \n",
       "31            970.0       NaN          US      US-MO   \n",
       "32           2600.0       NaN          US      US-MT   \n",
       "33            105.0       NaN          US      US-NJ   \n",
       "34            348.0       NaN          US      US-NC   \n",
       "36             96.0       NaN          US      US-NY   \n",
       "37           1000.0       NaN          US      US-NY   \n",
       "38            785.0       NaN          US      US-OH   \n",
       "40            960.0       NaN          US      US-OK   \n",
       "43           1301.0       NaN          US      US-PA   \n",
       "...             ...       ...         ...        ...   \n",
       "56029           NaN        AS          CN      CN-65   \n",
       "56030           NaN        AS          CN      CN-21   \n",
       "56031         706.0        AS          CN      CN-22   \n",
       "56032          80.0        AS          CN      CN-21   \n",
       "56033         568.0        AS          CN      CN-21   \n",
       "56034         984.0        AS          CN      CN-23   \n",
       "56035         548.0        AS          CN      CN-21   \n",
       "56036           NaN        AS          CN      CN-23   \n",
       "56037         457.0        AS          CN      CN-23   \n",
       "56038        8530.0        AS          CN      CN-23   \n",
       "56039           NaN        AS          CN      CN-22   \n",
       "56040         262.0        AS          CN      CN-23   \n",
       "56041           NaN        AS          CN      CN-23   \n",
       "56042         760.0        AS          CN      CN-23   \n",
       "56043           NaN        AS          CN      CN-21   \n",
       "56044         791.0        AS          CN      CN-23   \n",
       "56045       12816.0        AS          CN      CN-63   \n",
       "56046         883.0        AS          CN      CN-23   \n",
       "56047        1836.0        AS          CN      CN-23   \n",
       "56048         477.0        AS          CN      CN-23   \n",
       "56049         459.0        AS          CN      CN-22   \n",
       "56050        1240.0        AS          CN      CN-23   \n",
       "56051         107.0        AS          CN      CN-21   \n",
       "56052        1200.0        AS          CN      CN-22   \n",
       "56053         198.0        AS          CN      CN-21   \n",
       "56054         624.0        AS          CN      CN-22   \n",
       "56055           0.0        AS          CN      CN-21   \n",
       "56056           NaN        AS          CN      CN-21   \n",
       "56058          11.0        AF          TF     TF-U-A   \n",
       "56059         338.0        AS          JP      JP-46   \n",
       "\n",
       "                               municipality scheduled_service gps_code  \\\n",
       "1                                     Leoti                no     00AA   \n",
       "2                              Anchor Point                no     00AK   \n",
       "3                                   Harvest                no     00AL   \n",
       "4                                   Newport                no      NaN   \n",
       "5                                      Alex                no     00AS   \n",
       "6                                    Cordes                no     00AZ   \n",
       "7                                   Barstow                no     00CA   \n",
       "8                                     Biggs                no     00CL   \n",
       "10                               Briggsdale                no      NaN   \n",
       "11                                 Bushnell                no     00FA   \n",
       "13                               Okeechobee                no     00FL   \n",
       "14                                 Lithonia                no     00GA   \n",
       "17                               Clark Fork                no     00ID   \n",
       "18                                 McDonald                no     00IG   \n",
       "20                                     Polo                no     00IL   \n",
       "22                                    Kings                no     00IS   \n",
       "23                                  Gardner                no     00KS   \n",
       "24                                 Stanford                no     00KY   \n",
       "27                                Esterwood                no     00LS   \n",
       "28                             Federalsburg                no     00MD   \n",
       "30                              Battle Lake                no     00MN   \n",
       "31                                     Alba                no     00MO   \n",
       "32                                    Havre                no      NaN   \n",
       "33                                Bridgeton                no      00N   \n",
       "34                                Louisburg                no     00NC   \n",
       "36                              Beekmantown                no     00NK   \n",
       "37                          West Bloomfield                no     00NY   \n",
       "38                                  Wauseon                no      NaN   \n",
       "40                              Sandsprings                no     00OK   \n",
       "43                                   Mercer                no     00PN   \n",
       "...                                     ...               ...      ...   \n",
       "56029                                Yining               yes     ZWYN   \n",
       "56030                                Anshan               yes     ZYAS   \n",
       "56031                             Changchun               yes     ZYCC   \n",
       "56032                              Changhai                no     ZYCH   \n",
       "56033                              Chaoyang               yes     ZYCY   \n",
       "56034                           Wudalianchi               yes     ZYDU   \n",
       "56035                                 Fuxin                no     ZYFX   \n",
       "56036                                Fuyuan               yes     ZYFY   \n",
       "56037                                Harbin               yes     ZYHB   \n",
       "56038                                 Heihe               yes     ZYHE   \n",
       "56039                                 Jilin                no     ZYJL   \n",
       "56040                               Jiamusi               yes     ZYJM   \n",
       "56041                          Jiansanjiang               yes     ZYJS   \n",
       "56042                                  Jixi               yes     ZYJX   \n",
       "56043                               Jinzhou               yes     ZYJZ   \n",
       "56044                                Yichun               yes     ZYLD   \n",
       "56045                                 Yushu                no     ZYLS   \n",
       "56046                            Mudanjiang               yes     ZYMD   \n",
       "56047                                  Mohe               yes     ZYMH   \n",
       "56048                               Qiqihar               yes     ZYQQ   \n",
       "56049  Qian Gorlos Mongol Autonomous County               yes     ZYSQ   \n",
       "56050                                  Tahe                no     ZYTH   \n",
       "56051                                Dalian               yes     ZYTL   \n",
       "56052                               Tonghua               yes     ZYTN   \n",
       "56053                              Shenyang               yes     ZYTX   \n",
       "56054                                 Yanji               yes     ZYYJ   \n",
       "56055                               Yingkou               yes     ZYYK   \n",
       "56056                              Shenyang                no     ZYYY   \n",
       "56058                      Grande Glorieuse                no      NaN   \n",
       "56059                          Mishima-Mura                no     RJX7   \n",
       "\n",
       "      iata_code local_code home_link  \\\n",
       "1           NaN       00AA       NaN   \n",
       "2           NaN       00AK       NaN   \n",
       "3           NaN       00AL       NaN   \n",
       "4           NaN        NaN       NaN   \n",
       "5           NaN       00AS       NaN   \n",
       "6           NaN       00AZ       NaN   \n",
       "7           NaN       00CA       NaN   \n",
       "8           NaN       00CL       NaN   \n",
       "10          NaN        NaN       NaN   \n",
       "11          NaN       00FA       NaN   \n",
       "13          NaN       00FL       NaN   \n",
       "14          NaN       00GA       NaN   \n",
       "17          NaN       00ID       NaN   \n",
       "18          NaN       00IG       NaN   \n",
       "20          NaN       00IL       NaN   \n",
       "22          NaN       00IS       NaN   \n",
       "23          NaN       00KS       NaN   \n",
       "24          NaN       00KY       NaN   \n",
       "27          NaN       00LS       NaN   \n",
       "28          NaN       00MD       NaN   \n",
       "30          NaN       00MN       NaN   \n",
       "31          NaN       00MO       NaN   \n",
       "32          NaN        NaN       NaN   \n",
       "33          NaN        00N       NaN   \n",
       "34          NaN       00NC       NaN   \n",
       "36          NaN       00NK       NaN   \n",
       "37          NaN       00NY       NaN   \n",
       "38          NaN        NaN       NaN   \n",
       "40          NaN       00OK       NaN   \n",
       "43          NaN       00PN       NaN   \n",
       "...         ...        ...       ...   \n",
       "56029       YIN        NaN       NaN   \n",
       "56030       AOG        NaN       NaN   \n",
       "56031       CGQ        NaN       NaN   \n",
       "56032       CNI        NaN       NaN   \n",
       "56033       CHG        NaN       NaN   \n",
       "56034       DTU        NaN       NaN   \n",
       "56035       NaN        NaN       NaN   \n",
       "56036       FYJ        NaN       NaN   \n",
       "56037       HRB        NaN       NaN   \n",
       "56038       HEK        NaN       NaN   \n",
       "56039       JIL        NaN       NaN   \n",
       "56040       JMU        NaN       NaN   \n",
       "56041       JSJ        NaN       NaN   \n",
       "56042       JXA        NaN       NaN   \n",
       "56043       JNZ        NaN       NaN   \n",
       "56044       LDS        NaN       NaN   \n",
       "56045       YUS        NaN       NaN   \n",
       "56046       MDG        NaN       NaN   \n",
       "56047       OHE        NaN       NaN   \n",
       "56048       NDG        NaN       NaN   \n",
       "56049       YSQ        NaN       NaN   \n",
       "56050       NaN        NaN       NaN   \n",
       "56051       DLC        NaN       NaN   \n",
       "56052       TNH        NaN       NaN   \n",
       "56053       SHE        NaN       NaN   \n",
       "56054       YNJ        NaN       NaN   \n",
       "56055       YKH        NaN       NaN   \n",
       "56056       NaN        NaN       NaN   \n",
       "56058       NaN        NaN       NaN   \n",
       "56059       NaN        NaN       NaN   \n",
       "\n",
       "                                          wikipedia_link  \\\n",
       "1                                                    NaN   \n",
       "2                                                    NaN   \n",
       "3                                                    NaN   \n",
       "4                                                    NaN   \n",
       "5                                                    NaN   \n",
       "6                                                    NaN   \n",
       "7                                                    NaN   \n",
       "8                                                    NaN   \n",
       "10                                                   NaN   \n",
       "11                                                   NaN   \n",
       "13                                                   NaN   \n",
       "14                                                   NaN   \n",
       "17                                                   NaN   \n",
       "18                                                   NaN   \n",
       "20                                                   NaN   \n",
       "22                                                   NaN   \n",
       "23                                                   NaN   \n",
       "24                                                   NaN   \n",
       "27                                                   NaN   \n",
       "28                                                   NaN   \n",
       "30                                                   NaN   \n",
       "31                                                   NaN   \n",
       "32                                                   NaN   \n",
       "33                                                   NaN   \n",
       "34                                                   NaN   \n",
       "36                                                   NaN   \n",
       "37                                                   NaN   \n",
       "38                                                   NaN   \n",
       "40                                                   NaN   \n",
       "43                                                   NaN   \n",
       "...                                                  ...   \n",
       "56029       https://en.wikipedia.org/wiki/Yining_Airport   \n",
       "56030  https://en.wikipedia.org/wiki/Anshan_Teng%27ao...   \n",
       "56031  https://en.wikipedia.org/wiki/Changchun_Longji...   \n",
       "56032     https://en.wikipedia.org/wiki/Changhai_Airport   \n",
       "56033     https://en.wikipedia.org/wiki/Chaoyang_Airport   \n",
       "56034  https://en.wikipedia.org/wiki/Wudalianchi_Dedu...   \n",
       "56035                                                NaN   \n",
       "56036  https://en.wikipedia.org/wiki/Fuyuan_Dongji_Ai...   \n",
       "56037  https://en.wikipedia.org/wiki/Harbin_Taiping_I...   \n",
       "56038        https://en.wikipedia.org/wiki/Heihe_Airport   \n",
       "56039  https://en.wikipedia.org/wiki/Jilin_Ertaizi_Ai...   \n",
       "56040      https://en.wikipedia.org/wiki/Jiamusi_Airport   \n",
       "56041  https://en.wikipedia.org/wiki/Jiansanjiang_Air...   \n",
       "56042  https://en.wikipedia.org/wiki/Jixi_Xingkaihu_A...   \n",
       "56043      https://en.wikipedia.org/wiki/Jinzhou_Airport   \n",
       "56044  https://en.wikipedia.org/wiki/Yichun_Lindu_Air...   \n",
       "56045  https://en.wikipedia.org/wiki/Yushu_Batang_Air...   \n",
       "56046   https://en.wikipedia.org/wiki/Mudanjiang_Airport   \n",
       "56047  https://en.wikipedia.org/wiki/Mohe_Gulian_Airport   \n",
       "56048      https://en.wikipedia.org/wiki/Qiqihar_Airport   \n",
       "56049  https://en.wikipedia.org/wiki/Songyuan_Chaganh...   \n",
       "56050                                                NaN   \n",
       "56051  https://en.wikipedia.org/wiki/Dalian_Zhoushuiz...   \n",
       "56052  https://en.wikipedia.org/wiki/Tonghua_Sanyuanp...   \n",
       "56053  https://en.wikipedia.org/wiki/Shenyang_Taoxian...   \n",
       "56054  https://en.wikipedia.org/wiki/Yanji_Chaoyangch...   \n",
       "56055  https://en.wikipedia.org/wiki/Yingkou_Lanqi_Ai...   \n",
       "56056                                                NaN   \n",
       "56058                                                NaN   \n",
       "56059  http://wikimapia.org/6705190/Satsuma-Iwo-jima-...   \n",
       "\n",
       "                    keywords  \n",
       "1                        NaN  \n",
       "2                        NaN  \n",
       "3                        NaN  \n",
       "4                       00AR  \n",
       "5                        NaN  \n",
       "6                        NaN  \n",
       "7                        NaN  \n",
       "8                        NaN  \n",
       "10                      00CO  \n",
       "11                       NaN  \n",
       "13                       NaN  \n",
       "14                       NaN  \n",
       "17                       NaN  \n",
       "18                       NaN  \n",
       "20                       NaN  \n",
       "22                       NaN  \n",
       "23                       NaN  \n",
       "24                       NaN  \n",
       "27                       NaN  \n",
       "28                       NaN  \n",
       "30                       NaN  \n",
       "31                       5K8  \n",
       "32                      00MT  \n",
       "33                       NaN  \n",
       "34                       NaN  \n",
       "36                       NaN  \n",
       "37                       NaN  \n",
       "38                 64D, 00OH  \n",
       "40                       NaN  \n",
       "43                       NaN  \n",
       "...                      ...  \n",
       "56029                    NaN  \n",
       "56030                    NaN  \n",
       "56031                    NaN  \n",
       "56032                    NaN  \n",
       "56033                    NaN  \n",
       "56034                    NaN  \n",
       "56035                    NaN  \n",
       "56036                    NaN  \n",
       "56037                    NaN  \n",
       "56038                    NaN  \n",
       "56039                    NaN  \n",
       "56040                    NaN  \n",
       "56041                    NaN  \n",
       "56042                    NaN  \n",
       "56043    Xiaolingzi Air Base  \n",
       "56044     Yichun Shi Airport  \n",
       "56045                    NaN  \n",
       "56046             Mudanjiang  \n",
       "56047                    NaN  \n",
       "56048                    NaN  \n",
       "56049                    NaN  \n",
       "56050                    NaN  \n",
       "56051        Dalian Air Base  \n",
       "56052  Tonghua Liuhe Airport  \n",
       "56053                    NaN  \n",
       "56054                    NaN  \n",
       "56055                    NaN  \n",
       "56056                    NaN  \n",
       "56058                    NaN  \n",
       "56059   SATSUMA,IWOJIMA,RJX7  \n",
       "\n",
       "[44554 rows x 18 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select * from airports where type not in ('heliport', 'balloonport')\n",
    "# isin()\n",
    "airports[~airports['type'].isin(['heliport', 'balloonport'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "iso_country  type          \n",
       "US           small_airport     13570\n",
       "             heliport           6241\n",
       "BR           small_airport      3205\n",
       "US           closed             1684\n",
       "AU           small_airport      1542\n",
       "KR           heliport           1257\n",
       "BR           heliport           1075\n",
       "CA           small_airport      1005\n",
       "MX           small_airport       926\n",
       "DE           small_airport       746\n",
       "GB           small_airport       732\n",
       "US           medium_airport      687\n",
       "CA           closed              655\n",
       "AR           small_airport       625\n",
       "CO           small_airport       592\n",
       "US           seaplane_base       570\n",
       "IT           small_airport       547\n",
       "PG           small_airport       507\n",
       "RU           small_airport       504\n",
       "VE           small_airport       456\n",
       "CA           heliport            416\n",
       "ZA           small_airport       414\n",
       "ID           small_airport       399\n",
       "FR           small_airport       398\n",
       "CA           seaplane_base       380\n",
       "KE           small_airport       351\n",
       "CL           small_airport       338\n",
       "CA           medium_airport      327\n",
       "MX           heliport            306\n",
       "ES           small_airport       304\n",
       "                               ...  \n",
       "MT           heliport              1\n",
       "MS           medium_airport        1\n",
       "MK           large_airport         1\n",
       "DK           seaplane_base         1\n",
       "MD           closed                1\n",
       "ME           large_airport         1\n",
       "             medium_airport        1\n",
       "MF           medium_airport        1\n",
       "DJ           medium_airport        1\n",
       "MF           seaplane_base         1\n",
       "DE           seaplane_base         1\n",
       "MG           large_airport         1\n",
       "MH           closed                1\n",
       "MK           closed                1\n",
       "DE           balloonport           1\n",
       "MK           medium_airport        1\n",
       "MS           closed                1\n",
       "CZ           large_airport         1\n",
       "ML           large_airport         1\n",
       "MM           closed                1\n",
       "MN           large_airport         1\n",
       "MO           heliport              1\n",
       "             large_airport         1\n",
       "CX           medium_airport        1\n",
       "CW           medium_airport        1\n",
       "MP           small_airport         1\n",
       "MQ           medium_airport        1\n",
       "CV           large_airport         1\n",
       "MR           large_airport         1\n",
       "PA           large_airport         1\n",
       "Length: 846, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select count(*) from airports group by iso_country, type order by count(*)\n",
    "airports.groupby(['iso_country', 'type']).size().sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "type\n",
       "small_airport    13570\n",
       "heliport          6241\n",
       "closed            1684\n",
       "dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select count(*) from airports where iso_country = 'US' group by type having count(*) > 1000 order by count(*) desc\n",
    "# we can use filter for having surrounded by groupby \n",
    "airports[airports['iso_country'] == 'US'].groupby('type')./\n",
    "filter(lambda x: len(x) > 1000).groupby('type').size().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>airport_ref</th>\n",
       "      <th>airport_ident</th>\n",
       "      <th>type</th>\n",
       "      <th>description</th>\n",
       "      <th>frequency_mhz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4412</th>\n",
       "      <td>57161</td>\n",
       "      <td>2877</td>\n",
       "      <td>FHAW</td>\n",
       "      <td>ACC</td>\n",
       "      <td>ATLANTICO FIR</td>\n",
       "      <td>1795.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19803</th>\n",
       "      <td>71811</td>\n",
       "      <td>4976</td>\n",
       "      <td>NSFA</td>\n",
       "      <td>APP</td>\n",
       "      <td>APP</td>\n",
       "      <td>1790.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19806</th>\n",
       "      <td>71814</td>\n",
       "      <td>4976</td>\n",
       "      <td>NSFA</td>\n",
       "      <td>INFO</td>\n",
       "      <td>RDO</td>\n",
       "      <td>1790.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19809</th>\n",
       "      <td>71817</td>\n",
       "      <td>4976</td>\n",
       "      <td>NSFA</td>\n",
       "      <td>TWR</td>\n",
       "      <td>TWR</td>\n",
       "      <td>1790.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22746</th>\n",
       "      <td>51506</td>\n",
       "      <td>6104</td>\n",
       "      <td>SKBO</td>\n",
       "      <td>OPS</td>\n",
       "      <td>MILGP RDO OPS</td>\n",
       "      <td>1395.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24453</th>\n",
       "      <td>53626</td>\n",
       "      <td>26782</td>\n",
       "      <td>WAPK</td>\n",
       "      <td>RDO</td>\n",
       "      <td>RDO</td>\n",
       "      <td>1340.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4632</th>\n",
       "      <td>51120</td>\n",
       "      <td>3043</td>\n",
       "      <td>FZAI</td>\n",
       "      <td>A/G</td>\n",
       "      <td>A/G VOICE RDO</td>\n",
       "      <td>1330.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21904</th>\n",
       "      <td>55004</td>\n",
       "      <td>5656</td>\n",
       "      <td>RKSS</td>\n",
       "      <td>A/G</td>\n",
       "      <td>SEOUL RDO</td>\n",
       "      <td>1330.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19649</th>\n",
       "      <td>51624</td>\n",
       "      <td>4839</td>\n",
       "      <td>MUHA</td>\n",
       "      <td>A/G</td>\n",
       "      <td>BOYEROS RDO INTL</td>\n",
       "      <td>1329.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4916</th>\n",
       "      <td>51919</td>\n",
       "      <td>2383</td>\n",
       "      <td>HE44</td>\n",
       "      <td>RDO</td>\n",
       "      <td>UN ISMAILIYAH OPS</td>\n",
       "      <td>1325.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  airport_ref airport_ident  type        description  \\\n",
       "4412   57161         2877          FHAW   ACC      ATLANTICO FIR   \n",
       "19803  71811         4976          NSFA   APP                APP   \n",
       "19806  71814         4976          NSFA  INFO                RDO   \n",
       "19809  71817         4976          NSFA   TWR                TWR   \n",
       "22746  51506         6104          SKBO   OPS      MILGP RDO OPS   \n",
       "24453  53626        26782          WAPK   RDO                RDO   \n",
       "4632   51120         3043          FZAI   A/G      A/G VOICE RDO   \n",
       "21904  55004         5656          RKSS   A/G          SEOUL RDO   \n",
       "19649  51624         4839          MUHA   A/G   BOYEROS RDO INTL   \n",
       "4916   51919         2383          HE44   RDO  UN ISMAILIYAH OPS   \n",
       "\n",
       "       frequency_mhz  \n",
       "4412          1795.5  \n",
       "19803         1790.4  \n",
       "19806         1790.4  \n",
       "19809         1790.4  \n",
       "22746         1395.0  \n",
       "24453         1340.0  \n",
       "4632          1330.4  \n",
       "21904         1330.3  \n",
       "19649         1329.7  \n",
       "4916          1325.7  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select * from airport_freq order by frequency_mhz desc limit 10\n",
    "# nlargest \n",
    "# opposite is nsmallest\n",
    "airport_freq.nlargest(10,columns='frequency_mhz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>airport_ref</th>\n",
       "      <th>airport_ident</th>\n",
       "      <th>type</th>\n",
       "      <th>description</th>\n",
       "      <th>frequency_mhz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4421</th>\n",
       "      <td>53981</td>\n",
       "      <td>2880</td>\n",
       "      <td>FJDG</td>\n",
       "      <td>A/G</td>\n",
       "      <td>A/G VOICE</td>\n",
       "      <td>1325.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19771</th>\n",
       "      <td>54876</td>\n",
       "      <td>4972</td>\n",
       "      <td>NGTA</td>\n",
       "      <td>CTAF</td>\n",
       "      <td>TARAWA RDO</td>\n",
       "      <td>1133.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19863</th>\n",
       "      <td>55696</td>\n",
       "      <td>5011</td>\n",
       "      <td>NVVV</td>\n",
       "      <td>AFIS</td>\n",
       "      <td>FLT SVC</td>\n",
       "      <td>1133.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19866</th>\n",
       "      <td>55699</td>\n",
       "      <td>5011</td>\n",
       "      <td>NVVV</td>\n",
       "      <td>TWR</td>\n",
       "      <td>TWR</td>\n",
       "      <td>1133.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20991</th>\n",
       "      <td>68693</td>\n",
       "      <td>5388</td>\n",
       "      <td>PANC</td>\n",
       "      <td>MISC</td>\n",
       "      <td>SAN FRANCISCO ARINC</td>\n",
       "      <td>1133.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19632</th>\n",
       "      <td>51653</td>\n",
       "      <td>4834</td>\n",
       "      <td>MUCM</td>\n",
       "      <td>A/G</td>\n",
       "      <td>CAMAGUEY RDO</td>\n",
       "      <td>1132.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19636</th>\n",
       "      <td>51639</td>\n",
       "      <td>4835</td>\n",
       "      <td>MUCU</td>\n",
       "      <td>A/G</td>\n",
       "      <td>SANTIAGO RDO</td>\n",
       "      <td>1132.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19648</th>\n",
       "      <td>51626</td>\n",
       "      <td>4839</td>\n",
       "      <td>MUHA</td>\n",
       "      <td>A/G</td>\n",
       "      <td>BOYEROS RDO NATL</td>\n",
       "      <td>1132.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19656</th>\n",
       "      <td>51668</td>\n",
       "      <td>4840</td>\n",
       "      <td>MUHG</td>\n",
       "      <td>A/G</td>\n",
       "      <td>HOLGUIN RDO</td>\n",
       "      <td>1132.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19675</th>\n",
       "      <td>51659</td>\n",
       "      <td>4859</td>\n",
       "      <td>MUVR</td>\n",
       "      <td>A/G</td>\n",
       "      <td>VARADERO RDO</td>\n",
       "      <td>1132.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  airport_ref airport_ident  type          description  \\\n",
       "4421   53981         2880          FJDG   A/G            A/G VOICE   \n",
       "19771  54876         4972          NGTA  CTAF           TARAWA RDO   \n",
       "19863  55696         5011          NVVV  AFIS              FLT SVC   \n",
       "19866  55699         5011          NVVV   TWR                  TWR   \n",
       "20991  68693         5388          PANC  MISC  SAN FRANCISCO ARINC   \n",
       "19632  51653         4834          MUCM   A/G         CAMAGUEY RDO   \n",
       "19636  51639         4835          MUCU   A/G         SANTIAGO RDO   \n",
       "19648  51626         4839          MUHA   A/G     BOYEROS RDO NATL   \n",
       "19656  51668         4840          MUHG   A/G          HOLGUIN RDO   \n",
       "19675  51659         4859          MUVR   A/G         VARADERO RDO   \n",
       "\n",
       "       frequency_mhz  \n",
       "4421          1325.4  \n",
       "19771         1133.9  \n",
       "19863         1133.9  \n",
       "19866         1133.9  \n",
       "20991         1133.0  \n",
       "19632         1132.1  \n",
       "19636         1132.1  \n",
       "19648         1132.1  \n",
       "19656         1132.1  \n",
       "19675         1132.1  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select * from airport_freq order by frequency_mhz desc limit 10 offset 10 \n",
    "# return next 10 \n",
    "airport_freq.nlargest(20,columns='frequency_mhz').tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "max       120000.00000\n",
       "min            0.00000\n",
       "mean        3262.31036\n",
       "median      2745.00000\n",
       "Name: length_ft, dtype: float64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select max(length_ft), min(length_ft), avg(length_ft), median(length_ft) from runways\n",
    "runways['length_ft'].aggregate([max,min,mean,median])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airport_ident</th>\n",
       "      <th>type</th>\n",
       "      <th>description</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KLAX</td>\n",
       "      <td>large_airport</td>\n",
       "      <td>SOCAL APP</td>\n",
       "      <td>Los Angeles International Airport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KLAX</td>\n",
       "      <td>large_airport</td>\n",
       "      <td>SOCAL APP</td>\n",
       "      <td>Los Angeles International Airport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KLAX</td>\n",
       "      <td>large_airport</td>\n",
       "      <td>ATIS</td>\n",
       "      <td>Los Angeles International Airport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KLAX</td>\n",
       "      <td>large_airport</td>\n",
       "      <td>CLNC DEL</td>\n",
       "      <td>Los Angeles International Airport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KLAX</td>\n",
       "      <td>large_airport</td>\n",
       "      <td>SOCAL DEP</td>\n",
       "      <td>Los Angeles International Airport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>KLAX</td>\n",
       "      <td>large_airport</td>\n",
       "      <td>GND</td>\n",
       "      <td>Los Angeles International Airport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>KLAX</td>\n",
       "      <td>large_airport</td>\n",
       "      <td>CG</td>\n",
       "      <td>Los Angeles International Airport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>KLAX</td>\n",
       "      <td>large_airport</td>\n",
       "      <td>CG</td>\n",
       "      <td>Los Angeles International Airport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>KLAX</td>\n",
       "      <td>large_airport</td>\n",
       "      <td>AF</td>\n",
       "      <td>Los Angeles International Airport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>KLAX</td>\n",
       "      <td>large_airport</td>\n",
       "      <td>TWR</td>\n",
       "      <td>Los Angeles International Airport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>KLAX</td>\n",
       "      <td>large_airport</td>\n",
       "      <td>UNICOM</td>\n",
       "      <td>Los Angeles International Airport</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   airport_ident           type description                               name\n",
       "0           KLAX  large_airport   SOCAL APP  Los Angeles International Airport\n",
       "1           KLAX  large_airport   SOCAL APP  Los Angeles International Airport\n",
       "2           KLAX  large_airport        ATIS  Los Angeles International Airport\n",
       "3           KLAX  large_airport    CLNC DEL  Los Angeles International Airport\n",
       "4           KLAX  large_airport   SOCAL DEP  Los Angeles International Airport\n",
       "5           KLAX  large_airport         GND  Los Angeles International Airport\n",
       "6           KLAX  large_airport          CG  Los Angeles International Airport\n",
       "7           KLAX  large_airport          CG  Los Angeles International Airport\n",
       "8           KLAX  large_airport          AF  Los Angeles International Airport\n",
       "9           KLAX  large_airport         TWR  Los Angeles International Airport\n",
       "10          KLAX  large_airport      UNICOM  Los Angeles International Airport"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# join \n",
    "# select airport_ident, type, description, name from airport_freq join airports \n",
    "# on airport_freq.airport_ref = airports.id where airports.ident = 'KLAX'\n",
    "airport_freq.rename(columns={'type':'freq_type'},inplace=True)\n",
    "airport_freq.merge(airports[airports['ident'] == 'KLAX'], \n",
    "                   left_on='airport_ref', right_on='id')[['airport_ident', 'type', 'description', 'name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>municipality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Los Angeles International Airport</td>\n",
       "      <td>Los Angeles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Long Beach /Daugherty Field/ Airport</td>\n",
       "      <td>Long Beach</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   name municipality\n",
       "0     Los Angeles International Airport  Los Angeles\n",
       "1  Long Beach /Daugherty Field/ Airport   Long Beach"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select name, municipality from airports where ident = 'KLAX' union all select name, municipality \n",
    "# from airports where ident = 'KLGB'\n",
    "pd.concat([airports[airports['ident'] == 'KLAX'][['name', 'municipality']],\n",
    "           airports[airports['ident'] == 'KLGB'][['name', 'municipality']]]).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Name  Age    Address Qualification  Mobile No    Name  Age    Address  \\\n",
      "2  Gaurav   22  Allahabad           MCA         58  Gaurav   22  Allahabad   \n",
      "3    Anuj   32    Kannuaj           Phd         76    Anuj   32    Kannuaj   \n",
      "\n",
      "  Qualification  Salary  \n",
      "2           MCA    1000  \n",
      "3           Phd    2000  \n"
     ]
    }
   ],
   "source": [
    "# intersection\n",
    "data1 = {'Name':['Jai', 'Princi', 'Gaurav', 'Anuj'], \n",
    "        'Age':[27, 24, 22, 32], \n",
    "        'Address':['Nagpur', 'Kanpur', 'Allahabad', 'Kannuaj'], \n",
    "        'Qualification':['Msc', 'MA', 'MCA', 'Phd'],\n",
    "        'Mobile No': [97, 91, 58, 76]} \n",
    "# Define a dictionary containing employee data \n",
    "data2 = {'Name':['Gaurav', 'Anuj', 'Dhiraj', 'Hitesh'], \n",
    "        'Age':[22, 32, 12, 52], \n",
    "        'Address':['Allahabad', 'Kannuaj', 'Allahabad', 'Kannuaj'], \n",
    "        'Qualification':['MCA', 'Phd', 'Bcom', 'B.hons'],\n",
    "        'Salary':[1000, 2000, 3000, 4000]} \n",
    "# Convert the dictionary into DataFrame  \n",
    "df = pd.DataFrame(data1,index=[0, 1, 2, 3])\n",
    "# Convert the dictionary into DataFrame  \n",
    "df1 = pd.DataFrame(data2, index=[2, 3, 6, 7]) \n",
    "res2 = pd.concat([df, df1], axis=1, join='inner')\n",
    "print(res2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28336    http://www.lawa.org/welcomelax.aspx\n",
       "Name: home_link, dtype: object"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# update airports set home_link = 'http://www.lawa.org/welcomelax.aspx' where ident == 'KLAX'\n",
    "# we can update using loc \n",
    "airports.loc[airports['ident'] == 'KLAX','home_link'] = 'http://www.lawa.org/welcomelax.aspx'\n",
    "airports[airports['ident'] == 'KLAX']['home_link']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete from airports where ident = 'KLAX'\n",
    "airports.drop(airports[airports['ident'] == 'KLAX'].index,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min frequency_mhz: ESCRAVOS TOWER\n",
      "max frequency_mhz: ATLANTICO FIR\n"
     ]
    }
   ],
   "source": [
    "# min and max \n",
    "# idxmin - index of min & idxmax - index of max  \n",
    "print('min frequency_mhz:',airport_freq.loc[airport_freq['frequency_mhz'].idxmin()]['description'])\n",
    "print('max frequency_mhz:',airport_freq.loc[airport_freq['frequency_mhz'].idxmax()]['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
      "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
      "      dtype='object') \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Pclass</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>female</th>\n",
       "      <td>0.97</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male</th>\n",
       "      <td>0.37</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Pclass    1    2    3\n",
       "Sex                  \n",
       "female 0.97 0.92 0.50\n",
       "male   0.37 0.16 0.14"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pivot table \n",
    "# average survival rate for both males and females? In all 3 passenger classes\n",
    "df = pd.read_csv('data/titanic.csv')\n",
    "print(df.columns,'\\n')\n",
    "df.pivot_table(index = 'Sex', columns = 'Pclass', values = 'Survived', aggfunc = 'mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col_0  one  two\n",
      "row_0          \n",
      "b1       3    1\n",
      "s1       4    3\n",
      "\n",
      " q  one    two   \n",
      "r    x  y   x  y\n",
      "p               \n",
      "b1   1  2   1  0\n",
      "s1   2  2   1  2\n"
     ]
    }
   ],
   "source": [
    "# frequency table\n",
    "p = array([\"s1\",\"s1\",\"s1\",\"s1\",\"b1\",\"b1\",\"b1\",\"b1\",\"s1\",\"s1\",\"s1\"], dtype=object)\n",
    "q = array([\"one\",\"one\",\"one\",\"two\",\"one\",\"one\",\"one\",\"two\",\"two\",\"two\",\"one\"], dtype=object)\n",
    "r = array([\"x\",\"x\",\"y\",\"x\",\"x\",\"y\",\"y\",\"x\",\"y\",\"y\",\"y\"], dtype=object)\n",
    "print(pd.crosstab(p,q))\n",
    "print('\\n',pd.crosstab(p, [q, r], rownames=['p'], colnames=['q', 'r']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# web scraping "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are two libraies that we use for scraping \n",
    "# bs4(library) & scrapy(framework)\n",
    "# bs4 for smaller tasks and scrapy for complex projects\n",
    "# bs4 uses dom parsing style and uses selectors \n",
    "# where as scrapy follows event driven and uses xpath  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html>\n",
      " <head>\n",
      "  <title>\n",
      "   FX Rates\n",
      "  </title>\n",
      "  <link crossorigin=\"anonymous\" href=\"https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css\" integrity=\"sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T\" rel=\"stylesheet\"/>\n",
      "  <link crossorigin=\"anonymous\" href=\"https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.9.0/css/all.min.css\" rel=\"stylesheet\"/>\n",
      "  <meta charset=\"utf-8\"/>\n",
      "  <meta content=\"width=device-width, initial-scale=1, shrink-to-fit=no\" name=\"viewport\"/>\n",
      "  <style>\n",
      "   .date {\n",
      "\tcolor: blue;\n",
      "}\n",
      "  </style>\n",
      "  <script crossorigin=\"anonymous\" integrity=\"sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo\" src=\"https://code.jquery.com/jquery-3.3.1.slim.min.js\">\n",
      "  </script>\n",
      "  <script crossorigin=\"anonymous\" integrity=\"sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1\" src=\"https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js\">\n",
      "  </script>\n",
      "  <script crossorigin=\"anonymous\" integrity=\"sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM\" src=\"https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js\">\n",
      "  </script>\n",
      " </head>\n",
      " <body>\n",
      "  <div class=\"container\">\n",
      "   <div class=\"row\">\n",
      "    <div class=\"col-sm\">\n",
      "     <h1 class=\"text-center\">\n",
      "      FX Rates\n",
      "     </h1>\n",
      "     <h4>\n",
      "      Base:\n",
      "      <i class=\"fas fa-dollar-sign\" data-toggle=\"tooltip\" title=\"USD\">\n",
      "      </i>\n",
      "     </h4>\n",
      "    </div>\n",
      "   </div>\n",
      "   <div class=\"row\">\n",
      "    <div class=\"col\">\n",
      "     <table class=\"table table-stripped\">\n",
      "      <thead>\n",
      "       <thead>\n",
      "        <th>\n",
      "         Currency\n",
      "        </th>\n",
      "        <th>\n",
      "         Rate\n",
      "        </th>\n",
      "       </thead>\n",
      "       <tbody>\n",
      "        <tr>\n",
      "         <td>\n",
      "          <i class=\"fas fa-pound-sign\" data-toggle=\"tooltip\" title=\"GBP\">\n",
      "          </i>\n",
      "         </td>\n",
      "         <td>\n",
      "          0.83\n",
      "         </td>\n",
      "        </tr>\n",
      "        <tr>\n",
      "         <td>\n",
      "          <i class=\"fas fa-euro-sign\" data-toggle=\"tooltip\" title=\"EUR\">\n",
      "          </i>\n",
      "         </td>\n",
      "         <td>\n",
      "          0.89\n",
      "         </td>\n",
      "        </tr>\n",
      "        <tr>\n",
      "         <td>\n",
      "          <i class=\"fas fa-yen-sign\" data-toggle=\"tooltip\" title=\"JPY\">\n",
      "          </i>\n",
      "         </td>\n",
      "         <td>\n",
      "          105.3\n",
      "         </td>\n",
      "        </tr>\n",
      "        <tr>\n",
      "         <td>\n",
      "          <i class=\"fab fa-btc\" data-toggle=\"tooltip\" title=\"BTC\">\n",
      "          </i>\n",
      "         </td>\n",
      "         <td>\n",
      "          0.000088\n",
      "         </td>\n",
      "        </tr>\n",
      "        <tr>\n",
      "         <td>\n",
      "          <i class=\"fas fa-shekel-sign\" data-toggle=\"tooltip\" title=\"ILS\">\n",
      "          </i>\n",
      "         </td>\n",
      "         <td>\n",
      "          3.48\n",
      "         </td>\n",
      "        </tr>\n",
      "       </tbody>\n",
      "      </thead>\n",
      "     </table>\n",
      "    </div>\n",
      "   </div>\n",
      "   <div class=\"row\">\n",
      "    <div class=\"col-sm\">\n",
      "     <h4>\n",
      "      Date:\n",
      "      <i class=\"date\">\n",
      "       2019-11-11\n",
      "      </i>\n",
      "     </h4>\n",
      "    </div>\n",
      "   </div>\n",
      "  </div>\n",
      "  <script>\n",
      "   $(document).ready(function(){\n",
      "  $('[data-toggle=\"tooltip\"]').tooltip(); \n",
      "});\n",
      "  </script>\n",
      " </body>\n",
      "</html>\n",
      "\n",
      "FX Rates\n",
      "bootstrap cdn:https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js\n",
      "date: 2019-11-11 00:00:00\n",
      "row_0:USD/GBP = 0.830000\n",
      "row_1:USD/EUR = 0.890000\n",
      "row_2:USD/JPY = 105.300000\n",
      "row_3:USD/BTC = 0.000088\n",
      "row_4:USD/ILS = 3.480000\n"
     ]
    }
   ],
   "source": [
    "# local html parsing \n",
    "def parse_html(html):\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    print(soup.prettify())\n",
    "    print(soup.title.string) # similarly you can get head \n",
    "    print(f\"bootstrap cdn:{soup.find_all('script')[2].attrs['src']}\")\n",
    "    # <h4>Date: <i class=\"date\">2019-11-11</i></h4>\n",
    "    i = soup('i', {'class': 'date'})\n",
    "    if not i:\n",
    "        raise ValueError('cannot find date')\n",
    "    if(soup.find('i', {'class': 'date'}).parent.name == 'h4'): # check if the parent tag is a h4 tag \n",
    "        date = datetime.strptime(i[0].text, '%Y-%m-%d')\n",
    "        rowclass = soup.find('i', {'class': 'date'}).find_parent('div',class_=\"col-sm\").\\\n",
    "                    parent.attrs['class']\n",
    "        \n",
    "\n",
    "    rates = {}\n",
    "    for tr in soup('tr'):\n",
    "        # <tr>\n",
    "        # <td><i class=\"fas fa-pound-sign\" data-toggle=\"tooltip\"\n",
    "        #   title=\"GBP\"></i></td>\n",
    "        # <td>0.83</td>\n",
    "        # </tr>\n",
    "        symbol_td, rate_td = tr('td')\n",
    "        symbol = symbol_td('i')[0]['title']\n",
    "        rate = float(rate_td.text)\n",
    "        rates[symbol] = rate\n",
    "\n",
    "    return date, rates, rowclass\n",
    "\n",
    "with open('data/rates.html') as fp:\n",
    "    html = fp.read()\n",
    "    date, rates, rowclass = parse_html(html)\n",
    "    print(f'date: {date}')\n",
    "    row = 0\n",
    "    for symbol, rate in rates.items():\n",
    "        print(f'{rowclass[0]}_{row}:USD/{symbol} = {rate:f}')\n",
    "        row += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "<div class=\"image_container\">\n",
      "<a href=\"a-light-in-the-attic_1000/index.html\"><img alt=\"A Light in the Attic\" class=\"thumbnail\" src=\"../media/cache/2c/da/2cdad67c44b002e7ead0cc35693c0e8b.jpg\"/></a>\n",
      "</div>\n",
      "\n",
      "\n",
      "<p class=\"star-rating Three\">\n",
      "<i class=\"icon-star\"></i>\n",
      "<i class=\"icon-star\"></i>\n",
      "<i class=\"icon-star\"></i>\n",
      "<i class=\"icon-star\"></i>\n",
      "<i class=\"icon-star\"></i>\n",
      "</p>\n",
      "\n",
      "\n",
      "<h3><a href=\"a-light-in-the-attic_1000/index.html\" title=\"A Light in the Attic\">A Light in the ...</a></h3>\n",
      "\n",
      "\n",
      "<div class=\"product_price\">\n",
      "<p class=\"price_color\">Â£51.77</p>\n",
      "<p class=\"instock availability\">\n",
      "<i class=\"icon-ok\"></i>\n",
      "    \n",
      "        In stock\n",
      "    \n",
      "</p>\n",
      "<form>\n",
      "<button class=\"btn btn-primary btn-block\" data-loading-text=\"Adding...\" type=\"submit\">Add to basket</button>\n",
      "</form>\n",
      "</div>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# getting content using classes and id's\n",
    "base_url = 'http://books.toscrape.com/catalogue/page-{}.html'\n",
    "res = requests.get(base_url.format('1'))\n",
    "soup = BeautifulSoup(res.text,\"lxml\")\n",
    "for el in soup.select(\".product_pod\")[0].children:\n",
    "    print(el)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content:-\n",
      "[<title>Geeks For Geeks</title>]\n",
      "descendants:-\n",
      "<title>Geeks For Geeks</title>\n",
      "Geeks For Geeks\n",
      "strings:-\n",
      "'Geeks For Geeks'\n",
      "'most viewed courses in GFG,its all free'\n",
      "'Top 5 Popular Programming Languages'\n",
      "'Java'\n",
      "'c/c++'\n",
      "'Python'\n",
      "'Javascript'\n",
      "'Ruby'\n",
      "'Geeks For Geeks'\n",
      "\"The Biggest Online Tutorials Library, It's all Free\"\n",
      "'according to an online survey.'\n",
      "'Programming Languages'\n",
      "children:-\n",
      "Top 5 Popular Programming Languages\n",
      "sibling:-\n",
      "The Biggest Online Tutorials Library, It's all Free\n"
     ]
    }
   ],
   "source": [
    "# navigating a html doc using beautiful soup\n",
    "def parse_html(html):\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    # assigning head tag of BeautifulSoup variable\n",
    "    hTag = soup.head\n",
    "    # retrieving contents of BeautifulSoup variable\n",
    "    print('content:-')\n",
    "    print(hTag.contents)\n",
    "    # iterating through child in descendants of htag variable\n",
    "    print('descendants:-')\n",
    "    for child in hTag.descendants:\n",
    "        print(child)\n",
    "    # iterating through all string in docs using stripped_strings \n",
    "    print('strings:-')\n",
    "    for string in soup.stripped_strings :\n",
    "        print(repr(string))\n",
    "    print('children:-')\n",
    "    print(soup.find_all('p')[1].next_element)\n",
    "    print('sibling:-')\n",
    "    print(soup.li.next_sibling.string)\n",
    "with open('data/test_navigate.html') as fp:\n",
    "    html = fp.read()\n",
    "    parse_html(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<body>\n",
      " <div class=\"container\">\n",
      "  <div class=\"row\">\n",
      "   <div class=\"col-sm\">\n",
      "    <h1 class=\"text-center\">\n",
      "     FX Rates\n",
      "    </h1>\n",
      "    <h4>\n",
      "     Base:\n",
      "     <i class=\"fas fa-dollar-sign\" data-toggle=\"tooltip\" title=\"USD\">\n",
      "     </i>\n",
      "    </h4>\n",
      "   </div>\n",
      "  </div>\n",
      "  <div class=\"row\">\n",
      "   <div class=\"col\">\n",
      "    <table class=\"table table-stripped\">\n",
      "     <thead>\n",
      "      <thead>\n",
      "       <th>\n",
      "        Currency\n",
      "       </th>\n",
      "       <th>\n",
      "        Rate\n",
      "       </th>\n",
      "      </thead>\n",
      "      <tbody>\n",
      "       <tr>\n",
      "        <td>\n",
      "         <i class=\"fas fa-pound-sign\" data-toggle=\"tooltip\" title=\"GBP\">\n",
      "         </i>\n",
      "        </td>\n",
      "        <td>\n",
      "         0.83\n",
      "        </td>\n",
      "       </tr>\n",
      "       <tr>\n",
      "        <td>\n",
      "         <i class=\"fas fa-euro-sign\" data-toggle=\"tooltip\" title=\"EUR\">\n",
      "         </i>\n",
      "        </td>\n",
      "        <td>\n",
      "         0.89\n",
      "        </td>\n",
      "       </tr>\n",
      "       <tr>\n",
      "        <td>\n",
      "         <i class=\"fas fa-yen-sign\" data-toggle=\"tooltip\" title=\"JPY\">\n",
      "         </i>\n",
      "        </td>\n",
      "        <td>\n",
      "         105.3\n",
      "        </td>\n",
      "       </tr>\n",
      "       <tr>\n",
      "        <td>\n",
      "         <i class=\"fab fa-btc\" data-toggle=\"tooltip\" title=\"BTC\">\n",
      "         </i>\n",
      "        </td>\n",
      "        <td>\n",
      "         0.000088\n",
      "        </td>\n",
      "       </tr>\n",
      "       <tr>\n",
      "        <td>\n",
      "         <i class=\"fas fa-shekel-sign\" data-toggle=\"tooltip\" title=\"ILS\">\n",
      "         </i>\n",
      "        </td>\n",
      "        <td>\n",
      "         3.48\n",
      "        </td>\n",
      "       </tr>\n",
      "      </tbody>\n",
      "     </thead>\n",
      "    </table>\n",
      "   </div>\n",
      "  </div>\n",
      "  <div class=\"row\">\n",
      "   <div class=\"col-sm\">\n",
      "    <h4>\n",
      "     Date:\n",
      "     <i class=\"date\">\n",
      "      2019-11-11\n",
      "     </i>\n",
      "    </h4>\n",
      "   </div>\n",
      "  </div>\n",
      " </div>\n",
      " <script>\n",
      "  $(document).ready(function(){\n",
      "  $('[data-toggle=\"tooltip\"]').tooltip(); \n",
      "});\n",
      " </script>\n",
      "</body>\n"
     ]
    }
   ],
   "source": [
    "# parsing section of a document using soup strainer \n",
    "from bs4 import BeautifulSoup, SoupStrainer\n",
    "def parse_html(html):\n",
    "    parse_only = SoupStrainer(\"body\")\n",
    "    soup = BeautifulSoup(html, 'html.parser',parse_only=parse_only)\n",
    "    print(soup.prettify())\n",
    "with open('data/rates.html') as fp:\n",
    "    html = fp.read()\n",
    "    parse_html(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After modifying the tag name: \n",
      "<div class=\"para\">gfg</div>\n",
      "After modifying and adding attributes: \n",
      "<div class=\"div_class\" id=\"div_id\">gfg</div>\n",
      "After deleting class attribute: \n",
      "<div id=\"div_id\">gfg</div>\n",
      "After modifying tag string: \n",
      "<div id=\"div_id\">Geeks</div>\n",
      "After inserting: \n",
      "<div id=\"div_id\">Geeks for Geeks</div>\n",
      "insert before:\n",
      "<p>Geeks for Geeks</p>\n",
      "wrapping string\n",
      "<div id=\"div_id\">Geeks for Geeks</div><p><i>Geeks for Geeks</i></p>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# modifying html using bs4\n",
    "markup = \"\"\"<p class=\"para\">gfg</p>\n",
    "\"\"\"\n",
    "# parsering string to HTML\n",
    "soup = BeautifulSoup(markup, 'html.parser')\n",
    "# extracting a tag\n",
    "tag = soup.p\n",
    "# modifying tag name\n",
    "tag.name = \"div\" \n",
    "print(\"After modifying the tag name: \")\n",
    "print(tag)\n",
    "# modifying its class attribute\n",
    "tag['class'] = \"div_class\"\n",
    "# adding new attribute\n",
    "tag['id'] = \"div_id\"\n",
    "print(\"After modifying and adding attributes: \")\n",
    "print(tag) \n",
    "# to delete any attributes\n",
    "del tag[\"class\"]\n",
    "print(\"After deleting class attribute: \")\n",
    "print(tag) \n",
    "# modifying the tags content\n",
    "tag.string = \"Geeks\"\n",
    "print(\"After modifying tag string: \")\n",
    "print(tag)\n",
    "# inserting content\n",
    "tag = soup.div\n",
    "tag.insert(1, \" for Geeks\")\n",
    "print(\"After inserting: \")\n",
    "print(tag)\n",
    "# adding tags\n",
    "tag = soup.new_tag(\"p\")\n",
    "tag.string = \"Geeks for Geeks\"\n",
    "# insert after\n",
    "print('insert before:')\n",
    "soup.div.insert_after(tag)\n",
    "print(soup.p)\n",
    "# wrapping around the string\n",
    "print('wrapping string')\n",
    "soup.p.string.wrap(soup.new_tag(\"i\"))\n",
    "print(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "website_url = requests.get('https://en.wikipedia.org/wiki/List_of_Asian_countries_by_area').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(website_url,'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Asian countries by area - Wikipedia\n",
      "['Russia', 'European Russia', 'China', 'Taiwan', 'Hong Kong', 'Macao', 'India', 'Kazakhstan', 'Saudi Arabia', 'Iran', 'Mongolia', 'Indonesia', 'Western New Guinea', 'Oceania', 'Pakistan', 'Turkey', 'East Thrace', 'Myanmar', 'Afghanistan', 'Yemen', 'Thailand', 'Turkmenistan', 'Uzbekistan', 'Iraq', 'Japan', 'Vietnam', 'Malaysia', 'Oman', 'Philippines', 'Laos', 'Kyrgyzstan', 'Syria', 'Golan Heights', 'Cambodia', 'Bangladesh', 'Nepal', 'Tajikistan', 'North Korea', 'South Korea', 'Jordan', 'United Arab Emirates', 'Azerbaijan', 'Caucasus', 'Europe', 'Asia', 'Georgia (country)', 'Caucasus', 'Europe', 'Asia', 'Sri Lanka', 'Egypt', 'Bhutan', 'Taiwan', 'Armenia', 'Armenian highlands', 'Caucasus', 'Europe', 'Asia', 'Israel', 'West Bank', 'Gaza Strip', 'Golan Heights', 'Kuwait', 'East Timor', 'Qatar', 'Lebanon', 'Cyprus', 'Northern Cyprus', 'State of Palestine', 'West Bank', 'Gaza Strip', 'Brunei', 'Bahrain', 'Singapore', 'Maldives']\n"
     ]
    }
   ],
   "source": [
    "print(soup.title.string)\n",
    "countries = []\n",
    "# find 1st matching vs all matching(complete tag including child tags)  \n",
    "my_table = soup.find('table',{'class':'wikitable sortable'})\n",
    "links = my_table.findAll('a',href=True)\n",
    "for link in links:\n",
    "    if link.has_attr(\"title\"):\n",
    "        # get the value of the attribute \n",
    "        countries.append(link.get('title'))\n",
    "print(countries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# monster.com "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = 'https://www.monster.com/jobs/search/?q=Software-Developer&where=Australia'\n",
    "page = requests.get(URL)\n",
    "soup = BeautifulSoup(page.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find by id\n",
    "results = soup.find(id='ResultsContainer')\n",
    "# find by class and element \n",
    "job_elems = results.find_all('section', class_='card-content')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQL BI (SSRS, SSIS) developer for Blackboard - NYC\n",
      "LanceSoft Inc\n",
      "New york, WA\n",
      "\n",
      "Python Developer\n",
      "LanceSoft Inc\n",
      "Woodlands, WA\n",
      "\n",
      "Junior QA Analyst - Melbourne, Victoria\n",
      "Mediaocean\n",
      "Melbourne, VIC\n",
      "\n",
      "Test Analyst\n",
      "Dialog Group\n",
      "Canberra, ACT\n",
      "\n",
      "Test Consultant\n",
      "Dialog Group\n",
      "Brisbane, QLD\n",
      "\n",
      "Customer Experience Technical Analyst - Sydney, New South Wales\n",
      "Mediaocean\n",
      "Sydney, NSW\n",
      "\n",
      "Senior Practice Manager - IES (WA)\n",
      "Blue Ocean Ventures\n",
      "New York, WA\n",
      "\n",
      "Enterprise Account Executive\n",
      "Zuora\n",
      "Sydney, NSW\n",
      "\n",
      "Senior Automation Tester\n",
      "Dialog Group\n",
      "Canberra, ACT\n",
      "\n",
      "Software Developer (C# / ASP.NET) - Healthcare Software Company\n",
      "CyberCoders\n",
      "Chesterfield, MO\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for job_elem in job_elems:\n",
    "    title_elem = job_elem.find('h2', class_='title')\n",
    "    company_elem = job_elem.find('div', class_='company')\n",
    "    location_elem = job_elem.find('div', class_='location')\n",
    "    if None in (title_elem, company_elem, location_elem):\n",
    "        continue\n",
    "    # get text from the element \n",
    "    print(title_elem.text.strip())\n",
    "    print(company_elem.text.strip())\n",
    "    print(location_elem.text.strip())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python Developer\n",
      "Apply here: https://job-openings.monster.com/python-developer-woodlands-wa-us-lancesoft-inc/4755ec59-d0db-4ce9-8385-b4df7c1e9f7c\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get attribute \n",
    "# string here can be a list also\n",
    "python_jobs = results.find_all('h2',\n",
    "                        string=lambda text: \"python\" in text.lower())  \n",
    "\n",
    "for p_job in python_jobs:\n",
    "    link = p_job.find('a')['href']\n",
    "    print(p_job.text.strip())\n",
    "    print(f\"Apply here: {link}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hacker news "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zed, a collaborative code editor, is now open source (zed.dev), 1260 points, available at: https://zed.dev/blog/zed-is-now-open-source.\n"
     ]
    }
   ],
   "source": [
    "response = requests.get(\"https://news.ycombinator.com/\")\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "article_titles = []\n",
    "article_links = []\n",
    "for article_tag in soup.find_all(name=\"span\", class_=\"titleline\"):\n",
    "    article_titles.append(article_tag.text)# gets text from each span \n",
    "    article_links.append(article_tag.find(\"a\")[\"href\"])\n",
    "\n",
    "article_upvotes = []\n",
    "for article in soup.find_all(name=\"td\", class_=\"subtext\"):\n",
    "    if article.span.find(class_=\"score\") is None:\n",
    "        article_upvotes.append(0)\n",
    "    else:\n",
    "        article_upvotes.append(int(article.span.find(class_=\"score\").text.split()[0]))\n",
    "\n",
    "max_points_index = article_upvotes.index(max(article_upvotes))\n",
    "print(\n",
    "    f\"{article_titles[max_points_index]}, \"\n",
    "    f\"{article_upvotes[max_points_index]} points, \"\n",
    "    f\"available at: {article_links[max_points_index]}.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# empire online 100 movies to watch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = \"https://web.archive.org/web/20200518073855/https://www.empireonline.com/movies/features/best-movies-2/\"\n",
    "\n",
    "# Write your code below this line 👇\n",
    "\n",
    "response = requests.get(URL)\n",
    "website_html = response.text\n",
    "\n",
    "soup = BeautifulSoup(website_html, \"html.parser\")\n",
    "\n",
    "all_movies = soup.find_all(name=\"h3\", class_=\"title\")\n",
    "\n",
    "movie_titles = [movie.getText() for movie in all_movies]\n",
    "movies = movie_titles[::-1]\n",
    "\n",
    "with open(\"data/movies_100.txt\", mode=\"w\") as file:\n",
    "    for movie in movies:\n",
    "        file.write(f\"{movie}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epidomology of depression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = 'https://en.wikipedia.org/wiki/Epidemiology_of_depression'\n",
    "page = requests.get(URL)\n",
    "soup = BeautifulSoup(page.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = soup.find_all('table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_num(num):\n",
    "    return float(re.sub(r'[^\\w\\s]','',num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'countries':[],\n",
    "    'ranks':[],\n",
    "    'rates':[]}\n",
    "\n",
    "for table in tables:\n",
    "    rows = table.find_all('tr')\n",
    "    \n",
    "    for row in rows:\n",
    "        cells = row.find_all('td')\n",
    "        \n",
    "        \n",
    "        if len(cells) > 1:\n",
    "            rank = cells[0]\n",
    "            data['ranks'].append(int(rank.text))\n",
    "            \n",
    "            country = cells[1]\n",
    "            data['countries'].append(country.text.strip())\n",
    "            \n",
    "            rate = cells[2]\n",
    "            data['rates'].append(process_num(rate.text.strip()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>countries</th>\n",
       "      <th>ranks</th>\n",
       "      <th>rates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>United States</td>\n",
       "      <td>1</td>\n",
       "      <td>145474.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nepal</td>\n",
       "      <td>2</td>\n",
       "      <td>142448.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>East Timor</td>\n",
       "      <td>3</td>\n",
       "      <td>140410.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>4</td>\n",
       "      <td>140153.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>India</td>\n",
       "      <td>5</td>\n",
       "      <td>140084.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Pakistan</td>\n",
       "      <td>6</td>\n",
       "      <td>140042.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Brazil</td>\n",
       "      <td>7</td>\n",
       "      <td>139610.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Maldives</td>\n",
       "      <td>8</td>\n",
       "      <td>139161.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Bhutan</td>\n",
       "      <td>9</td>\n",
       "      <td>138553.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>10</td>\n",
       "      <td>138514.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Finland</td>\n",
       "      <td>11</td>\n",
       "      <td>134413.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Israel</td>\n",
       "      <td>12</td>\n",
       "      <td>127392.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Slovenia</td>\n",
       "      <td>13</td>\n",
       "      <td>124847.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Belgium</td>\n",
       "      <td>14</td>\n",
       "      <td>124446.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>France</td>\n",
       "      <td>15</td>\n",
       "      <td>123432.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Chile</td>\n",
       "      <td>16</td>\n",
       "      <td>122123.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Guatemala</td>\n",
       "      <td>17</td>\n",
       "      <td>117703.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Haiti</td>\n",
       "      <td>18</td>\n",
       "      <td>117073.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Bolivia</td>\n",
       "      <td>19</td>\n",
       "      <td>116156.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Nicaragua</td>\n",
       "      <td>20</td>\n",
       "      <td>116125.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        countries  ranks     rates\n",
       "0   United States      1  145474.0\n",
       "1           Nepal      2  142448.0\n",
       "2      East Timor      3  140410.0\n",
       "3      Bangladesh      4  140153.0\n",
       "4           India      5  140084.0\n",
       "5        Pakistan      6  140042.0\n",
       "6          Brazil      7  139610.0\n",
       "7        Maldives      8  139161.0\n",
       "8          Bhutan      9  138553.0\n",
       "9     Afghanistan     10  138514.0\n",
       "10        Finland     11  134413.0\n",
       "11         Israel     12  127392.0\n",
       "12       Slovenia     13  124847.0\n",
       "13        Belgium     14  124446.0\n",
       "14         France     15  123432.0\n",
       "15          Chile     16  122123.0\n",
       "16      Guatemala     17  117703.0\n",
       "17          Haiti     18  117073.0\n",
       "18        Bolivia     19  116156.0\n",
       "19      Nicaragua     20  116125.0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data)\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# amazon review scraping "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "header={'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_1) /\n",
    "        AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.129 Safari/537.36'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cookie = {'cookie': 'ubid-acbin=260-1909053-4047640; lc-acbin=en_IN; /\n",
    "          x-wl-uid=1rkHSudA/viplXWOFpVAUqTmi37h0RslVkgv82Dto06D1k632NaPouL/Z96cPd/\n",
    "          BQwqFG1iB7wYBFfDtswYGVlMLMQnjgEeiCp/lDN4Hf9+vsDZ0o/m1GRF0JsD+RE4p/LCQXZ9/uNT4=; \n",
    "          session-id=258-2370200-2213941; i18n-prefs=INR; p2dPopoverID_all_A3080OUTBC0143=1568050739.944; \n",
    "          p2dPopoverID_default_A3080OUTBC0143=1568050739.945; s_nr=1572545365305-New; \n",
    "          s_vnum=2004545365306%26vn%3D1; s_dslv=1572545365308; \n",
    "          x-acbin=\"TkGELE9fih23UyL0hFfqryLJmCFz?5sjtkyvUtoEHZWtpNvsclvFZ0jNE1@tnHJD\"; \n",
    "          at-acbin=Atza|IwEBICkYRnHoNbSeL_OAlNQ5OmvMQabdnDHK3EUXxoSYs0NYFdCB9ri6HCNjQ09-rHfxymAVQ0UgV0yU4jZ0VOqxKy-\n",
    "          pJJK3yzksl01F9sm6bemCKYBVS1JRt2xMb8y6m_LdCfYxQd2fFFHeNIciF8rJCBvXf1HLvZsQZASrph60NU5JdGSPn3UQ_\n",
    "          kpN6tvDLt7VvEAZ483PjB5651HphmVDbw-dD56ye9PWek4zSwPjDeQr4_WSw5dROVUgqOX-Dmdk1-tOQOMm-\n",
    "          mcZWqVZweZ5A1rCPytAC5B0zd-9n5Lm3rWqFLf4F2puOVGE868MCzXfDb2KiwP5ESdQRkX5vQ2aHYs5gS-\n",
    "          5YzT3A6mdhPMbHcdxUxm3cYhi6YLmSpIXHZWxxBXQdRlfMvz21FW3IZZSdwNY; \n",
    "          sess-at-acbin=\"pB5POe1Bdxu71Vt54rwQ4K2UFhIeq29aeLjs+bWwxO8=\"; \n",
    "          sst-acbin=Sst1|PQGnXVXsh_wr3BCCuhtSnZTpCxq1BP0NNqHuWgjdy9zLlIohgpv--\n",
    "          iUhHZKJX4jThrQjaPeyy4CbWidrKImxNcY_ZdDrCgvMEd3jmhTkpUeQxOghHNtfCJ9SIDOoG5x3kguR03UrSWKdQ_gM_\n",
    "          wJ15CRFFtPV6Z39dfp5GxsoCXfTRARjM8eIU85uNq6-jm-CHpTdQGoioqBeNe2DFk0kHohgt9hiHxPfoCCVSU-\n",
    "          a6HfCU3Bqu2m14qajk8oPaBIAYeBMWweSrhAzvsyLV5-I4XZCuKGf6rxs2qtqWk0rZydjNzdvZ6V4nXLf_\n",
    "          CRXkJky6DcWxzJQio4JsCLwf9XfQ-JwaA; visitCount=3; session-token=\"Gsa+1UjEo45P9sMD6I9zqcA/nkAPsxx5mV+\n",
    "          0bPps0Sf14MhKn7oWqEIDgOw9YLduIE04xXe6yaN3XmomI6X7tx14il0O2NFqUWh90msqn9LUceSxRjhgaNIY+\n",
    "          zRdcLzAJCIvcyD7GduhsXoUhcG6tRNg+/h+phtrwzwxyNtBtJvE/9MJMYMPzNOnuY8r0EhHnAzsShyXH49wBJq0sEkGrD5K/\n",
    "          wb3bbIzcipj1O5knCztGY2xo/GgopHQsnIa53sZdsMDBP4alTA=\"; session-id-time=2082758401l; \n",
    "          csm-hit=tb:0H2316FA44GP86DJ1QQY+s-KMSBTN6M3KGNH4ABSG0Z|1588756160911&t:1588756160912&adb:adblk_no'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Search(search_query):\n",
    "    url=\"https://www.amazon.in/s?k=\"+search_query\n",
    "    print(url)\n",
    "    page=requests.get(url,headers=header,cookies=cookie)\n",
    "    if page.status_code==200:\n",
    "        return page,url\n",
    "    else:\n",
    "        return \"Error\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.amazon.in/s?k=jbl+speakers&page=1\n",
      "https://www.amazon.in/s?k=jbl+speakers&page=2\n",
      "https://www.amazon.in/s?k=jbl+speakers&page=3\n"
     ]
    }
   ],
   "source": [
    "product_Name=[]\n",
    "Asin_no=[]\n",
    "for i in range(1,4):\n",
    "    response,url=Search(\"jbl+speakers&page=\"+str(i))\n",
    "    soup=BeautifulSoup(response.content)\n",
    "    for i in soup.findAll('span',attrs={'class':'a-size-base-plus a-color-base a-text-normal'}):\n",
    "        product_Name.append(i.text)\n",
    "    for i in soup.findAll('div',\n",
    "                          attrs={'class':'sg-col-4-of-24 sg-col-4-of-12 sg-col-4-of-36 s-result-item /\n",
    "                                 s-asin sg-col-4-of-28 sg-col-4-of-16 sg-col sg-col-4-of-20 sg-col-4-of-32'}):\n",
    "        Asin_no.append(i['data-asin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "144"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Asin_no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def url_link(query):\n",
    "    url=\"https://www.amazon.in/dp/\"+query\n",
    "    page=requests.get(url,headers=header)\n",
    "    if page.status_code==200:\n",
    "        return page\n",
    "    else:\n",
    "        return \"Error\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Link=[]\n",
    "for i in range(len(Asin_no)):\n",
    "    if Asin_no[i]!='':\n",
    "        link_response=url_link(Asin_no[i])\n",
    "        soup=BeautifulSoup(link_response.content)\n",
    "        for i in soup.findAll('a',attrs={'data-hook':'see-all-reviews-link-foot'}):\n",
    "            Link.append(i['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def content(query):\n",
    "    url=\"https://www.amazon.in/\"+query\n",
    "    print(url)\n",
    "    page=requests.get(url,headers=header)\n",
    "    if page.status_code==200:\n",
    "        return page\n",
    "    else:\n",
    "        return \"Error\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.amazon.in//%E0%A4%AA%E0%A5%8B%E0%A4%B0%E0%A5%8D%E0%A4%9F%E0%A5%87%E0%A4%AC%E0%A4%B2-%E0%A4%B5%E0%A4%BE%E0%A4%AF%E0%A4%B0%E0%A4%B2%E0%A5%87%E0%A4%B8-Bluetooth-%E0%A4%AE%E0%A4%BE%E0%A4%87%E0%A4%95-%E0%A4%B8%E0%A5%8D%E0%A4%AA%E0%A5%80%E0%A4%95%E0%A4%B0/product-reviews/B00TFGVULI?reviewerType=all_reviews&pageNumber=1\n",
      "https://www.amazon.in//%E0%A4%AA%E0%A5%8B%E0%A4%B0%E0%A5%8D%E0%A4%9F%E0%A5%87%E0%A4%AC%E0%A4%B2-%E0%A4%B5%E0%A4%BE%E0%A4%AF%E0%A4%B0%E0%A4%B2%E0%A5%87%E0%A4%B8-Bluetooth-%E0%A4%AE%E0%A4%BE%E0%A4%87%E0%A4%95-%E0%A4%B8%E0%A5%8D%E0%A4%AA%E0%A5%80%E0%A4%95%E0%A4%B0/product-reviews/B00TFGVULI?reviewerType=all_reviews&pageNumber=2\n",
      "https://www.amazon.in//%E0%A4%AA%E0%A5%8B%E0%A4%B0%E0%A5%8D%E0%A4%9F%E0%A5%87%E0%A4%AC%E0%A4%B2-%E0%A4%B5%E0%A4%BE%E0%A4%AF%E0%A4%B0%E0%A4%B2%E0%A5%87%E0%A4%B8-Bluetooth-%E0%A4%AE%E0%A4%BE%E0%A4%87%E0%A4%95-%E0%A4%B8%E0%A5%8D%E0%A4%AA%E0%A5%80%E0%A4%95%E0%A4%B0/product-reviews/B00TFGVULI?reviewerType=all_reviews&pageNumber=3\n",
      "https://www.amazon.in//%E0%A4%AA%E0%A5%8B%E0%A4%B0%E0%A5%8D%E0%A4%9F%E0%A5%87%E0%A4%AC%E0%A4%B2-%E0%A4%B5%E0%A4%BE%E0%A4%AF%E0%A4%B0%E0%A4%B2%E0%A5%87%E0%A4%B8-Bluetooth-%E0%A4%AE%E0%A4%BE%E0%A4%87%E0%A4%95-%E0%A4%B8%E0%A5%8D%E0%A4%AA%E0%A5%80%E0%A4%95%E0%A4%B0/product-reviews/B00TFGVULI?reviewerType=all_reviews&pageNumber=4\n",
      "https://www.amazon.in//%E0%A4%AA%E0%A5%8B%E0%A4%B0%E0%A5%8D%E0%A4%9F%E0%A5%87%E0%A4%AC%E0%A4%B2-%E0%A4%B5%E0%A4%BE%E0%A4%AF%E0%A4%B0%E0%A4%B2%E0%A5%87%E0%A4%B8-Bluetooth-%E0%A4%AE%E0%A4%BE%E0%A4%87%E0%A4%95-%E0%A4%B8%E0%A5%8D%E0%A4%AA%E0%A5%80%E0%A4%95%E0%A4%B0/product-reviews/B00TFGVULI?reviewerType=all_reviews&pageNumber=5\n",
      "https://www.amazon.in//%E0%A4%AA%E0%A5%8B%E0%A4%B0%E0%A5%8D%E0%A4%9F%E0%A5%87%E0%A4%AC%E0%A4%B2-%E0%A4%B5%E0%A4%BE%E0%A4%AF%E0%A4%B0%E0%A4%B2%E0%A5%87%E0%A4%B8-Bluetooth-%E0%A4%AE%E0%A4%BE%E0%A4%87%E0%A4%95-%E0%A4%B8%E0%A5%8D%E0%A4%AA%E0%A5%80%E0%A4%95%E0%A4%B0/product-reviews/B00TFGVULI?reviewerType=all_reviews&pageNumber=6\n",
      "https://www.amazon.in//%E0%A4%AA%E0%A5%8B%E0%A4%B0%E0%A5%8D%E0%A4%9F%E0%A5%87%E0%A4%AC%E0%A4%B2-%E0%A4%B5%E0%A4%BE%E0%A4%AF%E0%A4%B0%E0%A4%B2%E0%A5%87%E0%A4%B8-Bluetooth-%E0%A4%AE%E0%A4%BE%E0%A4%87%E0%A4%95-%E0%A4%B8%E0%A5%8D%E0%A4%AA%E0%A5%80%E0%A4%95%E0%A4%B0/product-reviews/B00TFGVULI?reviewerType=all_reviews&pageNumber=7\n",
      "https://www.amazon.in//%E0%A4%AA%E0%A5%8B%E0%A4%B0%E0%A5%8D%E0%A4%9F%E0%A5%87%E0%A4%AC%E0%A4%B2-%E0%A4%B5%E0%A4%BE%E0%A4%AF%E0%A4%B0%E0%A4%B2%E0%A5%87%E0%A4%B8-Bluetooth-%E0%A4%AE%E0%A4%BE%E0%A4%87%E0%A4%95-%E0%A4%B8%E0%A5%8D%E0%A4%AA%E0%A5%80%E0%A4%95%E0%A4%B0/product-reviews/B00TFGVULI?reviewerType=all_reviews&pageNumber=8\n",
      "https://www.amazon.in//%E0%A4%AA%E0%A5%8B%E0%A4%B0%E0%A5%8D%E0%A4%9F%E0%A5%87%E0%A4%AC%E0%A4%B2-%E0%A4%B5%E0%A4%BE%E0%A4%AF%E0%A4%B0%E0%A4%B2%E0%A5%87%E0%A4%B8-Bluetooth-%E0%A4%AE%E0%A4%BE%E0%A4%87%E0%A4%95-%E0%A4%B8%E0%A5%8D%E0%A4%AA%E0%A5%80%E0%A4%95%E0%A4%B0/product-reviews/B00TFGVULI?reviewerType=all_reviews&pageNumber=9\n",
      "https://www.amazon.in//%E0%A4%AA%E0%A5%8B%E0%A4%B0%E0%A5%8D%E0%A4%9F%E0%A5%87%E0%A4%AC%E0%A4%B2-%E0%A4%B5%E0%A4%BE%E0%A4%AF%E0%A4%B0%E0%A4%B2%E0%A5%87%E0%A4%B8-Bluetooth-%E0%A4%AE%E0%A4%BE%E0%A4%87%E0%A4%95-%E0%A4%B8%E0%A5%8D%E0%A4%AA%E0%A5%80%E0%A4%95%E0%A4%B0/product-reviews/B00TFGVULI?reviewerType=all_reviews&pageNumber=10\n",
      "https://www.amazon.in//%E0%A4%AA%E0%A5%8B%E0%A4%B0%E0%A5%8D%E0%A4%9F%E0%A5%87%E0%A4%AC%E0%A4%B2-%E0%A4%B5%E0%A4%BE%E0%A4%AF%E0%A4%B0%E0%A4%B2%E0%A5%87%E0%A4%B8-Bluetooth-%E0%A4%AE%E0%A4%BE%E0%A4%87%E0%A4%95-%E0%A4%B8%E0%A5%8D%E0%A4%AA%E0%A5%80%E0%A4%95%E0%A4%B0/product-reviews/B00TFGVULI?reviewerType=all_reviews&pageNumber=1\n",
      "https://www.amazon.in//%E0%A4%AA%E0%A5%8B%E0%A4%B0%E0%A5%8D%E0%A4%9F%E0%A5%87%E0%A4%AC%E0%A4%B2-%E0%A4%B5%E0%A4%BE%E0%A4%AF%E0%A4%B0%E0%A4%B2%E0%A5%87%E0%A4%B8-Bluetooth-%E0%A4%AE%E0%A4%BE%E0%A4%87%E0%A4%95-%E0%A4%B8%E0%A5%8D%E0%A4%AA%E0%A5%80%E0%A4%95%E0%A4%B0/product-reviews/B00TFGVULI?reviewerType=all_reviews&pageNumber=2\n",
      "https://www.amazon.in//%E0%A4%AA%E0%A5%8B%E0%A4%B0%E0%A5%8D%E0%A4%9F%E0%A5%87%E0%A4%AC%E0%A4%B2-%E0%A4%B5%E0%A4%BE%E0%A4%AF%E0%A4%B0%E0%A4%B2%E0%A5%87%E0%A4%B8-Bluetooth-%E0%A4%AE%E0%A4%BE%E0%A4%87%E0%A4%95-%E0%A4%B8%E0%A5%8D%E0%A4%AA%E0%A5%80%E0%A4%95%E0%A4%B0/product-reviews/B00TFGVULI?reviewerType=all_reviews&pageNumber=3\n",
      "https://www.amazon.in//%E0%A4%AA%E0%A5%8B%E0%A4%B0%E0%A5%8D%E0%A4%9F%E0%A5%87%E0%A4%AC%E0%A4%B2-%E0%A4%B5%E0%A4%BE%E0%A4%AF%E0%A4%B0%E0%A4%B2%E0%A5%87%E0%A4%B8-Bluetooth-%E0%A4%AE%E0%A4%BE%E0%A4%87%E0%A4%95-%E0%A4%B8%E0%A5%8D%E0%A4%AA%E0%A5%80%E0%A4%95%E0%A4%B0/product-reviews/B00TFGVULI?reviewerType=all_reviews&pageNumber=4\n",
      "https://www.amazon.in//%E0%A4%AA%E0%A5%8B%E0%A4%B0%E0%A5%8D%E0%A4%9F%E0%A5%87%E0%A4%AC%E0%A4%B2-%E0%A4%B5%E0%A4%BE%E0%A4%AF%E0%A4%B0%E0%A4%B2%E0%A5%87%E0%A4%B8-Bluetooth-%E0%A4%AE%E0%A4%BE%E0%A4%87%E0%A4%95-%E0%A4%B8%E0%A5%8D%E0%A4%AA%E0%A5%80%E0%A4%95%E0%A4%B0/product-reviews/B00TFGVULI?reviewerType=all_reviews&pageNumber=5\n",
      "https://www.amazon.in//%E0%A4%AA%E0%A5%8B%E0%A4%B0%E0%A5%8D%E0%A4%9F%E0%A5%87%E0%A4%AC%E0%A4%B2-%E0%A4%B5%E0%A4%BE%E0%A4%AF%E0%A4%B0%E0%A4%B2%E0%A5%87%E0%A4%B8-Bluetooth-%E0%A4%AE%E0%A4%BE%E0%A4%87%E0%A4%95-%E0%A4%B8%E0%A5%8D%E0%A4%AA%E0%A5%80%E0%A4%95%E0%A4%B0/product-reviews/B00TFGVULI?reviewerType=all_reviews&pageNumber=6\n",
      "https://www.amazon.in//%E0%A4%AA%E0%A5%8B%E0%A4%B0%E0%A5%8D%E0%A4%9F%E0%A5%87%E0%A4%AC%E0%A4%B2-%E0%A4%B5%E0%A4%BE%E0%A4%AF%E0%A4%B0%E0%A4%B2%E0%A5%87%E0%A4%B8-Bluetooth-%E0%A4%AE%E0%A4%BE%E0%A4%87%E0%A4%95-%E0%A4%B8%E0%A5%8D%E0%A4%AA%E0%A5%80%E0%A4%95%E0%A4%B0/product-reviews/B00TFGVULI?reviewerType=all_reviews&pageNumber=7\n",
      "https://www.amazon.in//%E0%A4%AA%E0%A5%8B%E0%A4%B0%E0%A5%8D%E0%A4%9F%E0%A5%87%E0%A4%AC%E0%A4%B2-%E0%A4%B5%E0%A4%BE%E0%A4%AF%E0%A4%B0%E0%A4%B2%E0%A5%87%E0%A4%B8-Bluetooth-%E0%A4%AE%E0%A4%BE%E0%A4%87%E0%A4%95-%E0%A4%B8%E0%A5%8D%E0%A4%AA%E0%A5%80%E0%A4%95%E0%A4%B0/product-reviews/B00TFGVULI?reviewerType=all_reviews&pageNumber=8\n",
      "https://www.amazon.in//%E0%A4%AA%E0%A5%8B%E0%A4%B0%E0%A5%8D%E0%A4%9F%E0%A5%87%E0%A4%AC%E0%A4%B2-%E0%A4%B5%E0%A4%BE%E0%A4%AF%E0%A4%B0%E0%A4%B2%E0%A5%87%E0%A4%B8-Bluetooth-%E0%A4%AE%E0%A4%BE%E0%A4%87%E0%A4%95-%E0%A4%B8%E0%A5%8D%E0%A4%AA%E0%A5%80%E0%A4%95%E0%A4%B0/product-reviews/B00TFGVULI?reviewerType=all_reviews&pageNumber=9\n",
      "https://www.amazon.in//%E0%A4%AA%E0%A5%8B%E0%A4%B0%E0%A5%8D%E0%A4%9F%E0%A5%87%E0%A4%AC%E0%A4%B2-%E0%A4%B5%E0%A4%BE%E0%A4%AF%E0%A4%B0%E0%A4%B2%E0%A5%87%E0%A4%B8-Bluetooth-%E0%A4%AE%E0%A4%BE%E0%A4%87%E0%A4%95-%E0%A4%B8%E0%A5%8D%E0%A4%AA%E0%A5%80%E0%A4%95%E0%A4%B0/product-reviews/B00TFGVULI?reviewerType=all_reviews&pageNumber=10\n",
      "https://www.amazon.in//JBL-Powerful-Waterproof-Bluetooth-Powerbank/product-reviews/B083ZS4BDZ?reviewerType=all_reviews&pageNumber=1\n",
      "https://www.amazon.in//JBL-Powerful-Waterproof-Bluetooth-Powerbank/product-reviews/B083ZS4BDZ?reviewerType=all_reviews&pageNumber=2\n",
      "https://www.amazon.in//JBL-Powerful-Waterproof-Bluetooth-Powerbank/product-reviews/B083ZS4BDZ?reviewerType=all_reviews&pageNumber=3\n",
      "https://www.amazon.in//JBL-Powerful-Waterproof-Bluetooth-Powerbank/product-reviews/B083ZS4BDZ?reviewerType=all_reviews&pageNumber=4\n",
      "https://www.amazon.in//JBL-Powerful-Waterproof-Bluetooth-Powerbank/product-reviews/B083ZS4BDZ?reviewerType=all_reviews&pageNumber=5\n",
      "https://www.amazon.in//JBL-Powerful-Waterproof-Bluetooth-Powerbank/product-reviews/B083ZS4BDZ?reviewerType=all_reviews&pageNumber=6\n",
      "https://www.amazon.in//JBL-Powerful-Waterproof-Bluetooth-Powerbank/product-reviews/B083ZS4BDZ?reviewerType=all_reviews&pageNumber=7\n",
      "https://www.amazon.in//JBL-Powerful-Waterproof-Bluetooth-Powerbank/product-reviews/B083ZS4BDZ?reviewerType=all_reviews&pageNumber=8\n",
      "https://www.amazon.in//JBL-Powerful-Waterproof-Bluetooth-Powerbank/product-reviews/B083ZS4BDZ?reviewerType=all_reviews&pageNumber=9\n",
      "https://www.amazon.in//JBL-Powerful-Waterproof-Bluetooth-Powerbank/product-reviews/B083ZS4BDZ?reviewerType=all_reviews&pageNumber=10\n",
      "https://www.amazon.in//JBL-Powerful-Waterproof-Bluetooth-Powerbank/product-reviews/B083ZS4BDZ?reviewerType=all_reviews&pageNumber=1\n",
      "https://www.amazon.in//JBL-Powerful-Waterproof-Bluetooth-Powerbank/product-reviews/B083ZS4BDZ?reviewerType=all_reviews&pageNumber=2\n",
      "https://www.amazon.in//JBL-Powerful-Waterproof-Bluetooth-Powerbank/product-reviews/B083ZS4BDZ?reviewerType=all_reviews&pageNumber=3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.amazon.in//JBL-Powerful-Waterproof-Bluetooth-Powerbank/product-reviews/B083ZS4BDZ?reviewerType=all_reviews&pageNumber=4\n",
      "https://www.amazon.in//JBL-Powerful-Waterproof-Bluetooth-Powerbank/product-reviews/B083ZS4BDZ?reviewerType=all_reviews&pageNumber=5\n",
      "https://www.amazon.in//JBL-Powerful-Waterproof-Bluetooth-Powerbank/product-reviews/B083ZS4BDZ?reviewerType=all_reviews&pageNumber=6\n",
      "https://www.amazon.in//JBL-Powerful-Waterproof-Bluetooth-Powerbank/product-reviews/B083ZS4BDZ?reviewerType=all_reviews&pageNumber=7\n",
      "https://www.amazon.in//JBL-Powerful-Waterproof-Bluetooth-Powerbank/product-reviews/B083ZS4BDZ?reviewerType=all_reviews&pageNumber=8\n",
      "https://www.amazon.in//JBL-Powerful-Waterproof-Bluetooth-Powerbank/product-reviews/B083ZS4BDZ?reviewerType=all_reviews&pageNumber=9\n",
      "https://www.amazon.in//JBL-Powerful-Waterproof-Bluetooth-Powerbank/product-reviews/B083ZS4BDZ?reviewerType=all_reviews&pageNumber=10\n",
      "https://www.amazon.in//JBL-Ultra-Portable-Wireless-Bluetooth-Speaker/product-reviews/B083ZRNJCQ?reviewerType=all_reviews&pageNumber=1\n",
      "https://www.amazon.in//JBL-Ultra-Portable-Wireless-Bluetooth-Speaker/product-reviews/B083ZRNJCQ?reviewerType=all_reviews&pageNumber=2\n",
      "https://www.amazon.in//JBL-Ultra-Portable-Wireless-Bluetooth-Speaker/product-reviews/B083ZRNJCQ?reviewerType=all_reviews&pageNumber=3\n",
      "https://www.amazon.in//JBL-Ultra-Portable-Wireless-Bluetooth-Speaker/product-reviews/B083ZRNJCQ?reviewerType=all_reviews&pageNumber=4\n",
      "https://www.amazon.in//JBL-Ultra-Portable-Wireless-Bluetooth-Speaker/product-reviews/B083ZRNJCQ?reviewerType=all_reviews&pageNumber=5\n",
      "https://www.amazon.in//JBL-Ultra-Portable-Wireless-Bluetooth-Speaker/product-reviews/B083ZRNJCQ?reviewerType=all_reviews&pageNumber=6\n",
      "https://www.amazon.in//JBL-Ultra-Portable-Wireless-Bluetooth-Speaker/product-reviews/B083ZRNJCQ?reviewerType=all_reviews&pageNumber=7\n",
      "https://www.amazon.in//JBL-Ultra-Portable-Wireless-Bluetooth-Speaker/product-reviews/B083ZRNJCQ?reviewerType=all_reviews&pageNumber=8\n",
      "https://www.amazon.in//JBL-Ultra-Portable-Wireless-Bluetooth-Speaker/product-reviews/B083ZRNJCQ?reviewerType=all_reviews&pageNumber=9\n",
      "https://www.amazon.in//JBL-Ultra-Portable-Wireless-Bluetooth-Speaker/product-reviews/B083ZRNJCQ?reviewerType=all_reviews&pageNumber=10\n",
      "https://www.amazon.in//JBL-Ultra-Portable-Wireless-Bluetooth-Speaker/product-reviews/B083ZRNJCQ?reviewerType=all_reviews&pageNumber=1\n",
      "https://www.amazon.in//JBL-Ultra-Portable-Wireless-Bluetooth-Speaker/product-reviews/B083ZRNJCQ?reviewerType=all_reviews&pageNumber=2\n",
      "https://www.amazon.in//JBL-Ultra-Portable-Wireless-Bluetooth-Speaker/product-reviews/B083ZRNJCQ?reviewerType=all_reviews&pageNumber=3\n",
      "https://www.amazon.in//JBL-Ultra-Portable-Wireless-Bluetooth-Speaker/product-reviews/B083ZRNJCQ?reviewerType=all_reviews&pageNumber=4\n",
      "https://www.amazon.in//JBL-Ultra-Portable-Wireless-Bluetooth-Speaker/product-reviews/B083ZRNJCQ?reviewerType=all_reviews&pageNumber=5\n",
      "https://www.amazon.in//JBL-Ultra-Portable-Wireless-Bluetooth-Speaker/product-reviews/B083ZRNJCQ?reviewerType=all_reviews&pageNumber=6\n",
      "https://www.amazon.in//JBL-Ultra-Portable-Wireless-Bluetooth-Speaker/product-reviews/B083ZRNJCQ?reviewerType=all_reviews&pageNumber=7\n",
      "https://www.amazon.in//JBL-Ultra-Portable-Wireless-Bluetooth-Speaker/product-reviews/B083ZRNJCQ?reviewerType=all_reviews&pageNumber=8\n",
      "https://www.amazon.in//JBL-Ultra-Portable-Wireless-Bluetooth-Speaker/product-reviews/B083ZRNJCQ?reviewerType=all_reviews&pageNumber=9\n",
      "https://www.amazon.in//JBL-Ultra-Portable-Wireless-Bluetooth-Speaker/product-reviews/B083ZRNJCQ?reviewerType=all_reviews&pageNumber=10\n",
      "https://www.amazon.in//JBL-Portable-Waterproof-Bluetooth-Speaker/product-reviews/B07B8T92W1?reviewerType=all_reviews&pageNumber=1\n",
      "https://www.amazon.in//JBL-Portable-Waterproof-Bluetooth-Speaker/product-reviews/B07B8T92W1?reviewerType=all_reviews&pageNumber=2\n",
      "https://www.amazon.in//JBL-Portable-Waterproof-Bluetooth-Speaker/product-reviews/B07B8T92W1?reviewerType=all_reviews&pageNumber=3\n",
      "https://www.amazon.in//JBL-Portable-Waterproof-Bluetooth-Speaker/product-reviews/B07B8T92W1?reviewerType=all_reviews&pageNumber=4\n",
      "https://www.amazon.in//JBL-Portable-Waterproof-Bluetooth-Speaker/product-reviews/B07B8T92W1?reviewerType=all_reviews&pageNumber=5\n",
      "https://www.amazon.in//JBL-Portable-Waterproof-Bluetooth-Speaker/product-reviews/B07B8T92W1?reviewerType=all_reviews&pageNumber=6\n",
      "https://www.amazon.in//JBL-Portable-Waterproof-Bluetooth-Speaker/product-reviews/B07B8T92W1?reviewerType=all_reviews&pageNumber=7\n",
      "https://www.amazon.in//JBL-Portable-Waterproof-Bluetooth-Speaker/product-reviews/B07B8T92W1?reviewerType=all_reviews&pageNumber=8\n",
      "https://www.amazon.in//JBL-Portable-Waterproof-Bluetooth-Speaker/product-reviews/B07B8T92W1?reviewerType=all_reviews&pageNumber=9\n",
      "https://www.amazon.in//JBL-Portable-Waterproof-Bluetooth-Speaker/product-reviews/B07B8T92W1?reviewerType=all_reviews&pageNumber=10\n",
      "https://www.amazon.in//JBL-Portable-Waterproof-Bluetooth-Speaker/product-reviews/B07B8T92W1?reviewerType=all_reviews&pageNumber=1\n",
      "https://www.amazon.in//JBL-Portable-Waterproof-Bluetooth-Speaker/product-reviews/B07B8T92W1?reviewerType=all_reviews&pageNumber=2\n",
      "https://www.amazon.in//JBL-Portable-Waterproof-Bluetooth-Speaker/product-reviews/B07B8T92W1?reviewerType=all_reviews&pageNumber=3\n",
      "https://www.amazon.in//JBL-Portable-Waterproof-Bluetooth-Speaker/product-reviews/B07B8T92W1?reviewerType=all_reviews&pageNumber=4\n",
      "https://www.amazon.in//JBL-Portable-Waterproof-Bluetooth-Speaker/product-reviews/B07B8T92W1?reviewerType=all_reviews&pageNumber=5\n",
      "https://www.amazon.in//JBL-Portable-Waterproof-Bluetooth-Speaker/product-reviews/B07B8T92W1?reviewerType=all_reviews&pageNumber=6\n",
      "https://www.amazon.in//JBL-Portable-Waterproof-Bluetooth-Speaker/product-reviews/B07B8T92W1?reviewerType=all_reviews&pageNumber=7\n",
      "https://www.amazon.in//JBL-Portable-Waterproof-Bluetooth-Speaker/product-reviews/B07B8T92W1?reviewerType=all_reviews&pageNumber=8\n",
      "https://www.amazon.in//JBL-Portable-Waterproof-Bluetooth-Speaker/product-reviews/B07B8T92W1?reviewerType=all_reviews&pageNumber=9\n",
      "https://www.amazon.in//JBL-Portable-Waterproof-Bluetooth-Speaker/product-reviews/B07B8T92W1?reviewerType=all_reviews&pageNumber=10\n",
      "https://www.amazon.in//JBL-SRX728-18-inch-Singel-Subwoofer/product-reviews/B000Y01I84/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=1\n",
      "https://www.amazon.in//JBL-SRX728-18-inch-Singel-Subwoofer/product-reviews/B000Y01I84/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=2\n",
      "https://www.amazon.in//JBL-SRX728-18-inch-Singel-Subwoofer/product-reviews/B000Y01I84/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=3\n",
      "https://www.amazon.in//JBL-SRX728-18-inch-Singel-Subwoofer/product-reviews/B000Y01I84/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=4\n",
      "https://www.amazon.in//JBL-SRX728-18-inch-Singel-Subwoofer/product-reviews/B000Y01I84/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=5\n",
      "https://www.amazon.in//JBL-SRX728-18-inch-Singel-Subwoofer/product-reviews/B000Y01I84/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=6\n",
      "https://www.amazon.in//JBL-SRX728-18-inch-Singel-Subwoofer/product-reviews/B000Y01I84/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=7\n",
      "https://www.amazon.in//JBL-SRX728-18-inch-Singel-Subwoofer/product-reviews/B000Y01I84/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=8\n",
      "https://www.amazon.in//JBL-SRX728-18-inch-Singel-Subwoofer/product-reviews/B000Y01I84/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=9\n",
      "https://www.amazon.in//JBL-SRX728-18-inch-Singel-Subwoofer/product-reviews/B000Y01I84/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=10\n",
      "https://www.amazon.in//JBL-Portable-Bluetooth-Waterproof-Speaker/product-reviews/B07B8THDLF/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=1\n",
      "https://www.amazon.in//JBL-Portable-Bluetooth-Waterproof-Speaker/product-reviews/B07B8THDLF/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=2\n",
      "https://www.amazon.in//JBL-Portable-Bluetooth-Waterproof-Speaker/product-reviews/B07B8THDLF/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.amazon.in//JBL-Portable-Bluetooth-Waterproof-Speaker/product-reviews/B07B8THDLF/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=4\n",
      "https://www.amazon.in//JBL-Portable-Bluetooth-Waterproof-Speaker/product-reviews/B07B8THDLF/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=5\n",
      "https://www.amazon.in//JBL-Portable-Bluetooth-Waterproof-Speaker/product-reviews/B07B8THDLF/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=6\n",
      "https://www.amazon.in//JBL-Portable-Bluetooth-Waterproof-Speaker/product-reviews/B07B8THDLF/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=7\n",
      "https://www.amazon.in//JBL-Portable-Bluetooth-Waterproof-Speaker/product-reviews/B07B8THDLF/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=8\n",
      "https://www.amazon.in//JBL-Portable-Bluetooth-Waterproof-Speaker/product-reviews/B07B8THDLF/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=9\n",
      "https://www.amazon.in//JBL-Portable-Bluetooth-Waterproof-Speaker/product-reviews/B07B8THDLF/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=10\n",
      "https://www.amazon.in//JBL-Portable-Bluetooth-Waterproof-Speaker/product-reviews/B07B8THDLF/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=1\n",
      "https://www.amazon.in//JBL-Portable-Bluetooth-Waterproof-Speaker/product-reviews/B07B8THDLF/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=2\n",
      "https://www.amazon.in//JBL-Portable-Bluetooth-Waterproof-Speaker/product-reviews/B07B8THDLF/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=3\n",
      "https://www.amazon.in//JBL-Portable-Bluetooth-Waterproof-Speaker/product-reviews/B07B8THDLF/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=4\n",
      "https://www.amazon.in//JBL-Portable-Bluetooth-Waterproof-Speaker/product-reviews/B07B8THDLF/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=5\n",
      "https://www.amazon.in//JBL-Portable-Bluetooth-Waterproof-Speaker/product-reviews/B07B8THDLF/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=6\n",
      "https://www.amazon.in//JBL-Portable-Bluetooth-Waterproof-Speaker/product-reviews/B07B8THDLF/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=7\n",
      "https://www.amazon.in//JBL-Portable-Bluetooth-Waterproof-Speaker/product-reviews/B07B8THDLF/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=8\n",
      "https://www.amazon.in//JBL-Portable-Bluetooth-Waterproof-Speaker/product-reviews/B07B8THDLF/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=9\n",
      "https://www.amazon.in//JBL-Portable-Bluetooth-Waterproof-Speaker/product-reviews/B07B8THDLF/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=10\n",
      "https://www.amazon.in//JBL-FLIP3-Wireless-Bluetooth-Streaming/product-reviews/B0145L65S0/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=1\n",
      "https://www.amazon.in//JBL-FLIP3-Wireless-Bluetooth-Streaming/product-reviews/B0145L65S0/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=2\n",
      "https://www.amazon.in//JBL-FLIP3-Wireless-Bluetooth-Streaming/product-reviews/B0145L65S0/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=3\n",
      "https://www.amazon.in//JBL-FLIP3-Wireless-Bluetooth-Streaming/product-reviews/B0145L65S0/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=4\n",
      "https://www.amazon.in//JBL-FLIP3-Wireless-Bluetooth-Streaming/product-reviews/B0145L65S0/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=5\n",
      "https://www.amazon.in//JBL-FLIP3-Wireless-Bluetooth-Streaming/product-reviews/B0145L65S0/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=6\n",
      "https://www.amazon.in//JBL-FLIP3-Wireless-Bluetooth-Streaming/product-reviews/B0145L65S0/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=7\n",
      "https://www.amazon.in//JBL-FLIP3-Wireless-Bluetooth-Streaming/product-reviews/B0145L65S0/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=8\n",
      "https://www.amazon.in//JBL-FLIP3-Wireless-Bluetooth-Streaming/product-reviews/B0145L65S0/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=9\n",
      "https://www.amazon.in//JBL-FLIP3-Wireless-Bluetooth-Streaming/product-reviews/B0145L65S0/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=10\n",
      "https://www.amazon.in//JBL-FLIP3-Wireless-Bluetooth-Streaming/product-reviews/B0145L65S0/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=1\n",
      "https://www.amazon.in//JBL-FLIP3-Wireless-Bluetooth-Streaming/product-reviews/B0145L65S0/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=2\n",
      "https://www.amazon.in//JBL-FLIP3-Wireless-Bluetooth-Streaming/product-reviews/B0145L65S0/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=3\n",
      "https://www.amazon.in//JBL-FLIP3-Wireless-Bluetooth-Streaming/product-reviews/B0145L65S0/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=4\n",
      "https://www.amazon.in//JBL-FLIP3-Wireless-Bluetooth-Streaming/product-reviews/B0145L65S0/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=5\n",
      "https://www.amazon.in//JBL-FLIP3-Wireless-Bluetooth-Streaming/product-reviews/B0145L65S0/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=6\n",
      "https://www.amazon.in//JBL-FLIP3-Wireless-Bluetooth-Streaming/product-reviews/B0145L65S0/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=7\n",
      "https://www.amazon.in//JBL-FLIP3-Wireless-Bluetooth-Streaming/product-reviews/B0145L65S0/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=8\n",
      "https://www.amazon.in//JBL-FLIP3-Wireless-Bluetooth-Streaming/product-reviews/B0145L65S0/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=9\n",
      "https://www.amazon.in//JBL-FLIP3-Wireless-Bluetooth-Streaming/product-reviews/B0145L65S0/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=10\n",
      "https://www.amazon.in//JBL-Professional-EON-Compact-Professional-Grade/product-reviews/B07YBPHBTR?reviewerType=all_reviews&pageNumber=1\n",
      "https://www.amazon.in//JBL-Professional-EON-Compact-Professional-Grade/product-reviews/B07YBPHBTR?reviewerType=all_reviews&pageNumber=2\n",
      "https://www.amazon.in//JBL-Professional-EON-Compact-Professional-Grade/product-reviews/B07YBPHBTR?reviewerType=all_reviews&pageNumber=3\n",
      "https://www.amazon.in//JBL-Professional-EON-Compact-Professional-Grade/product-reviews/B07YBPHBTR?reviewerType=all_reviews&pageNumber=4\n",
      "https://www.amazon.in//JBL-Professional-EON-Compact-Professional-Grade/product-reviews/B07YBPHBTR?reviewerType=all_reviews&pageNumber=5\n",
      "https://www.amazon.in//JBL-Professional-EON-Compact-Professional-Grade/product-reviews/B07YBPHBTR?reviewerType=all_reviews&pageNumber=6\n",
      "https://www.amazon.in//JBL-Professional-EON-Compact-Professional-Grade/product-reviews/B07YBPHBTR?reviewerType=all_reviews&pageNumber=7\n",
      "https://www.amazon.in//JBL-Professional-EON-Compact-Professional-Grade/product-reviews/B07YBPHBTR?reviewerType=all_reviews&pageNumber=8\n",
      "https://www.amazon.in//JBL-Professional-EON-Compact-Professional-Grade/product-reviews/B07YBPHBTR?reviewerType=all_reviews&pageNumber=9\n",
      "https://www.amazon.in//JBL-Professional-EON-Compact-Professional-Grade/product-reviews/B07YBPHBTR?reviewerType=all_reviews&pageNumber=10\n",
      "https://www.amazon.in//JBL-Professional-EON-Compact-Professional-Grade/product-reviews/B07YBPHBTR?reviewerType=all_reviews&pageNumber=1\n",
      "https://www.amazon.in//JBL-Professional-EON-Compact-Professional-Grade/product-reviews/B07YBPHBTR?reviewerType=all_reviews&pageNumber=2\n",
      "https://www.amazon.in//JBL-Professional-EON-Compact-Professional-Grade/product-reviews/B07YBPHBTR?reviewerType=all_reviews&pageNumber=3\n",
      "https://www.amazon.in//JBL-Professional-EON-Compact-Professional-Grade/product-reviews/B07YBPHBTR?reviewerType=all_reviews&pageNumber=4\n",
      "https://www.amazon.in//JBL-Professional-EON-Compact-Professional-Grade/product-reviews/B07YBPHBTR?reviewerType=all_reviews&pageNumber=5\n",
      "https://www.amazon.in//JBL-Professional-EON-Compact-Professional-Grade/product-reviews/B07YBPHBTR?reviewerType=all_reviews&pageNumber=6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.amazon.in//JBL-Professional-EON-Compact-Professional-Grade/product-reviews/B07YBPHBTR?reviewerType=all_reviews&pageNumber=7\n",
      "https://www.amazon.in//JBL-Professional-EON-Compact-Professional-Grade/product-reviews/B07YBPHBTR?reviewerType=all_reviews&pageNumber=8\n",
      "https://www.amazon.in//JBL-Professional-EON-Compact-Professional-Grade/product-reviews/B07YBPHBTR?reviewerType=all_reviews&pageNumber=9\n",
      "https://www.amazon.in//JBL-Professional-EON-Compact-Professional-Grade/product-reviews/B07YBPHBTR?reviewerType=all_reviews&pageNumber=10\n",
      "https://www.amazon.in//JBL-Flip-Portable-Wireless-Powerful/product-reviews/B076CG24YJ?reviewerType=all_reviews&pageNumber=1\n",
      "https://www.amazon.in//JBL-Flip-Portable-Wireless-Powerful/product-reviews/B076CG24YJ?reviewerType=all_reviews&pageNumber=2\n",
      "https://www.amazon.in//JBL-Flip-Portable-Wireless-Powerful/product-reviews/B076CG24YJ?reviewerType=all_reviews&pageNumber=3\n",
      "https://www.amazon.in//JBL-Flip-Portable-Wireless-Powerful/product-reviews/B076CG24YJ?reviewerType=all_reviews&pageNumber=4\n",
      "https://www.amazon.in//JBL-Flip-Portable-Wireless-Powerful/product-reviews/B076CG24YJ?reviewerType=all_reviews&pageNumber=5\n",
      "https://www.amazon.in//JBL-Flip-Portable-Wireless-Powerful/product-reviews/B076CG24YJ?reviewerType=all_reviews&pageNumber=6\n",
      "https://www.amazon.in//JBL-Flip-Portable-Wireless-Powerful/product-reviews/B076CG24YJ?reviewerType=all_reviews&pageNumber=7\n",
      "https://www.amazon.in//JBL-Flip-Portable-Wireless-Powerful/product-reviews/B076CG24YJ?reviewerType=all_reviews&pageNumber=8\n",
      "https://www.amazon.in//JBL-Flip-Portable-Wireless-Powerful/product-reviews/B076CG24YJ?reviewerType=all_reviews&pageNumber=9\n",
      "https://www.amazon.in//JBL-Flip-Portable-Wireless-Powerful/product-reviews/B076CG24YJ?reviewerType=all_reviews&pageNumber=10\n",
      "https://www.amazon.in//JBL-Flip-Portable-Wireless-Powerful/product-reviews/B076CG24YJ?reviewerType=all_reviews&pageNumber=1\n",
      "https://www.amazon.in//JBL-Flip-Portable-Wireless-Powerful/product-reviews/B076CG24YJ?reviewerType=all_reviews&pageNumber=2\n",
      "https://www.amazon.in//JBL-Flip-Portable-Wireless-Powerful/product-reviews/B076CG24YJ?reviewerType=all_reviews&pageNumber=3\n",
      "https://www.amazon.in//JBL-Flip-Portable-Wireless-Powerful/product-reviews/B076CG24YJ?reviewerType=all_reviews&pageNumber=4\n",
      "https://www.amazon.in//JBL-Flip-Portable-Wireless-Powerful/product-reviews/B076CG24YJ?reviewerType=all_reviews&pageNumber=5\n",
      "https://www.amazon.in//JBL-Flip-Portable-Wireless-Powerful/product-reviews/B076CG24YJ?reviewerType=all_reviews&pageNumber=6\n",
      "https://www.amazon.in//JBL-Flip-Portable-Wireless-Powerful/product-reviews/B076CG24YJ?reviewerType=all_reviews&pageNumber=7\n",
      "https://www.amazon.in//JBL-Flip-Portable-Wireless-Powerful/product-reviews/B076CG24YJ?reviewerType=all_reviews&pageNumber=8\n",
      "https://www.amazon.in//JBL-Flip-Portable-Wireless-Powerful/product-reviews/B076CG24YJ?reviewerType=all_reviews&pageNumber=9\n",
      "https://www.amazon.in//JBL-Flip-Portable-Wireless-Powerful/product-reviews/B076CG24YJ?reviewerType=all_reviews&pageNumber=10\n",
      "https://www.amazon.in//GT-X1500THI-12-%E0%A4%87%E0%A4%82%E0%A4%9A-%E0%A4%B8%E0%A4%AC%E0%A4%B5%E0%A5%82%E0%A5%9E%E0%A4%B0-%E0%A4%AC%E0%A5%87%E0%A4%B8-%E0%A4%B0%E0%A4%BF%E0%A5%9E%E0%A5%8D%E0%A4%B2%E0%A5%87%E0%A4%95%E0%A5%8D%E0%A4%B8-%E0%A4%8F%E0%A4%A8%E0%A4%95%E0%A5%8D%E0%A4%B2%E0%A5%8B%E0%A5%9B%E0%A4%B0/product-reviews/B07NT2FQDC/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=1\n",
      "https://www.amazon.in//GT-X1500THI-12-%E0%A4%87%E0%A4%82%E0%A4%9A-%E0%A4%B8%E0%A4%AC%E0%A4%B5%E0%A5%82%E0%A5%9E%E0%A4%B0-%E0%A4%AC%E0%A5%87%E0%A4%B8-%E0%A4%B0%E0%A4%BF%E0%A5%9E%E0%A5%8D%E0%A4%B2%E0%A5%87%E0%A4%95%E0%A5%8D%E0%A4%B8-%E0%A4%8F%E0%A4%A8%E0%A4%95%E0%A5%8D%E0%A4%B2%E0%A5%8B%E0%A5%9B%E0%A4%B0/product-reviews/B07NT2FQDC/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=2\n",
      "https://www.amazon.in//GT-X1500THI-12-%E0%A4%87%E0%A4%82%E0%A4%9A-%E0%A4%B8%E0%A4%AC%E0%A4%B5%E0%A5%82%E0%A5%9E%E0%A4%B0-%E0%A4%AC%E0%A5%87%E0%A4%B8-%E0%A4%B0%E0%A4%BF%E0%A5%9E%E0%A5%8D%E0%A4%B2%E0%A5%87%E0%A4%95%E0%A5%8D%E0%A4%B8-%E0%A4%8F%E0%A4%A8%E0%A4%95%E0%A5%8D%E0%A4%B2%E0%A5%8B%E0%A5%9B%E0%A4%B0/product-reviews/B07NT2FQDC/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=3\n",
      "https://www.amazon.in//GT-X1500THI-12-%E0%A4%87%E0%A4%82%E0%A4%9A-%E0%A4%B8%E0%A4%AC%E0%A4%B5%E0%A5%82%E0%A5%9E%E0%A4%B0-%E0%A4%AC%E0%A5%87%E0%A4%B8-%E0%A4%B0%E0%A4%BF%E0%A5%9E%E0%A5%8D%E0%A4%B2%E0%A5%87%E0%A4%95%E0%A5%8D%E0%A4%B8-%E0%A4%8F%E0%A4%A8%E0%A4%95%E0%A5%8D%E0%A4%B2%E0%A5%8B%E0%A5%9B%E0%A4%B0/product-reviews/B07NT2FQDC/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=4\n",
      "https://www.amazon.in//GT-X1500THI-12-%E0%A4%87%E0%A4%82%E0%A4%9A-%E0%A4%B8%E0%A4%AC%E0%A4%B5%E0%A5%82%E0%A5%9E%E0%A4%B0-%E0%A4%AC%E0%A5%87%E0%A4%B8-%E0%A4%B0%E0%A4%BF%E0%A5%9E%E0%A5%8D%E0%A4%B2%E0%A5%87%E0%A4%95%E0%A5%8D%E0%A4%B8-%E0%A4%8F%E0%A4%A8%E0%A4%95%E0%A5%8D%E0%A4%B2%E0%A5%8B%E0%A5%9B%E0%A4%B0/product-reviews/B07NT2FQDC/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=5\n",
      "https://www.amazon.in//GT-X1500THI-12-%E0%A4%87%E0%A4%82%E0%A4%9A-%E0%A4%B8%E0%A4%AC%E0%A4%B5%E0%A5%82%E0%A5%9E%E0%A4%B0-%E0%A4%AC%E0%A5%87%E0%A4%B8-%E0%A4%B0%E0%A4%BF%E0%A5%9E%E0%A5%8D%E0%A4%B2%E0%A5%87%E0%A4%95%E0%A5%8D%E0%A4%B8-%E0%A4%8F%E0%A4%A8%E0%A4%95%E0%A5%8D%E0%A4%B2%E0%A5%8B%E0%A5%9B%E0%A4%B0/product-reviews/B07NT2FQDC/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=6\n",
      "https://www.amazon.in//GT-X1500THI-12-%E0%A4%87%E0%A4%82%E0%A4%9A-%E0%A4%B8%E0%A4%AC%E0%A4%B5%E0%A5%82%E0%A5%9E%E0%A4%B0-%E0%A4%AC%E0%A5%87%E0%A4%B8-%E0%A4%B0%E0%A4%BF%E0%A5%9E%E0%A5%8D%E0%A4%B2%E0%A5%87%E0%A4%95%E0%A5%8D%E0%A4%B8-%E0%A4%8F%E0%A4%A8%E0%A4%95%E0%A5%8D%E0%A4%B2%E0%A5%8B%E0%A5%9B%E0%A4%B0/product-reviews/B07NT2FQDC/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=7\n",
      "https://www.amazon.in//GT-X1500THI-12-%E0%A4%87%E0%A4%82%E0%A4%9A-%E0%A4%B8%E0%A4%AC%E0%A4%B5%E0%A5%82%E0%A5%9E%E0%A4%B0-%E0%A4%AC%E0%A5%87%E0%A4%B8-%E0%A4%B0%E0%A4%BF%E0%A5%9E%E0%A5%8D%E0%A4%B2%E0%A5%87%E0%A4%95%E0%A5%8D%E0%A4%B8-%E0%A4%8F%E0%A4%A8%E0%A4%95%E0%A5%8D%E0%A4%B2%E0%A5%8B%E0%A5%9B%E0%A4%B0/product-reviews/B07NT2FQDC/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=8\n",
      "https://www.amazon.in//GT-X1500THI-12-%E0%A4%87%E0%A4%82%E0%A4%9A-%E0%A4%B8%E0%A4%AC%E0%A4%B5%E0%A5%82%E0%A5%9E%E0%A4%B0-%E0%A4%AC%E0%A5%87%E0%A4%B8-%E0%A4%B0%E0%A4%BF%E0%A5%9E%E0%A5%8D%E0%A4%B2%E0%A5%87%E0%A4%95%E0%A5%8D%E0%A4%B8-%E0%A4%8F%E0%A4%A8%E0%A4%95%E0%A5%8D%E0%A4%B2%E0%A5%8B%E0%A5%9B%E0%A4%B0/product-reviews/B07NT2FQDC/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=9\n",
      "https://www.amazon.in//GT-X1500THI-12-%E0%A4%87%E0%A4%82%E0%A4%9A-%E0%A4%B8%E0%A4%AC%E0%A4%B5%E0%A5%82%E0%A5%9E%E0%A4%B0-%E0%A4%AC%E0%A5%87%E0%A4%B8-%E0%A4%B0%E0%A4%BF%E0%A5%9E%E0%A5%8D%E0%A4%B2%E0%A5%87%E0%A4%95%E0%A5%8D%E0%A4%B8-%E0%A4%8F%E0%A4%A8%E0%A4%95%E0%A5%8D%E0%A4%B2%E0%A5%8B%E0%A5%9B%E0%A4%B0/product-reviews/B07NT2FQDC/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=10\n",
      "https://www.amazon.in//JBL-EON206P-Portable-System-Black/product-reviews/B00TZW9BJK?reviewerType=all_reviews&pageNumber=1\n",
      "https://www.amazon.in//JBL-EON206P-Portable-System-Black/product-reviews/B00TZW9BJK?reviewerType=all_reviews&pageNumber=2\n",
      "https://www.amazon.in//JBL-EON206P-Portable-System-Black/product-reviews/B00TZW9BJK?reviewerType=all_reviews&pageNumber=3\n",
      "https://www.amazon.in//JBL-EON206P-Portable-System-Black/product-reviews/B00TZW9BJK?reviewerType=all_reviews&pageNumber=4\n",
      "https://www.amazon.in//JBL-EON206P-Portable-System-Black/product-reviews/B00TZW9BJK?reviewerType=all_reviews&pageNumber=5\n",
      "https://www.amazon.in//JBL-EON206P-Portable-System-Black/product-reviews/B00TZW9BJK?reviewerType=all_reviews&pageNumber=6\n",
      "https://www.amazon.in//JBL-EON206P-Portable-System-Black/product-reviews/B00TZW9BJK?reviewerType=all_reviews&pageNumber=7\n",
      "https://www.amazon.in//JBL-EON206P-Portable-System-Black/product-reviews/B00TZW9BJK?reviewerType=all_reviews&pageNumber=8\n",
      "https://www.amazon.in//JBL-EON206P-Portable-System-Black/product-reviews/B00TZW9BJK?reviewerType=all_reviews&pageNumber=9\n",
      "https://www.amazon.in//JBL-EON206P-Portable-System-Black/product-reviews/B00TZW9BJK?reviewerType=all_reviews&pageNumber=10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.amazon.in//JBL-EON206P-Portable-System-Black/product-reviews/B00TZW9BJK?reviewerType=all_reviews&pageNumber=1\n",
      "https://www.amazon.in//JBL-EON206P-Portable-System-Black/product-reviews/B00TZW9BJK?reviewerType=all_reviews&pageNumber=2\n",
      "https://www.amazon.in//JBL-EON206P-Portable-System-Black/product-reviews/B00TZW9BJK?reviewerType=all_reviews&pageNumber=3\n",
      "https://www.amazon.in//JBL-EON206P-Portable-System-Black/product-reviews/B00TZW9BJK?reviewerType=all_reviews&pageNumber=4\n",
      "https://www.amazon.in//JBL-EON206P-Portable-System-Black/product-reviews/B00TZW9BJK?reviewerType=all_reviews&pageNumber=5\n",
      "https://www.amazon.in//JBL-EON206P-Portable-System-Black/product-reviews/B00TZW9BJK?reviewerType=all_reviews&pageNumber=6\n",
      "https://www.amazon.in//JBL-EON206P-Portable-System-Black/product-reviews/B00TZW9BJK?reviewerType=all_reviews&pageNumber=7\n",
      "https://www.amazon.in//JBL-EON206P-Portable-System-Black/product-reviews/B00TZW9BJK?reviewerType=all_reviews&pageNumber=8\n",
      "https://www.amazon.in//JBL-EON206P-Portable-System-Black/product-reviews/B00TZW9BJK?reviewerType=all_reviews&pageNumber=9\n",
      "https://www.amazon.in//JBL-EON206P-Portable-System-Black/product-reviews/B00TZW9BJK?reviewerType=all_reviews&pageNumber=10\n",
      "https://www.amazon.in//JBL-JRX215-Sound-Passive-Speakers/product-reviews/B00CYNTFES/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=1\n",
      "https://www.amazon.in//JBL-JRX215-Sound-Passive-Speakers/product-reviews/B00CYNTFES/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=2\n",
      "https://www.amazon.in//JBL-JRX215-Sound-Passive-Speakers/product-reviews/B00CYNTFES/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=3\n",
      "https://www.amazon.in//JBL-JRX215-Sound-Passive-Speakers/product-reviews/B00CYNTFES/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=4\n",
      "https://www.amazon.in//JBL-JRX215-Sound-Passive-Speakers/product-reviews/B00CYNTFES/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=5\n",
      "https://www.amazon.in//JBL-JRX215-Sound-Passive-Speakers/product-reviews/B00CYNTFES/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=6\n",
      "https://www.amazon.in//JBL-JRX215-Sound-Passive-Speakers/product-reviews/B00CYNTFES/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=7\n",
      "https://www.amazon.in//JBL-JRX215-Sound-Passive-Speakers/product-reviews/B00CYNTFES/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=8\n",
      "https://www.amazon.in//JBL-JRX215-Sound-Passive-Speakers/product-reviews/B00CYNTFES/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=9\n",
      "https://www.amazon.in//JBL-JRX215-Sound-Passive-Speakers/product-reviews/B00CYNTFES/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=10\n",
      "https://www.amazon.in//JBL-JRX215-Sound-Passive-Speakers/product-reviews/B00CYNTFES/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=1\n",
      "https://www.amazon.in//JBL-JRX215-Sound-Passive-Speakers/product-reviews/B00CYNTFES/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=2\n",
      "https://www.amazon.in//JBL-JRX215-Sound-Passive-Speakers/product-reviews/B00CYNTFES/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=3\n",
      "https://www.amazon.in//JBL-JRX215-Sound-Passive-Speakers/product-reviews/B00CYNTFES/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=4\n",
      "https://www.amazon.in//JBL-JRX215-Sound-Passive-Speakers/product-reviews/B00CYNTFES/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=5\n",
      "https://www.amazon.in//JBL-JRX215-Sound-Passive-Speakers/product-reviews/B00CYNTFES/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=6\n",
      "https://www.amazon.in//JBL-JRX215-Sound-Passive-Speakers/product-reviews/B00CYNTFES/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=7\n",
      "https://www.amazon.in//JBL-JRX215-Sound-Passive-Speakers/product-reviews/B00CYNTFES/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=8\n",
      "https://www.amazon.in//JBL-JRX215-Sound-Passive-Speakers/product-reviews/B00CYNTFES/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=9\n",
      "https://www.amazon.in//JBL-JRX215-Sound-Passive-Speakers/product-reviews/B00CYNTFES/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=10\n",
      "https://www.amazon.in//Renewed-JBL-Portable-Waterproof-Bluetooth/product-reviews/B07R4DVRCW/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=1\n",
      "https://www.amazon.in//Renewed-JBL-Portable-Waterproof-Bluetooth/product-reviews/B07R4DVRCW/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=2\n",
      "https://www.amazon.in//Renewed-JBL-Portable-Waterproof-Bluetooth/product-reviews/B07R4DVRCW/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=3\n",
      "https://www.amazon.in//Renewed-JBL-Portable-Waterproof-Bluetooth/product-reviews/B07R4DVRCW/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=4\n",
      "https://www.amazon.in//Renewed-JBL-Portable-Waterproof-Bluetooth/product-reviews/B07R4DVRCW/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=5\n",
      "https://www.amazon.in//Renewed-JBL-Portable-Waterproof-Bluetooth/product-reviews/B07R4DVRCW/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=6\n",
      "https://www.amazon.in//Renewed-JBL-Portable-Waterproof-Bluetooth/product-reviews/B07R4DVRCW/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=7\n",
      "https://www.amazon.in//Renewed-JBL-Portable-Waterproof-Bluetooth/product-reviews/B07R4DVRCW/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=8\n",
      "https://www.amazon.in//Renewed-JBL-Portable-Waterproof-Bluetooth/product-reviews/B07R4DVRCW/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=9\n",
      "https://www.amazon.in//Renewed-JBL-Portable-Waterproof-Bluetooth/product-reviews/B07R4DVRCW/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=10\n",
      "https://www.amazon.in//Renewed-JBL-Portable-Waterproof-Bluetooth/product-reviews/B07R4DVRCW/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=1\n",
      "https://www.amazon.in//Renewed-JBL-Portable-Waterproof-Bluetooth/product-reviews/B07R4DVRCW/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=2\n",
      "https://www.amazon.in//Renewed-JBL-Portable-Waterproof-Bluetooth/product-reviews/B07R4DVRCW/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=3\n",
      "https://www.amazon.in//Renewed-JBL-Portable-Waterproof-Bluetooth/product-reviews/B07R4DVRCW/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=4\n",
      "https://www.amazon.in//Renewed-JBL-Portable-Waterproof-Bluetooth/product-reviews/B07R4DVRCW/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=5\n",
      "https://www.amazon.in//Renewed-JBL-Portable-Waterproof-Bluetooth/product-reviews/B07R4DVRCW/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=6\n",
      "https://www.amazon.in//Renewed-JBL-Portable-Waterproof-Bluetooth/product-reviews/B07R4DVRCW/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=7\n",
      "https://www.amazon.in//Renewed-JBL-Portable-Waterproof-Bluetooth/product-reviews/B07R4DVRCW/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=8\n",
      "https://www.amazon.in//Renewed-JBL-Portable-Waterproof-Bluetooth/product-reviews/B07R4DVRCW/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=9\n",
      "https://www.amazon.in//Renewed-JBL-Portable-Waterproof-Bluetooth/product-reviews/B07R4DVRCW/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=10\n",
      "https://www.amazon.in//JBL-Waterproof-Bluetooth-Speaker-PartyBoost/product-reviews/B07SVHCL7H/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=1\n",
      "https://www.amazon.in//JBL-Waterproof-Bluetooth-Speaker-PartyBoost/product-reviews/B07SVHCL7H/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=2\n",
      "https://www.amazon.in//JBL-Waterproof-Bluetooth-Speaker-PartyBoost/product-reviews/B07SVHCL7H/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.amazon.in//JBL-Waterproof-Bluetooth-Speaker-PartyBoost/product-reviews/B07SVHCL7H/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=4\n",
      "https://www.amazon.in//JBL-Waterproof-Bluetooth-Speaker-PartyBoost/product-reviews/B07SVHCL7H/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=5\n",
      "https://www.amazon.in//JBL-Waterproof-Bluetooth-Speaker-PartyBoost/product-reviews/B07SVHCL7H/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=6\n",
      "https://www.amazon.in//JBL-Waterproof-Bluetooth-Speaker-PartyBoost/product-reviews/B07SVHCL7H/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=7\n",
      "https://www.amazon.in//JBL-Waterproof-Bluetooth-Speaker-PartyBoost/product-reviews/B07SVHCL7H/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=8\n",
      "https://www.amazon.in//JBL-Waterproof-Bluetooth-Speaker-PartyBoost/product-reviews/B07SVHCL7H/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=9\n",
      "https://www.amazon.in//JBL-Waterproof-Bluetooth-Speaker-PartyBoost/product-reviews/B07SVHCL7H/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=10\n",
      "https://www.amazon.in//JBL-Waterproof-Bluetooth-Speaker-PartyBoost/product-reviews/B07SVHCL7H/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=1\n",
      "https://www.amazon.in//JBL-Waterproof-Bluetooth-Speaker-PartyBoost/product-reviews/B07SVHCL7H/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=2\n",
      "https://www.amazon.in//JBL-Waterproof-Bluetooth-Speaker-PartyBoost/product-reviews/B07SVHCL7H/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=3\n",
      "https://www.amazon.in//JBL-Waterproof-Bluetooth-Speaker-PartyBoost/product-reviews/B07SVHCL7H/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=4\n",
      "https://www.amazon.in//JBL-Waterproof-Bluetooth-Speaker-PartyBoost/product-reviews/B07SVHCL7H/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=5\n",
      "https://www.amazon.in//JBL-Waterproof-Bluetooth-Speaker-PartyBoost/product-reviews/B07SVHCL7H/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=6\n",
      "https://www.amazon.in//JBL-Waterproof-Bluetooth-Speaker-PartyBoost/product-reviews/B07SVHCL7H/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=7\n",
      "https://www.amazon.in//JBL-Waterproof-Bluetooth-Speaker-PartyBoost/product-reviews/B07SVHCL7H/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=8\n",
      "https://www.amazon.in//JBL-Waterproof-Bluetooth-Speaker-PartyBoost/product-reviews/B07SVHCL7H/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=9\n",
      "https://www.amazon.in//JBL-Waterproof-Bluetooth-Speaker-PartyBoost/product-reviews/B07SVHCL7H/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=10\n",
      "https://www.amazon.in//JBL-Libra-500-Mixer-Amplifiers/product-reviews/B073W9ZLD1/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=1\n",
      "https://www.amazon.in//JBL-Libra-500-Mixer-Amplifiers/product-reviews/B073W9ZLD1/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=2\n",
      "https://www.amazon.in//JBL-Libra-500-Mixer-Amplifiers/product-reviews/B073W9ZLD1/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=3\n",
      "https://www.amazon.in//JBL-Libra-500-Mixer-Amplifiers/product-reviews/B073W9ZLD1/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=4\n",
      "https://www.amazon.in//JBL-Libra-500-Mixer-Amplifiers/product-reviews/B073W9ZLD1/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=5\n",
      "https://www.amazon.in//JBL-Libra-500-Mixer-Amplifiers/product-reviews/B073W9ZLD1/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=6\n",
      "https://www.amazon.in//JBL-Libra-500-Mixer-Amplifiers/product-reviews/B073W9ZLD1/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=7\n",
      "https://www.amazon.in//JBL-Libra-500-Mixer-Amplifiers/product-reviews/B073W9ZLD1/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=8\n",
      "https://www.amazon.in//JBL-Libra-500-Mixer-Amplifiers/product-reviews/B073W9ZLD1/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=9\n",
      "https://www.amazon.in//JBL-Libra-500-Mixer-Amplifiers/product-reviews/B073W9ZLD1/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=10\n",
      "https://www.amazon.in//JBL-Boombox-Portable-Bluetooth-Waterproof/product-reviews/B07PY95KRZ/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=1\n",
      "https://www.amazon.in//JBL-Boombox-Portable-Bluetooth-Waterproof/product-reviews/B07PY95KRZ/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=2\n",
      "https://www.amazon.in//JBL-Boombox-Portable-Bluetooth-Waterproof/product-reviews/B07PY95KRZ/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=3\n",
      "https://www.amazon.in//JBL-Boombox-Portable-Bluetooth-Waterproof/product-reviews/B07PY95KRZ/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=4\n",
      "https://www.amazon.in//JBL-Boombox-Portable-Bluetooth-Waterproof/product-reviews/B07PY95KRZ/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=5\n",
      "https://www.amazon.in//JBL-Boombox-Portable-Bluetooth-Waterproof/product-reviews/B07PY95KRZ/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=6\n",
      "https://www.amazon.in//JBL-Boombox-Portable-Bluetooth-Waterproof/product-reviews/B07PY95KRZ/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=7\n",
      "https://www.amazon.in//JBL-Boombox-Portable-Bluetooth-Waterproof/product-reviews/B07PY95KRZ/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=8\n",
      "https://www.amazon.in//JBL-Boombox-Portable-Bluetooth-Waterproof/product-reviews/B07PY95KRZ/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=9\n",
      "https://www.amazon.in//JBL-Boombox-Portable-Bluetooth-Waterproof/product-reviews/B07PY95KRZ/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=10\n",
      "https://www.amazon.in//CERTIFIED-REFURBISHED-JBL-Splashproof-Bluetooth/product-reviews/B00J0EGEHU/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=1\n",
      "https://www.amazon.in//CERTIFIED-REFURBISHED-JBL-Splashproof-Bluetooth/product-reviews/B00J0EGEHU/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=2\n",
      "https://www.amazon.in//CERTIFIED-REFURBISHED-JBL-Splashproof-Bluetooth/product-reviews/B00J0EGEHU/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=3\n",
      "https://www.amazon.in//CERTIFIED-REFURBISHED-JBL-Splashproof-Bluetooth/product-reviews/B00J0EGEHU/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=4\n",
      "https://www.amazon.in//CERTIFIED-REFURBISHED-JBL-Splashproof-Bluetooth/product-reviews/B00J0EGEHU/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=5\n",
      "https://www.amazon.in//CERTIFIED-REFURBISHED-JBL-Splashproof-Bluetooth/product-reviews/B00J0EGEHU/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=6\n",
      "https://www.amazon.in//CERTIFIED-REFURBISHED-JBL-Splashproof-Bluetooth/product-reviews/B00J0EGEHU/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=7\n",
      "https://www.amazon.in//CERTIFIED-REFURBISHED-JBL-Splashproof-Bluetooth/product-reviews/B00J0EGEHU/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=8\n",
      "https://www.amazon.in//CERTIFIED-REFURBISHED-JBL-Splashproof-Bluetooth/product-reviews/B00J0EGEHU/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=9\n",
      "https://www.amazon.in//CERTIFIED-REFURBISHED-JBL-Splashproof-Bluetooth/product-reviews/B00J0EGEHU/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=10\n",
      "https://www.amazon.in//JBL-Portable-Wireless-Speaker-Powerful/product-reviews/B0764HJG8V/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=1\n",
      "https://www.amazon.in//JBL-Portable-Wireless-Speaker-Powerful/product-reviews/B0764HJG8V/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=2\n",
      "https://www.amazon.in//JBL-Portable-Wireless-Speaker-Powerful/product-reviews/B0764HJG8V/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.amazon.in//JBL-Portable-Wireless-Speaker-Powerful/product-reviews/B0764HJG8V/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=4\n",
      "https://www.amazon.in//JBL-Portable-Wireless-Speaker-Powerful/product-reviews/B0764HJG8V/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=5\n",
      "https://www.amazon.in//JBL-Portable-Wireless-Speaker-Powerful/product-reviews/B0764HJG8V/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=6\n",
      "https://www.amazon.in//JBL-Portable-Wireless-Speaker-Powerful/product-reviews/B0764HJG8V/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=7\n",
      "https://www.amazon.in//JBL-Portable-Wireless-Speaker-Powerful/product-reviews/B0764HJG8V/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=8\n",
      "https://www.amazon.in//JBL-Portable-Wireless-Speaker-Powerful/product-reviews/B0764HJG8V/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=9\n",
      "https://www.amazon.in//JBL-Portable-Wireless-Speaker-Powerful/product-reviews/B0764HJG8V/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=10\n",
      "https://www.amazon.in//JBL-Portable-Wireless-Speaker-Powerful/product-reviews/B0764HJG8V/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=1\n",
      "https://www.amazon.in//JBL-Portable-Wireless-Speaker-Powerful/product-reviews/B0764HJG8V/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=2\n",
      "https://www.amazon.in//JBL-Portable-Wireless-Speaker-Powerful/product-reviews/B0764HJG8V/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=3\n",
      "https://www.amazon.in//JBL-Portable-Wireless-Speaker-Powerful/product-reviews/B0764HJG8V/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=4\n",
      "https://www.amazon.in//JBL-Portable-Wireless-Speaker-Powerful/product-reviews/B0764HJG8V/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=5\n",
      "https://www.amazon.in//JBL-Portable-Wireless-Speaker-Powerful/product-reviews/B0764HJG8V/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=6\n",
      "https://www.amazon.in//JBL-Portable-Wireless-Speaker-Powerful/product-reviews/B0764HJG8V/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=7\n",
      "https://www.amazon.in//JBL-Portable-Wireless-Speaker-Powerful/product-reviews/B0764HJG8V/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=8\n",
      "https://www.amazon.in//JBL-Portable-Wireless-Speaker-Powerful/product-reviews/B0764HJG8V/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=9\n",
      "https://www.amazon.in//JBL-Portable-Wireless-Speaker-Powerful/product-reviews/B0764HJG8V/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=10\n",
      "https://www.amazon.in//JBL-Waterproof-Bluetooth-Speaker-PartyBoost/product-reviews/B07SWLWPXW/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=1\n",
      "https://www.amazon.in//JBL-Waterproof-Bluetooth-Speaker-PartyBoost/product-reviews/B07SWLWPXW/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=2\n",
      "https://www.amazon.in//JBL-Waterproof-Bluetooth-Speaker-PartyBoost/product-reviews/B07SWLWPXW/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=3\n",
      "https://www.amazon.in//JBL-Waterproof-Bluetooth-Speaker-PartyBoost/product-reviews/B07SWLWPXW/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=4\n",
      "https://www.amazon.in//JBL-Waterproof-Bluetooth-Speaker-PartyBoost/product-reviews/B07SWLWPXW/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=5\n",
      "https://www.amazon.in//JBL-Waterproof-Bluetooth-Speaker-PartyBoost/product-reviews/B07SWLWPXW/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=6\n",
      "https://www.amazon.in//JBL-Waterproof-Bluetooth-Speaker-PartyBoost/product-reviews/B07SWLWPXW/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=7\n",
      "https://www.amazon.in//JBL-Waterproof-Bluetooth-Speaker-PartyBoost/product-reviews/B07SWLWPXW/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=8\n",
      "https://www.amazon.in//JBL-Waterproof-Bluetooth-Speaker-PartyBoost/product-reviews/B07SWLWPXW/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=9\n",
      "https://www.amazon.in//JBL-Waterproof-Bluetooth-Speaker-PartyBoost/product-reviews/B07SWLWPXW/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=10\n",
      "https://www.amazon.in//JBL-Waterproof-Bluetooth-Speaker-PartyBoost/product-reviews/B07SWLWPXW/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=1\n",
      "https://www.amazon.in//JBL-Waterproof-Bluetooth-Speaker-PartyBoost/product-reviews/B07SWLWPXW/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=2\n",
      "https://www.amazon.in//JBL-Waterproof-Bluetooth-Speaker-PartyBoost/product-reviews/B07SWLWPXW/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=3\n",
      "https://www.amazon.in//JBL-Waterproof-Bluetooth-Speaker-PartyBoost/product-reviews/B07SWLWPXW/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=4\n",
      "https://www.amazon.in//JBL-Waterproof-Bluetooth-Speaker-PartyBoost/product-reviews/B07SWLWPXW/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=5\n",
      "https://www.amazon.in//JBL-Waterproof-Bluetooth-Speaker-PartyBoost/product-reviews/B07SWLWPXW/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=6\n",
      "https://www.amazon.in//JBL-Waterproof-Bluetooth-Speaker-PartyBoost/product-reviews/B07SWLWPXW/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=7\n",
      "https://www.amazon.in//JBL-Waterproof-Bluetooth-Speaker-PartyBoost/product-reviews/B07SWLWPXW/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=8\n",
      "https://www.amazon.in//JBL-Waterproof-Bluetooth-Speaker-PartyBoost/product-reviews/B07SWLWPXW/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=9\n",
      "https://www.amazon.in//JBL-Waterproof-Bluetooth-Speaker-PartyBoost/product-reviews/B07SWLWPXW/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=10\n",
      "https://www.amazon.in//JBL-T460BT-Extra-Wireless-Headphones/product-reviews/B07MKRJY53/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=1\n",
      "https://www.amazon.in//JBL-T460BT-Extra-Wireless-Headphones/product-reviews/B07MKRJY53/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=2\n",
      "https://www.amazon.in//JBL-T460BT-Extra-Wireless-Headphones/product-reviews/B07MKRJY53/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=3\n",
      "https://www.amazon.in//JBL-T460BT-Extra-Wireless-Headphones/product-reviews/B07MKRJY53/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=4\n",
      "https://www.amazon.in//JBL-T460BT-Extra-Wireless-Headphones/product-reviews/B07MKRJY53/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=5\n",
      "https://www.amazon.in//JBL-T460BT-Extra-Wireless-Headphones/product-reviews/B07MKRJY53/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=6\n",
      "https://www.amazon.in//JBL-T460BT-Extra-Wireless-Headphones/product-reviews/B07MKRJY53/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=7\n",
      "https://www.amazon.in//JBL-T460BT-Extra-Wireless-Headphones/product-reviews/B07MKRJY53/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=8\n",
      "https://www.amazon.in//JBL-T460BT-Extra-Wireless-Headphones/product-reviews/B07MKRJY53/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=9\n",
      "https://www.amazon.in//JBL-T460BT-Extra-Wireless-Headphones/product-reviews/B07MKRJY53/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=10\n",
      "https://www.amazon.in//JBL-T460BT-Extra-Wireless-Headphones/product-reviews/B07MKRJY53/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=1\n",
      "https://www.amazon.in//JBL-T460BT-Extra-Wireless-Headphones/product-reviews/B07MKRJY53/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=2\n",
      "https://www.amazon.in//JBL-T460BT-Extra-Wireless-Headphones/product-reviews/B07MKRJY53/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.amazon.in//JBL-T460BT-Extra-Wireless-Headphones/product-reviews/B07MKRJY53/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=4\n",
      "https://www.amazon.in//JBL-T460BT-Extra-Wireless-Headphones/product-reviews/B07MKRJY53/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=5\n",
      "https://www.amazon.in//JBL-T460BT-Extra-Wireless-Headphones/product-reviews/B07MKRJY53/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=6\n",
      "https://www.amazon.in//JBL-T460BT-Extra-Wireless-Headphones/product-reviews/B07MKRJY53/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=7\n",
      "https://www.amazon.in//JBL-T460BT-Extra-Wireless-Headphones/product-reviews/B07MKRJY53/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=8\n",
      "https://www.amazon.in//JBL-T460BT-Extra-Wireless-Headphones/product-reviews/B07MKRJY53/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=9\n",
      "https://www.amazon.in//JBL-T460BT-Extra-Wireless-Headphones/product-reviews/B07MKRJY53/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=10\n",
      "https://www.amazon.in//JBL-Portable-Speaker-Waterproof-Hardshell/product-reviews/B085TR2SSR/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=1\n",
      "https://www.amazon.in//JBL-Portable-Speaker-Waterproof-Hardshell/product-reviews/B085TR2SSR/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=2\n",
      "https://www.amazon.in//JBL-Portable-Speaker-Waterproof-Hardshell/product-reviews/B085TR2SSR/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=3\n",
      "https://www.amazon.in//JBL-Portable-Speaker-Waterproof-Hardshell/product-reviews/B085TR2SSR/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=4\n",
      "https://www.amazon.in//JBL-Portable-Speaker-Waterproof-Hardshell/product-reviews/B085TR2SSR/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=5\n",
      "https://www.amazon.in//JBL-Portable-Speaker-Waterproof-Hardshell/product-reviews/B085TR2SSR/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=6\n",
      "https://www.amazon.in//JBL-Portable-Speaker-Waterproof-Hardshell/product-reviews/B085TR2SSR/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=7\n",
      "https://www.amazon.in//JBL-Portable-Speaker-Waterproof-Hardshell/product-reviews/B085TR2SSR/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=8\n",
      "https://www.amazon.in//JBL-Portable-Speaker-Waterproof-Hardshell/product-reviews/B085TR2SSR/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=9\n",
      "https://www.amazon.in//JBL-Portable-Speaker-Waterproof-Hardshell/product-reviews/B085TR2SSR/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=10\n",
      "https://www.amazon.in//JBL-T205BT-Wireless-Earbud-Headphones/product-reviews/B07B9G75Z9/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=1\n",
      "https://www.amazon.in//JBL-T205BT-Wireless-Earbud-Headphones/product-reviews/B07B9G75Z9/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=2\n",
      "https://www.amazon.in//JBL-T205BT-Wireless-Earbud-Headphones/product-reviews/B07B9G75Z9/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=3\n",
      "https://www.amazon.in//JBL-T205BT-Wireless-Earbud-Headphones/product-reviews/B07B9G75Z9/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=4\n",
      "https://www.amazon.in//JBL-T205BT-Wireless-Earbud-Headphones/product-reviews/B07B9G75Z9/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=5\n",
      "https://www.amazon.in//JBL-T205BT-Wireless-Earbud-Headphones/product-reviews/B07B9G75Z9/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=6\n",
      "https://www.amazon.in//JBL-T205BT-Wireless-Earbud-Headphones/product-reviews/B07B9G75Z9/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=7\n",
      "https://www.amazon.in//JBL-T205BT-Wireless-Earbud-Headphones/product-reviews/B07B9G75Z9/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=8\n",
      "https://www.amazon.in//JBL-T205BT-Wireless-Earbud-Headphones/product-reviews/B07B9G75Z9/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=9\n",
      "https://www.amazon.in//JBL-T205BT-Wireless-Earbud-Headphones/product-reviews/B07B9G75Z9/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=10\n",
      "https://www.amazon.in//JBL-T205BT-Wireless-Earbud-Headphones/product-reviews/B07B9G75Z9/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=1\n",
      "https://www.amazon.in//JBL-T205BT-Wireless-Earbud-Headphones/product-reviews/B07B9G75Z9/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=2\n",
      "https://www.amazon.in//JBL-T205BT-Wireless-Earbud-Headphones/product-reviews/B07B9G75Z9/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=3\n",
      "https://www.amazon.in//JBL-T205BT-Wireless-Earbud-Headphones/product-reviews/B07B9G75Z9/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=4\n",
      "https://www.amazon.in//JBL-T205BT-Wireless-Earbud-Headphones/product-reviews/B07B9G75Z9/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=5\n",
      "https://www.amazon.in//JBL-T205BT-Wireless-Earbud-Headphones/product-reviews/B07B9G75Z9/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=6\n",
      "https://www.amazon.in//JBL-T205BT-Wireless-Earbud-Headphones/product-reviews/B07B9G75Z9/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=7\n",
      "https://www.amazon.in//JBL-T205BT-Wireless-Earbud-Headphones/product-reviews/B07B9G75Z9/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=8\n",
      "https://www.amazon.in//JBL-T205BT-Wireless-Earbud-Headphones/product-reviews/B07B9G75Z9/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=9\n",
      "https://www.amazon.in//JBL-T205BT-Wireless-Earbud-Headphones/product-reviews/B07B9G75Z9/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=10\n",
      "https://www.amazon.in//JBL-GX-600C-%E0%A4%95%E0%A5%89%E0%A4%AE%E0%A5%8D%E0%A4%AA%E0%A5%8B%E0%A4%A8%E0%A5%87%E0%A4%A8%E0%A5%8D%E0%A4%9F-%E0%A4%B8%E0%A5%80%E0%A4%95%E0%A4%B0-%E0%A4%B8%E0%A4%BF%E0%A4%B8%E0%A5%8D%E0%A4%9F%E0%A4%AE/product-reviews/B00MUKN7I0/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=1\n",
      "https://www.amazon.in//JBL-GX-600C-%E0%A4%95%E0%A5%89%E0%A4%AE%E0%A5%8D%E0%A4%AA%E0%A5%8B%E0%A4%A8%E0%A5%87%E0%A4%A8%E0%A5%8D%E0%A4%9F-%E0%A4%B8%E0%A5%80%E0%A4%95%E0%A4%B0-%E0%A4%B8%E0%A4%BF%E0%A4%B8%E0%A5%8D%E0%A4%9F%E0%A4%AE/product-reviews/B00MUKN7I0/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=2\n",
      "https://www.amazon.in//JBL-GX-600C-%E0%A4%95%E0%A5%89%E0%A4%AE%E0%A5%8D%E0%A4%AA%E0%A5%8B%E0%A4%A8%E0%A5%87%E0%A4%A8%E0%A5%8D%E0%A4%9F-%E0%A4%B8%E0%A5%80%E0%A4%95%E0%A4%B0-%E0%A4%B8%E0%A4%BF%E0%A4%B8%E0%A5%8D%E0%A4%9F%E0%A4%AE/product-reviews/B00MUKN7I0/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=3\n",
      "https://www.amazon.in//JBL-GX-600C-%E0%A4%95%E0%A5%89%E0%A4%AE%E0%A5%8D%E0%A4%AA%E0%A5%8B%E0%A4%A8%E0%A5%87%E0%A4%A8%E0%A5%8D%E0%A4%9F-%E0%A4%B8%E0%A5%80%E0%A4%95%E0%A4%B0-%E0%A4%B8%E0%A4%BF%E0%A4%B8%E0%A5%8D%E0%A4%9F%E0%A4%AE/product-reviews/B00MUKN7I0/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=4\n",
      "https://www.amazon.in//JBL-GX-600C-%E0%A4%95%E0%A5%89%E0%A4%AE%E0%A5%8D%E0%A4%AA%E0%A5%8B%E0%A4%A8%E0%A5%87%E0%A4%A8%E0%A5%8D%E0%A4%9F-%E0%A4%B8%E0%A5%80%E0%A4%95%E0%A4%B0-%E0%A4%B8%E0%A4%BF%E0%A4%B8%E0%A5%8D%E0%A4%9F%E0%A4%AE/product-reviews/B00MUKN7I0/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=5\n",
      "https://www.amazon.in//JBL-GX-600C-%E0%A4%95%E0%A5%89%E0%A4%AE%E0%A5%8D%E0%A4%AA%E0%A5%8B%E0%A4%A8%E0%A5%87%E0%A4%A8%E0%A5%8D%E0%A4%9F-%E0%A4%B8%E0%A5%80%E0%A4%95%E0%A4%B0-%E0%A4%B8%E0%A4%BF%E0%A4%B8%E0%A5%8D%E0%A4%9F%E0%A4%AE/product-reviews/B00MUKN7I0/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=6\n",
      "https://www.amazon.in//JBL-GX-600C-%E0%A4%95%E0%A5%89%E0%A4%AE%E0%A5%8D%E0%A4%AA%E0%A5%8B%E0%A4%A8%E0%A5%87%E0%A4%A8%E0%A5%8D%E0%A4%9F-%E0%A4%B8%E0%A5%80%E0%A4%95%E0%A4%B0-%E0%A4%B8%E0%A4%BF%E0%A4%B8%E0%A5%8D%E0%A4%9F%E0%A4%AE/product-reviews/B00MUKN7I0/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.amazon.in//JBL-GX-600C-%E0%A4%95%E0%A5%89%E0%A4%AE%E0%A5%8D%E0%A4%AA%E0%A5%8B%E0%A4%A8%E0%A5%87%E0%A4%A8%E0%A5%8D%E0%A4%9F-%E0%A4%B8%E0%A5%80%E0%A4%95%E0%A4%B0-%E0%A4%B8%E0%A4%BF%E0%A4%B8%E0%A5%8D%E0%A4%9F%E0%A4%AE/product-reviews/B00MUKN7I0/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=8\n",
      "https://www.amazon.in//JBL-GX-600C-%E0%A4%95%E0%A5%89%E0%A4%AE%E0%A5%8D%E0%A4%AA%E0%A5%8B%E0%A4%A8%E0%A5%87%E0%A4%A8%E0%A5%8D%E0%A4%9F-%E0%A4%B8%E0%A5%80%E0%A4%95%E0%A4%B0-%E0%A4%B8%E0%A4%BF%E0%A4%B8%E0%A5%8D%E0%A4%9F%E0%A4%AE/product-reviews/B00MUKN7I0/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=9\n",
      "https://www.amazon.in//JBL-GX-600C-%E0%A4%95%E0%A5%89%E0%A4%AE%E0%A5%8D%E0%A4%AA%E0%A5%8B%E0%A4%A8%E0%A5%87%E0%A4%A8%E0%A5%8D%E0%A4%9F-%E0%A4%B8%E0%A5%80%E0%A4%95%E0%A4%B0-%E0%A4%B8%E0%A4%BF%E0%A4%B8%E0%A5%8D%E0%A4%9F%E0%A4%AE/product-reviews/B00MUKN7I0/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=10\n",
      "https://www.amazon.in//JBL-GX-600C-%E0%A4%95%E0%A5%89%E0%A4%AE%E0%A5%8D%E0%A4%AA%E0%A5%8B%E0%A4%A8%E0%A5%87%E0%A4%A8%E0%A5%8D%E0%A4%9F-%E0%A4%B8%E0%A5%80%E0%A4%95%E0%A4%B0-%E0%A4%B8%E0%A4%BF%E0%A4%B8%E0%A5%8D%E0%A4%9F%E0%A4%AE/product-reviews/B00MUKN7I0/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=1\n",
      "https://www.amazon.in//JBL-GX-600C-%E0%A4%95%E0%A5%89%E0%A4%AE%E0%A5%8D%E0%A4%AA%E0%A5%8B%E0%A4%A8%E0%A5%87%E0%A4%A8%E0%A5%8D%E0%A4%9F-%E0%A4%B8%E0%A5%80%E0%A4%95%E0%A4%B0-%E0%A4%B8%E0%A4%BF%E0%A4%B8%E0%A5%8D%E0%A4%9F%E0%A4%AE/product-reviews/B00MUKN7I0/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=2\n",
      "https://www.amazon.in//JBL-GX-600C-%E0%A4%95%E0%A5%89%E0%A4%AE%E0%A5%8D%E0%A4%AA%E0%A5%8B%E0%A4%A8%E0%A5%87%E0%A4%A8%E0%A5%8D%E0%A4%9F-%E0%A4%B8%E0%A5%80%E0%A4%95%E0%A4%B0-%E0%A4%B8%E0%A4%BF%E0%A4%B8%E0%A5%8D%E0%A4%9F%E0%A4%AE/product-reviews/B00MUKN7I0/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=3\n",
      "https://www.amazon.in//JBL-GX-600C-%E0%A4%95%E0%A5%89%E0%A4%AE%E0%A5%8D%E0%A4%AA%E0%A5%8B%E0%A4%A8%E0%A5%87%E0%A4%A8%E0%A5%8D%E0%A4%9F-%E0%A4%B8%E0%A5%80%E0%A4%95%E0%A4%B0-%E0%A4%B8%E0%A4%BF%E0%A4%B8%E0%A5%8D%E0%A4%9F%E0%A4%AE/product-reviews/B00MUKN7I0/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=4\n",
      "https://www.amazon.in//JBL-GX-600C-%E0%A4%95%E0%A5%89%E0%A4%AE%E0%A5%8D%E0%A4%AA%E0%A5%8B%E0%A4%A8%E0%A5%87%E0%A4%A8%E0%A5%8D%E0%A4%9F-%E0%A4%B8%E0%A5%80%E0%A4%95%E0%A4%B0-%E0%A4%B8%E0%A4%BF%E0%A4%B8%E0%A5%8D%E0%A4%9F%E0%A4%AE/product-reviews/B00MUKN7I0/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=5\n",
      "https://www.amazon.in//JBL-GX-600C-%E0%A4%95%E0%A5%89%E0%A4%AE%E0%A5%8D%E0%A4%AA%E0%A5%8B%E0%A4%A8%E0%A5%87%E0%A4%A8%E0%A5%8D%E0%A4%9F-%E0%A4%B8%E0%A5%80%E0%A4%95%E0%A4%B0-%E0%A4%B8%E0%A4%BF%E0%A4%B8%E0%A5%8D%E0%A4%9F%E0%A4%AE/product-reviews/B00MUKN7I0/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=6\n",
      "https://www.amazon.in//JBL-GX-600C-%E0%A4%95%E0%A5%89%E0%A4%AE%E0%A5%8D%E0%A4%AA%E0%A5%8B%E0%A4%A8%E0%A5%87%E0%A4%A8%E0%A5%8D%E0%A4%9F-%E0%A4%B8%E0%A5%80%E0%A4%95%E0%A4%B0-%E0%A4%B8%E0%A4%BF%E0%A4%B8%E0%A5%8D%E0%A4%9F%E0%A4%AE/product-reviews/B00MUKN7I0/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=7\n",
      "https://www.amazon.in//JBL-GX-600C-%E0%A4%95%E0%A5%89%E0%A4%AE%E0%A5%8D%E0%A4%AA%E0%A5%8B%E0%A4%A8%E0%A5%87%E0%A4%A8%E0%A5%8D%E0%A4%9F-%E0%A4%B8%E0%A5%80%E0%A4%95%E0%A4%B0-%E0%A4%B8%E0%A4%BF%E0%A4%B8%E0%A5%8D%E0%A4%9F%E0%A4%AE/product-reviews/B00MUKN7I0/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=8\n",
      "https://www.amazon.in//JBL-GX-600C-%E0%A4%95%E0%A5%89%E0%A4%AE%E0%A5%8D%E0%A4%AA%E0%A5%8B%E0%A4%A8%E0%A5%87%E0%A4%A8%E0%A5%8D%E0%A4%9F-%E0%A4%B8%E0%A5%80%E0%A4%95%E0%A4%B0-%E0%A4%B8%E0%A4%BF%E0%A4%B8%E0%A5%8D%E0%A4%9F%E0%A4%AE/product-reviews/B00MUKN7I0/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=9\n",
      "https://www.amazon.in//JBL-GX-600C-%E0%A4%95%E0%A5%89%E0%A4%AE%E0%A5%8D%E0%A4%AA%E0%A5%8B%E0%A4%A8%E0%A5%87%E0%A4%A8%E0%A5%8D%E0%A4%9F-%E0%A4%B8%E0%A5%80%E0%A4%95%E0%A4%B0-%E0%A4%B8%E0%A4%BF%E0%A4%B8%E0%A5%8D%E0%A4%9F%E0%A4%AE/product-reviews/B00MUKN7I0/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=10\n"
     ]
    }
   ],
   "source": [
    "reviews=[]\n",
    "ratings=[]\n",
    "for k in range(len(Link)):\n",
    "    for i in range(1,11):\n",
    "        cont_response=content(Link[k]+'&pageNumber='+str(i))\n",
    "        soup=BeautifulSoup(cont_response.content)\n",
    "        for j in soup.findAll(\"span\",attrs={'data-hook':'review-body'}):\n",
    "            reviews.append(j.text)\n",
    "        for star in soup.findAll(\"i\",attrs={'data-hook':\"review-star-rating\"}):\n",
    "            ratings.append(star.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\nI bought this after reading many reviews on ...</td>\n",
       "      <td>3.0 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\nAverage speaker, i bought it for watching mo...</td>\n",
       "      <td>3.0 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\nExcellent product from JBL, I really loved i...</td>\n",
       "      <td>5.0 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\nExcellent product from JBL, I really loved i...</td>\n",
       "      <td>5.0 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\nSuperb voice. With good copy of songs, you g...</td>\n",
       "      <td>5.0 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\\nTruth be told I'm not much of a techie perso...</td>\n",
       "      <td>5.0 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>\\n1. Portable: The JBL Go Portable Speakers is...</td>\n",
       "      <td>4.0 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>\\nIt's been 1.5 years since the time I purchas...</td>\n",
       "      <td>5.0 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>\\nReceived the product today, am in love with ...</td>\n",
       "      <td>5.0 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>\\nI got it for 1399 rs during sale, and for th...</td>\n",
       "      <td>5.0 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>\\nIt STOPED functioning very next day. I purch...</td>\n",
       "      <td>1.0 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>\\nThis speaker sucks, I have used JBL flip 4 a...</td>\n",
       "      <td>2.0 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>\\nIt is one of the best. The only problem is t...</td>\n",
       "      <td>5.0 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>\\nSuperb. Sound quality minimizes a little whe...</td>\n",
       "      <td>5.0 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>\\nIt is unbelievable unless you see it and use...</td>\n",
       "      <td>5.0 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>\\nJBL..... This name is everything for me bcoz...</td>\n",
       "      <td>5.0 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>\\nJBL Go, Just Amazed Me. I knew It would be g...</td>\n",
       "      <td>5.0 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>\\nVery clearly, the day I got I really expecte...</td>\n",
       "      <td>3.0 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>\\nOverhyped product. Worst sound quality. Only...</td>\n",
       "      <td>1.0 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>\\nMy only concern while buying a pocket speake...</td>\n",
       "      <td>5.0 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>\\ngood one better sound quality and very handy...</td>\n",
       "      <td>4.0 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>\\nReally liked the reviews about the product s...</td>\n",
       "      <td>1.0 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>\\nExtremely disappointed with Amazon. A defect...</td>\n",
       "      <td>1.0 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>\\nIt got broken the very next day! Faulty prod...</td>\n",
       "      <td>1.0 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>\\nFirst let's talk about it's build quality :-...</td>\n",
       "      <td>5.0 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>\\nGood speaker for 1400₹.Pros1. Low &amp; Mid are ...</td>\n",
       "      <td>4.0 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>\\nI bought this jbl speaker for my laptop sinc...</td>\n",
       "      <td>4.0 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>\\nSorry to say but I was delivered a faulty pr...</td>\n",
       "      <td>1.0 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>\\nThis is one of the finest devices for travel...</td>\n",
       "      <td>4.0 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>\\nDon't go for the brand guys. The speaker is ...</td>\n",
       "      <td>1.0 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1966</th>\n",
       "      <td>\\nAfter using 20 days am writing the review .I...</td>\n",
       "      <td>5.0 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1967</th>\n",
       "      <td>\\nIt's an awesome pair of earphones with very ...</td>\n",
       "      <td>4.0 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1968</th>\n",
       "      <td>\\nVery disappointed, with the product, The rig...</td>\n",
       "      <td>1.0 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1969</th>\n",
       "      <td>\\nAs most reviews say it, the ear piece is eas...</td>\n",
       "      <td>5.0 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970</th>\n",
       "      <td>\\nThis earphone or earpod so to say has superb...</td>\n",
       "      <td>5.0 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1971</th>\n",
       "      <td>\\nThese pair of Headphones were supplied by Ap...</td>\n",
       "      <td>1.0 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1972</th>\n",
       "      <td>\\nOne of those good bluetooth earphones in the...</td>\n",
       "      <td>5.0 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1973</th>\n",
       "      <td>\\nReceived an hour back from Amazon agent and ...</td>\n",
       "      <td>1.0 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1974</th>\n",
       "      <td>\\nBest of the active wireless headphones i hav...</td>\n",
       "      <td>5.0 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1975</th>\n",
       "      <td>\\nUntil it was working, the product was great....</td>\n",
       "      <td>1.0 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1976</th>\n",
       "      <td>\\nWithin 10 days of buying these headphones, t...</td>\n",
       "      <td>1.0 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1977</th>\n",
       "      <td>\\nBluetooth Connectivity :- GoodNoise Cancella...</td>\n",
       "      <td>3.0 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1978</th>\n",
       "      <td>\\nActually dare to listenit is a JBL earpod......</td>\n",
       "      <td>5.0 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979</th>\n",
       "      <td>\\nTHE PRODUCT WAS GOOD UNTILL IT STOPPED WORKI...</td>\n",
       "      <td>1.0 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980</th>\n",
       "      <td>\\nAt the price I paid I think this was the bes...</td>\n",
       "      <td>4.0 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981</th>\n",
       "      <td>\\nI was confused with mix reviews. But once I ...</td>\n",
       "      <td>5.0 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1982</th>\n",
       "      <td>\\nIdk why people are complaining about this pr...</td>\n",
       "      <td>5.0 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1983</th>\n",
       "      <td>\\nYou will not feel them in your ears, if you ...</td>\n",
       "      <td>5.0 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1984</th>\n",
       "      <td>\\nFrom the image of product it looks like the ...</td>\n",
       "      <td>3.0 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1985</th>\n",
       "      <td>\\nPros: Very good sound quality (for the price...</td>\n",
       "      <td>4.0 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986</th>\n",
       "      <td>\\nFor a product thats made for mobility, this ...</td>\n",
       "      <td>1.0 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1987</th>\n",
       "      <td>\\nYES THERE IS GOOD BASS AND CLARITYBUT DUE TO...</td>\n",
       "      <td>3.0 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1988</th>\n",
       "      <td>\\nMusic quality is excellent. Have to try whil...</td>\n",
       "      <td>4.0 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1989</th>\n",
       "      <td>\\nI am not a very technical guy, but I love mu...</td>\n",
       "      <td>3.0 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990</th>\n",
       "      <td>\\nBuild quality of speakers is too good. It ha...</td>\n",
       "      <td>5.0 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991</th>\n",
       "      <td>\\nas name says JBL...nice product..nice deal\\n</td>\n",
       "      <td>5.0 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992</th>\n",
       "      <td>\\nDont fall for wrong info this is the best sp...</td>\n",
       "      <td>5.0 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993</th>\n",
       "      <td>\\nBuild quality of speakers is too good. It ha...</td>\n",
       "      <td>5.0 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994</th>\n",
       "      <td>\\nas name says JBL...nice product..nice deal\\n</td>\n",
       "      <td>5.0 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>\\nDont fall for wrong info this is the best sp...</td>\n",
       "      <td>5.0 out of 5 stars</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1996 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                reviews              rating\n",
       "0     \\nI bought this after reading many reviews on ...  3.0 out of 5 stars\n",
       "1     \\nAverage speaker, i bought it for watching mo...  3.0 out of 5 stars\n",
       "2     \\nExcellent product from JBL, I really loved i...  5.0 out of 5 stars\n",
       "3     \\nExcellent product from JBL, I really loved i...  5.0 out of 5 stars\n",
       "4     \\nSuperb voice. With good copy of songs, you g...  5.0 out of 5 stars\n",
       "5     \\nTruth be told I'm not much of a techie perso...  5.0 out of 5 stars\n",
       "6     \\n1. Portable: The JBL Go Portable Speakers is...  4.0 out of 5 stars\n",
       "7     \\nIt's been 1.5 years since the time I purchas...  5.0 out of 5 stars\n",
       "8     \\nReceived the product today, am in love with ...  5.0 out of 5 stars\n",
       "9     \\nI got it for 1399 rs during sale, and for th...  5.0 out of 5 stars\n",
       "10    \\nIt STOPED functioning very next day. I purch...  1.0 out of 5 stars\n",
       "11    \\nThis speaker sucks, I have used JBL flip 4 a...  2.0 out of 5 stars\n",
       "12    \\nIt is one of the best. The only problem is t...  5.0 out of 5 stars\n",
       "13    \\nSuperb. Sound quality minimizes a little whe...  5.0 out of 5 stars\n",
       "14    \\nIt is unbelievable unless you see it and use...  5.0 out of 5 stars\n",
       "15    \\nJBL..... This name is everything for me bcoz...  5.0 out of 5 stars\n",
       "16    \\nJBL Go, Just Amazed Me. I knew It would be g...  5.0 out of 5 stars\n",
       "17    \\nVery clearly, the day I got I really expecte...  3.0 out of 5 stars\n",
       "18    \\nOverhyped product. Worst sound quality. Only...  1.0 out of 5 stars\n",
       "19    \\nMy only concern while buying a pocket speake...  5.0 out of 5 stars\n",
       "20    \\ngood one better sound quality and very handy...  4.0 out of 5 stars\n",
       "21    \\nReally liked the reviews about the product s...  1.0 out of 5 stars\n",
       "22    \\nExtremely disappointed with Amazon. A defect...  1.0 out of 5 stars\n",
       "23    \\nIt got broken the very next day! Faulty prod...  1.0 out of 5 stars\n",
       "24    \\nFirst let's talk about it's build quality :-...  5.0 out of 5 stars\n",
       "25    \\nGood speaker for 1400₹.Pros1. Low & Mid are ...  4.0 out of 5 stars\n",
       "26    \\nI bought this jbl speaker for my laptop sinc...  4.0 out of 5 stars\n",
       "27    \\nSorry to say but I was delivered a faulty pr...  1.0 out of 5 stars\n",
       "28    \\nThis is one of the finest devices for travel...  4.0 out of 5 stars\n",
       "29    \\nDon't go for the brand guys. The speaker is ...  1.0 out of 5 stars\n",
       "...                                                 ...                 ...\n",
       "1966  \\nAfter using 20 days am writing the review .I...  5.0 out of 5 stars\n",
       "1967  \\nIt's an awesome pair of earphones with very ...  4.0 out of 5 stars\n",
       "1968  \\nVery disappointed, with the product, The rig...  1.0 out of 5 stars\n",
       "1969  \\nAs most reviews say it, the ear piece is eas...  5.0 out of 5 stars\n",
       "1970  \\nThis earphone or earpod so to say has superb...  5.0 out of 5 stars\n",
       "1971  \\nThese pair of Headphones were supplied by Ap...  1.0 out of 5 stars\n",
       "1972  \\nOne of those good bluetooth earphones in the...  5.0 out of 5 stars\n",
       "1973  \\nReceived an hour back from Amazon agent and ...  1.0 out of 5 stars\n",
       "1974  \\nBest of the active wireless headphones i hav...  5.0 out of 5 stars\n",
       "1975  \\nUntil it was working, the product was great....  1.0 out of 5 stars\n",
       "1976  \\nWithin 10 days of buying these headphones, t...  1.0 out of 5 stars\n",
       "1977  \\nBluetooth Connectivity :- GoodNoise Cancella...  3.0 out of 5 stars\n",
       "1978  \\nActually dare to listenit is a JBL earpod......  5.0 out of 5 stars\n",
       "1979  \\nTHE PRODUCT WAS GOOD UNTILL IT STOPPED WORKI...  1.0 out of 5 stars\n",
       "1980  \\nAt the price I paid I think this was the bes...  4.0 out of 5 stars\n",
       "1981  \\nI was confused with mix reviews. But once I ...  5.0 out of 5 stars\n",
       "1982  \\nIdk why people are complaining about this pr...  5.0 out of 5 stars\n",
       "1983  \\nYou will not feel them in your ears, if you ...  5.0 out of 5 stars\n",
       "1984  \\nFrom the image of product it looks like the ...  3.0 out of 5 stars\n",
       "1985  \\nPros: Very good sound quality (for the price...  4.0 out of 5 stars\n",
       "1986  \\nFor a product thats made for mobility, this ...  1.0 out of 5 stars\n",
       "1987  \\nYES THERE IS GOOD BASS AND CLARITYBUT DUE TO...  3.0 out of 5 stars\n",
       "1988  \\nMusic quality is excellent. Have to try whil...  4.0 out of 5 stars\n",
       "1989  \\nI am not a very technical guy, but I love mu...  3.0 out of 5 stars\n",
       "1990  \\nBuild quality of speakers is too good. It ha...  5.0 out of 5 stars\n",
       "1991     \\nas name says JBL...nice product..nice deal\\n  5.0 out of 5 stars\n",
       "1992  \\nDont fall for wrong info this is the best sp...  5.0 out of 5 stars\n",
       "1993  \\nBuild quality of speakers is too good. It ha...  5.0 out of 5 stars\n",
       "1994     \\nas name says JBL...nice product..nice deal\\n  5.0 out of 5 stars\n",
       "1995  \\nDont fall for wrong info this is the best sp...  5.0 out of 5 stars\n",
       "\n",
       "[1996 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame()\n",
    "df['reviews']=reviews\n",
    "df['rating']=ratings\n",
    "df.to_csv('sample_review.csv',index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# !Hurray We completed data analysis on Pandas and numpy "
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "441px",
    "left": "119px",
    "top": "255px",
    "width": "237.391px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
